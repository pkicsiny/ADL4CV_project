{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #\"\" for CPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rain measurements\n",
    "Measurements are downloaded from the DWD (German weather service) open data server: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/__<br>\n",
    "I'm working with the data of August 2010 (based on [this](https://tradingeconomics.com/germany/precipitation)), so I have downloaded this: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/2010/RW-201008.tar__<br>\n",
    "_DWD manual:_<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/BESCHREIBUNG_gridsgermany_hourly_radolan_historical_asc_de.pdf__<br><br>\n",
    "This contains radar maps recorded in every hour. Each map has a resolution of $900\\times900$ pixels and each pixel corresponds to an $1\\,km\\times1\\,km$ area in reality. Pixel values are the precipitation height in $0.1\\,mm$.\n",
    "Below I'm importing the data of this as a series of numpy arrays and plot them to see the acual radar map. The _sys.path[0]_ is the path on my computer and it can be different for you.\n",
    "<br>\n",
    "The data with hourly resolutions spans from 1995 to 2012.<br><br>\n",
    "Additionally there is data with 5 minutes resolution available here: \n",
    "https://opendata.dwd.de/weather/radar/composit/rx/<br>\n",
    "The span of this is the last two days and it is updated constantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = src.get_data(sys.path[0]+\"/rain_hourly\", which=\"h\",total_length=4, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, v, s = src.load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind measurements\n",
    "Here I'm loading wind measurements. This is important because later we might experiment not only with rain (the density field) but with the wind (velocity field) too. This is because in the [tempoGAN](https://arxiv.org/pdf/1801.09710.pdf) paper they also use the velocity and without it that might be very difficult to build the GAN. I have downloaded two datasets for the wind:<br><br>\n",
    "_Wind direction:_ __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/Project_TRY/wind_direction/DD_201208.nc.gz__<br>\n",
    "_Wind speed:_ __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/Project_TRY/wind_speed/FF_201208.nc.gz__<br>\n",
    "_DWD manuals:_<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/Project_TRY/wind_direction/DESCRIPTION_gridsgermany_hourly_Project_TRY_wind_direction_en.pdf__\n",
    "<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/Project_TRY/wind_speed/DESCRIPTION_gridsgermany_hourly_Project_TRY_wind_speed_en.pdf__<br><br>\n",
    "I create two datasets out of these. They contain the $x$ and $y$ velocity components.\n",
    "The measurements are in $\\displaystyle0.1\\,\\frac{m}{s}$.\n",
    "<br><br>\n",
    "_<font color='red'>__Issue__:</font> [Mostly](https://www.nationalgeographic.com/science/earth/earths-atmosphere/clouds/) an average rain cloud is at $2000\\,m$ high. Normal clouds can be up to $6000\\,m$ high. We only have wind measurements recorded at $10\\,m$. \n",
    "We can use e.g. [this](https://websites.pmc.ucsc.edu/~jnoble/wind/extrap/) to calculate wind speed at higher altitudes. We can't correct the change in wind direction so this remains a weak point in the simulations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the paths are probably different for you\n",
    "w_dir = Dataset(sys.path[0]+'/wind_direction/DD_201008_CF.nc')  # direction DD\n",
    "w_vel = Dataset(sys.path[0]+'/wind_speed/FF_201008_CF.nc')  # velocity FF\n",
    "cloud = Dataset(sys.path[0]+'/cloud/N_201008_CF.nc')  # cloud cover CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_vel[\"datum\"][743]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads wind direction and magnitude datasets. They are hourly distributed and I use the dataset of 2010. August. The dates of the measurements begin with 2018.08.01.00:00:00. There are 744 = 24$\\cdot$31 maps, each 938*720 pixels. This cell below is very memory consuming so this is just a demonstration here to look over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#creating vx and vy datasets from |v| and phi\n",
    "vx = np.ma.masked_where(np.ma.getmask(w_dir['DD'][:10]), np.zeros(w_dir['DD'][:10].shape))\n",
    "vy = np.ma.masked_where(np.ma.getmask(w_dir['DD'][:10]), np.zeros(w_dir['DD'][:10].shape))\n",
    "for t in range(np.shape(vx)[0]):\n",
    "    src.update_output(f\"[{t+1}/{np.shape(vx)[0]}]\")\n",
    "    vx[t] = np.flip(w_vel[\"FF\"][t]*np.sin(np.deg2rad(w_dir['DD'][t])),axis = 0)\n",
    "    vy[t] = np.flip(w_vel[\"FF\"][t]*np.cos(np.deg2rad(w_dir['DD'][t])),axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell below extract the radar grid of these wind measurements. So a $938\\cdot720$ long dataframe is created with the latitude and longitude coordinates of the center of each grid point. The individual cells are labeled with a cell ID which is just an integer value similar to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gps grid of wind maps\n",
    "#47.075\n",
    "wind_grid = pd.DataFrame(data={'LAT':w_vel['lat'][:].flatten(),\n",
    "                               'LON':w_vel['lon'][:].flatten()}).reset_index().rename(columns={\"index\":\"CELL_ID\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I plot some examples for sanity check that the wind direction is preserved after the velocity x and y calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity checks\n",
    "%matplotlib notebook\n",
    "idx = 0\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "# NE, N, NW\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(np.ma.masked_where(vy[idx] < 0, vy[idx]))\n",
    "plt.colorbar(shrink=0.7)\n",
    "plt.title(\"All northern wind\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(np.flip(np.ma.masked_where((w_dir['DD'][idx]>=90)& (w_dir['DD'][idx]<=270),w_dir['DD'][idx] ), axis=0))\n",
    "plt.colorbar(shrink=0.7)\n",
    "plt.title(\"All northern wind truth\")\n",
    "\n",
    "# SW\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(np.ma.masked_where((vy[idx]>0)|(vx[idx]>0), vy[idx]))\n",
    "plt.colorbar(shrink=0.7)\n",
    "plt.title(\"Southwestern wind\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.flip(np.ma.masked_where((w_dir['DD'][idx]<180)| (w_dir['DD'][idx]>270),w_dir['DD'][idx] ), axis=0))\n",
    "plt.colorbar(shrink=0.7)\n",
    "plt.title(\"Southwestern wind truth\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is valid if one already has the rain data interpolated to the wind grid. If not scroll down for some info on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = Dataset(sys.path[0]+\"/rain_density/rho.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho[\"field\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualise channels\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5,figsize=(12,12))\n",
    "for ax in [ax1,ax2,ax3,ax4, ax5]:\n",
    "    ax.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left=False,      # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "ax1.set_title(\"Rain density\")\n",
    "ax2.set_title(\"Cloud density\")\n",
    "ax3.set_title(\"Wind velocity x\")\n",
    "ax4.set_title(\"Wind velocity y\")\n",
    "ax5.set_title(\"Wind direction\")\n",
    "line1 = ax1.imshow(rho[\"field\"][0]) # start from index 0 which means 0:50:00\n",
    "line2 = ax2.imshow(np.flip(cloud[\"CF\"][1],axis = 0)) # start from index 1 which means 1:00:00\n",
    "line3 = ax3.imshow(-np.flip(np.sin(np.deg2rad(w_dir['DD'][1])),axis = 0),cmap=\"seismic\")\n",
    "line4 = ax4.imshow(-np.flip(np.cos(np.deg2rad(w_dir['DD'][1])),axis = 0),cmap=\"seismic\")\n",
    "line5 = ax5.imshow(np.flip(w_dir[\"DD\"][1],axis = 0),cmap=\"terrain\")\n",
    "line = [line1, line2, line3, line4, line5]\n",
    "\n",
    "sh = 0.15\n",
    "fig.colorbar(line1, ax=ax1,shrink=sh)\n",
    "fig.colorbar(line2, ax=ax2,shrink=sh)\n",
    "fig.colorbar(line3, ax=ax3,shrink=sh)\n",
    "fig.colorbar(line4, ax=ax4,shrink=sh)\n",
    "fig.colorbar(line5, ax=ax5,shrink=sh)\n",
    "\n",
    "def run(i):\n",
    "    line[0].set_data(rho[\"field\"][i])\n",
    "    line[1].set_data(np.flip(cloud[\"CF\"][i+1],axis = 0))\n",
    "    line[2].set_data(-np.flip(np.sin(np.deg2rad(w_dir['DD'][i+1])),axis = 0))\n",
    "    line[3].set_data(-np.flip(np.cos(np.deg2rad(w_dir['DD'][i+1])),axis = 0))\n",
    "    line[4].set_data(np.flip(w_dir[\"DD\"][i+1],axis = 0))\n",
    "    fig.suptitle(f\"Index in array: {i}\")\n",
    "    return line\n",
    "\n",
    "ani = animation.FuncAnimation(fig, run, blit=True, interval=400, frames=500,\n",
    "    repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets for temporal GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = generate_tempoGAN_datasets(rho[\"field\"], w_vel[\"FF\"], w_dir[\"DD\"], n=10, size=200, normalize=True)[\"images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample=0\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(test[sample,:,:,0])\n",
    "plt.colorbar(shrink=0.3)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(test[sample,:,:,1])\n",
    "plt.colorbar(shrink=0.3)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(test[sample,:,:,2])\n",
    "plt.colorbar(shrink=0.3)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(test[sample,:,:,3])\n",
    "plt.colorbar(shrink=0.3)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tempoGAN_datasets(rain_density, wind_vel, wind_dir, n=10, size=64, split=None, normalize=False):\n",
    "    \"\"\"\n",
    "    Splits input array into training, cross validation and test sets.\n",
    "    :param array: 3D np array, dataset to be split. This is a channel*900*900 large array of rain radar maps.\n",
    "    Data is created by cutting size*size frames randomly from 2 consecutive maps.\n",
    "    :param n: int, total number of data instances to make\n",
    "    :param size: int, height and width in pixels of each frame\n",
    "    :param split: list or np array of either floats between 0 and 1 or positive integers. Set to None by deafult\n",
    "    which means no splitting, just return all instances in one set.\n",
    "    :return: 3D np array, either one dataset of smaller image frames or three datasets for training,\n",
    "    cross validating and testing\n",
    "    \"\"\"\n",
    "    time = 743\n",
    "    h = rain_density[0].shape[0] #938\n",
    "    w = rain_density[0].shape[1] #720\n",
    "\n",
    "\n",
    "    images = np.empty((n, 4, size, size))  # n series, each of size size**2 and rho,vx,vy,future frames as channels\n",
    "    for i in range(n):\n",
    "        src.update_output(f\"[{i+1}/{n}]\")\n",
    "        # draw 3 random numbers for map number and idx of top left pixel of window\n",
    "        valid = 0\n",
    "        while not valid:\n",
    "            anchor = (np.random.randint(0, time - 2), np.random.randint(0, h - size), np.random.randint(0, w - size))\n",
    "            # update_output(f\"Cutting images...\\n[{i+1}/{n}]\") \n",
    "            image = [ar[anchor[1]:anchor[1] + size, anchor[2]:anchor[2] + size].filled(np.nan) for ar in [\n",
    "                rain_density[anchor[0]],\n",
    "                -np.flip(np.sin(np.deg2rad(wind_dir[anchor[0]+1])),axis = 0),\n",
    "                -np.flip(np.cos(np.deg2rad(wind_dir[anchor[0]+1])),axis = 0),\n",
    "                rain_density[anchor[0]+1]]]\n",
    "            # first channel is the current frame, the next two are the wind x and y components where the index is shifted by 1\n",
    "            # because the rain dates are in xx:50 resolution but the wind is in xx:00. The next channels are the next rain fields\n",
    "            # to be predicted\n",
    "            valid = valid_image(image)\n",
    "        images[i] = image\n",
    "    \n",
    "    if normalize: #to [0,1] only for rain\n",
    "        images = [[ch/s[[x for x in [0,-1]]][\n",
    "            ~np.isnan(s[[x for x in [0,-1]]])].max() if i in [0, 3] else ch for i,ch in enumerate(s)] for s in images]\n",
    "\n",
    "    txt = f\"Shape of data: {np.shape(images)}\"\n",
    "    if split is not None:  # split\n",
    "        if all((r <= 1) & (r >= 0) for r in split):\n",
    "            assert (sum(split) == 1), \"Split values must sum up to 1.\"\n",
    "            train = images[:int(n * split[0])]\n",
    "            xval = images[int(n * split[0]):int(n * (split[0] + split[1]))]\n",
    "            test = images[int(n * (split[0] + split[1])):]\n",
    "        elif all(isinstance(r, int) for r in split):\n",
    "            train = images[:int(n * split[0] / sum(split))]\n",
    "            xval = images[int(n * split[0] / sum(split)):int(n * (split[0] + split[1]) / sum(split))]\n",
    "            test = images[int(n * (split[0] + split[1]) / sum(split)):]\n",
    "        else:\n",
    "            sys.exit(\"All split values must be either fractions for percentages or integers.\")\n",
    "\n",
    "        txt = txt + f\"\\n\\nTraining set: {np.shape(train)}\\nValidation set: {np.shape(xval)}\\nTest set: {np.shape(test)}\"\n",
    "        src.update_output(txt)\n",
    "        return {\"train\":np.transpose(train,(0,3,2,1)),\n",
    "                \"xval\": np.transpose(xval,(0,3,2,1)),\n",
    "                \"test\": np.transpose(test,(0,3,2,1))}\n",
    "    else:  # no split\n",
    "        src.update_output(txt)\n",
    "        return {\"images\": np.transpose(images,(0,3,2,1))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test[3][~np.isnan(test[3])].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_image(image):\n",
    "    \"\"\"\n",
    "    Filters out some useless data. in the junk variable several conditions are defined to check on the images.\n",
    "    Currently it checks the number of different entry values and if 0s or 1s make up 0.75 part of the whole data.\n",
    "    This throws out the cuts made inside or almost inside the mask region and rainless areas.\n",
    "    Still can be improved.\n",
    "    :param image: 3D np array, dimensions are the number of consecutive frames, height and width\n",
    "    :return: bool, whether the data instance is valid in terms of usability\n",
    "    \"\"\"\n",
    "    junk = [len(set(np.array(ar).flatten()[\n",
    "                     ~np.isnan(np.array(ar).flatten())])) <= 8 for ar in image]\n",
    "    junk += [len(np.array(frame).flatten()[\n",
    "                     np.isnan(np.array(frame).flatten())]) > 0.25 * len(np.array(frame).flatten()) for frame in image]\n",
    "    return 0 if any(junk) else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machting rain cells to wind cells\n",
    "Don't run this if the rain density data on the wind grid is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar coordinates\n",
    "The gps coordinates of the radar grid for the rain measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coords = src.get_rain_grid_coords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduced_coords = coords[coords[\"LON\"]>= germany[\"LON\"].min()]\n",
    "reduced_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Germany\n",
    "GPS coordinates of Germany. This is a subset of the wind grid. As next I'm matching wind grid cells with the nearest rain cells. As seen on the plot below, the rain and wind data comes from a different radar measurement method so they have a different grid map so the grid points are not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('germany.pickle', 'rb') as handle:\n",
    "        germany = pickle.load(handle)\n",
    "except:\n",
    "    #this takes 1 night\n",
    "    src.get_germany(w_vel, coords)\n",
    "germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "#plot wind grid\n",
    "plt.scatter(wind_grid[\"LON\"], wind_grid[\"LAT\"],s=0.2, label=\"wind grid\")\n",
    "#plot rain grid\n",
    "plt.scatter(coords[\"LON\"], coords[\"LAT\"],s=0.2, label=\"rain grid\")\n",
    "#plot wind grid points inside Germany\n",
    "plt.scatter(germany[\"LON\"],germany[\"LAT\"],s=10, label=\"Germany on wind grid\")\n",
    "#plot rain grid points that are the nearest neighbors to each wind grid cell inside Germany\n",
    "#plt.scatter(coords.iloc[germany[\"CLOSEST_RAIN_CELL_ID\"]][\"LON\"],\n",
    "#            coords.iloc[germany[\"CLOSEST_RAIN_CELL_ID\"]][\"LAT\"],\n",
    "#            s=10, label=\"rain grid\")\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Rain and wind radar grids\")\n",
    "lgnd = plt.legend(loc=\"lower right\")\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "plt.savefig(\"grids.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create density channel (rain) with the grid of the wind maps. We need 3 channels: [rain,vx,vy]<br>\n",
    "Since the wind data is available until the end of 2012, we can only create three channels using the hourly resolution. 5 min data is available only for the past 48 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = np.ma.masked_where(np.flip(np.ma.getmask(w_dir['DD'][:144]),axis=1),\n",
    "                         np.zeros((144,w_dir['DD'].shape[1],w_dir['DD'].shape[2])))\n",
    "rho[:,938-germany[\"CELL_ID\"]//720,\n",
    "    germany[\"CELL_ID\"]%720] = inputs[600:,900-germany[\"CLOSEST_RAIN_CELL_ID\"]//900, germany[\"CLOSEST_RAIN_CELL_ID\"]%900]\n",
    "rho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "idx = 45\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(np.ma.masked_where(inputs[200+idx] < 0,inputs[200+idx]))\n",
    "plt.title(\"RADOLAN rain\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rho[idx])\n",
    "plt.title(\"Interpolated rain\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(vy[idx])\n",
    "plt.title(\"Wind\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.ma.concatenate((a[\"field\"][:], rho), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating .nc file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#root_grp.close()\n",
    "root_grp = Dataset('rho.nc', 'w', format='NETCDF4')\n",
    "root_grp.description = 'Example simulation data'\n",
    "\n",
    "lat_n = 938\n",
    "lon_n = 720\n",
    "xdimension = 0.75\n",
    "ydimension = 0.75\n",
    "# dimensions\n",
    "root_grp.createDimension('time', None)\n",
    "root_grp.createDimension('lat', lat_n)\n",
    "root_grp.createDimension('lon', lon_n)\n",
    "\n",
    "# variables\n",
    "time = root_grp.createVariable('time', 'c', ('time',))\n",
    "x = root_grp.createVariable('lat', 'c', ('lat',))\n",
    "y = root_grp.createVariable('lon', 'c', ('lon',))\n",
    "field = root_grp.createVariable('field', 'f4', ('time', 'lat', 'lon',))\n",
    "\n",
    "field[:,:,:] = new\n",
    "\n",
    "root_grp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
