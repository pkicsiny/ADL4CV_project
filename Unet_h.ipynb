{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1030643681092037672\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#forces CPU usage\n",
    "environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rain measurements\n",
    "Measurements are downloaded from the DWD (German weather service) open data server: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/__<br>\n",
    "I'm working with the data of August 2010 (based on [this](https://tradingeconomics.com/germany/precipitation)), so I have downloaded this: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/2010/RW-201008.tar__<br>\n",
    "_DWD manual:_<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/BESCHREIBUNG_gridsgermany_hourly_radolan_historical_asc_de.pdf__<br><br>\n",
    "This contains radar maps recorded in every hour. Each map has a resolution of $900\\times900$ pixels and each pixel corresponds to an $1\\,km\\times1\\,km$ area in reality. Pixel values are the precipitation height in $0.1\\,mm$.\n",
    "Below I'm importing the data of this as a series of numpy arrays and plot them to see the acual radar map. The _sys.path[0]_ is the path on my computer and it can be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = src.get_data(sys.path[0]+\"/rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.ma.masked_where(inputs[0] <0,inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = src.generate_datasets(inputs, n=10000, size=128, length=2, normalize=True, split=(6,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(sys.path[0]+\"/dataset.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low_res_train = images[\"low_res_train\"]\n",
    "#low_res_xval = images[\"low_res_xval\"]\n",
    "#low_res_test = images[\"low_res_test\"]\n",
    "#overfit = np.reshape(images['images'],np.shape(images['images'])+(1,))\n",
    "train = np.reshape(images[\"train\"],np.shape(images[\"train\"])+(1,))\n",
    "xval = np.reshape(images[\"xval\"],np.shape(images[\"xval\"])+(1,))\n",
    "test = np.reshape(images[\"test\"],np.shape(images[\"test\"])+(1,))\n",
    "print(f\"Training data: {train.shape}\\nValidation data: {xval.shape}\\nTest data: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_train     = np.reshape(train[:,0,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "unet_truth     = np.reshape(train[:,1,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "unet_val       = np.reshape(xval[:,0,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "unet_val_truth = np.reshape(xval[:,1,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "print(unet_train.shape,\"\\n\",unet_truth.shape,\"\\n\",unet_val.shape,\"\\n\",unet_truth.shape)\n",
    "unet_test      = np.reshape(test[:,0,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "unet_test_truth = np.reshape(test[:,1,:,:,:],((test.shape[0],)+test.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_train = np.reshape(train[5,0,:,:,:],((1,)+train.shape[2:]))\n",
    "overfit_truth = np.reshape(train[5,1,:,:,:],((1,)+train.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.visualise_data(xval[:,:,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 8, 8, 32), (None, 4, 4, 32)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ae5aa7ed86f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mUpSamp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"channels_last\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLr5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmerge1\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mConvDown4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mUpSamp1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#(UpSamp1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mConv1\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mLr6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m   \"\"\"\n\u001b[1;32m--> 684\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m    313\u001b[0m     \u001b[1;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_inputs_arg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m           \u001b[1;31m# Note: not all sub-classes of Layer call Layer.__init__ (especially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    583\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    388\u001b[0m                        \u001b[1;34m'inputs with matching shapes '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                        \u001b[1;34m'except for the concat axis. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                        'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 8, 8, 32), (None, 4, 4, 32)]"
     ]
    }
   ],
   "source": [
    "model2=keras.Sequential()\n",
    "\n",
    "init = keras.layers.Input(shape=(64,64,1))\n",
    "ConvDown1  = keras.layers.Conv2D(filters=8,kernel_size=(2,2),strides=(1,1),padding=\"same\")(init)\n",
    "Lr1 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown1)\n",
    "#64\n",
    "ConvDown2  = keras.layers.Conv2D(filters=16,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr1)\n",
    "Lr2 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown2)\n",
    "#32\n",
    "ConvDown3  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr2)\n",
    "Lr3 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown3)\n",
    "#16\n",
    "ConvDown4  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr3)\n",
    "Lr4 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown4)\n",
    "#8\n",
    "ConvDown5  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr4)\n",
    "Lr5 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown5)\n",
    "#4\n",
    "\n",
    "UpSamp1 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr5)\n",
    "#8\n",
    "merge1  = keras.layers.concatenate([ConvDown4,UpSamp1],axis=-1)#(UpSamp1)\n",
    "Conv1   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge1)\n",
    "Lr6 = keras.layers.LeakyReLU(alpha=0.0)(Conv1)\n",
    "#8\n",
    "UpSamp2 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr6)\n",
    "#16\n",
    "merge2  = keras.layers.concatenate([ConvDown3,UpSamp2],axis=-1)#(UpSamp2)\n",
    "Conv2   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge2)\n",
    "Lr7  = keras.layers.LeakyReLU(alpha=0.0)(Conv2)\n",
    "#16\n",
    "UpSamp3 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr7)\n",
    "\n",
    "#32\n",
    "Conv3   = keras.layers.Conv2D(filters=16,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp3)\n",
    "Lr8  = keras.layers.LeakyReLU(alpha=0.0)(Conv3)\n",
    "\n",
    "UpSamp4 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr8)\n",
    "#64\n",
    "Conv4   = keras.layers.Conv2D(filters=8,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'relu')(UpSamp4)\n",
    "\n",
    "Conv5   = keras.layers.Conv2D(filters=1,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'elu')(Conv4)\n",
    "\n",
    "model2 = keras.models.Model(inputs=init, outputs=Conv5)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "model2.compile(optimizer=tf.train.AdamOptimizer(learning_rate = 0.0001),loss='mean_squared_error', metrics=[src.relative_error_tensor]) \n",
    "model2.fit(unet_train,\n",
    "          unet_truth,\n",
    "          batch_size = 100,\n",
    "          epochs=50,\n",
    "          validation_data=(unet_val,unet_val_truth),\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model2.history\n",
    "hist.history.keys()\n",
    "plt.plot(hist.history['loss'],)\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig('training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "predictions = model2.predict(unet_test, batch_size=100)\n",
    "truth       = unet_test_truth\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(truth, predictions)\n",
    "args[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(truth,predictions, metric=\"relative_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src.result_plotter(args[:10], (unet_test[:,:,:,0], truth[:,:,:,0], predictions[:,:,:,0], error_images[:,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 32, 32)   544         input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_244 (LeakyReLU)     (None, 32, 32, 32)   0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   32832       leaky_re_lu_244[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_245 (LeakyReLU)     (None, 16, 16, 64)   0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 128)    131200      leaky_re_lu_245[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_246 (LeakyReLU)     (None, 8, 8, 128)    0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 4, 4, 256)    524544      leaky_re_lu_246[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_247 (LeakyReLU)     (None, 4, 4, 256)    0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 2, 2, 256)    1048832     leaky_re_lu_247[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_248 (LeakyReLU)     (None, 2, 2, 256)    0           conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_54 (Conv2DTran (None, 4, 4, 256)    1048832     leaky_re_lu_248[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_249 (LeakyReLU)     (None, 4, 4, 256)    0           conv2d_transpose_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 4, 4, 512)    0           conv2d_209[0][0]                 \n",
      "                                                                 leaky_re_lu_249[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_55 (Conv2DTran (None, 8, 8, 128)    1048704     concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_250 (LeakyReLU)     (None, 8, 8, 128)    0           conv2d_transpose_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 8, 8, 256)    0           conv2d_208[0][0]                 \n",
      "                                                                 leaky_re_lu_250[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_56 (Conv2DTran (None, 16, 16, 64)   262208      concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_251 (LeakyReLU)     (None, 16, 16, 64)   0           conv2d_transpose_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 16, 16, 128)  0           conv2d_207[0][0]                 \n",
      "                                                                 leaky_re_lu_251[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_57 (Conv2DTran (None, 32, 32, 32)   65568       concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_252 (LeakyReLU)     (None, 32, 32, 32)   0           conv2d_transpose_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 32, 32, 64)   0           conv2d_206[0][0]                 \n",
      "                                                                 leaky_re_lu_252[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_58 (Conv2DTran (None, 64, 64, 1)    1025        concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_253 (LeakyReLU)     (None, 64, 64, 1)    0           conv2d_transpose_58[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 4,164,289\n",
      "Trainable params: 4,164,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def unet2(input_shape=(64, 64, 1), dropout=0.0, batchnorm=False):\n",
    "    lr = 0.1\n",
    "    \n",
    "    init = keras.layers.Input(shape=input_shape)\n",
    "    ConvDown1  = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(2,2),padding=\"same\")(init)\n",
    "    if batchnorm:\n",
    "        ConvDown1 = keras.layers.BatchNormalization()(ConvDown1)\n",
    "    Lr1 = keras.layers.LeakyReLU(alpha=lr)(ConvDown1)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr1 = keras.layers.Dropout(dropout)(Lr1)\n",
    "    #32\n",
    "    ConvDown2  = keras.layers.Conv2D(filters=64,kernel_size=(4,4),strides=(2,2),padding=\"same\")(Lr1)\n",
    "    if batchnorm:\n",
    "        ConvDown2 = keras.layers.BatchNormalization()(ConvDown2)\n",
    "    Lr2 = keras.layers.LeakyReLU(alpha=lr)(ConvDown2)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr2 = keras.layers.Dropout(dropout)(Lr2)\n",
    "    #16\n",
    "    ConvDown3  = keras.layers.Conv2D(filters=128,kernel_size=(4,4),strides=(2,2),padding=\"same\")(Lr2)\n",
    "    if batchnorm:\n",
    "        ConvDown3 = keras.layers.BatchNormalization()(ConvDown3)\n",
    "    Lr3 = keras.layers.LeakyReLU(alpha=lr)(ConvDown3)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr3 = keras.layers.Dropout(dropout)(Lr3)\n",
    "    #8\n",
    "    ConvDown4  = keras.layers.Conv2D(filters=256,kernel_size=(4,4),strides=(2,2),padding=\"same\")(Lr3)\n",
    "    if batchnorm:\n",
    "        ConvDown4 = keras.layers.BatchNormalization()(ConvDown4)\n",
    "    Lr4 = keras.layers.LeakyReLU(alpha=lr)(ConvDown4)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr4 = keras.layers.Dropout(dropout)(Lr4)\n",
    "    #4\n",
    "    ConvDown5  = keras.layers.Conv2D(filters=256,kernel_size=(4,4),strides=(2,2),padding=\"same\")(Lr4)\n",
    "    if batchnorm:\n",
    "        ConvDown5 = keras.layers.BatchNormalization()(ConvDown5)\n",
    "    Lr5 = keras.layers.LeakyReLU(alpha=lr)(ConvDown5)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr5 = keras.layers.Dropout(dropout)(Lr5)\n",
    "    #2\n",
    "    \n",
    "    UpConv1 = keras.layers.Conv2DTranspose(filters=256,kernel_size=(4,4),strides=(2,2),padding=\"same\")(Lr5)\n",
    "    if batchnorm:\n",
    "        UpConv1 = keras.layers.BatchNormalization()(UpConv1)\n",
    "    Lr6 = keras.layers.LeakyReLU(alpha=lr)(UpConv1)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr6 = keras.layers.Dropout(dropout)(Lr6)\n",
    "    merge1  = keras.layers.concatenate([ConvDown4,Lr6],axis=-1)\n",
    "    #4\n",
    "    UpConv2 = keras.layers.Conv2DTranspose(filters=128,kernel_size=(4,4),strides=(2,2),padding=\"same\")(merge1)\n",
    "    if batchnorm:\n",
    "        UpConv2 = keras.layers.BatchNormalization()(UpConv2)\n",
    "    Lr7  = keras.layers.LeakyReLU(alpha=lr)(UpConv2)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr7 = keras.layers.Dropout(dropout)(Lr7)\n",
    "    merge2  = keras.layers.concatenate([ConvDown3,Lr7],axis=-1)\n",
    "    #8\n",
    "    UpConv3 = keras.layers.Conv2DTranspose(filters=64,kernel_size=(4,4),strides=(2,2),padding=\"same\")(merge2)\n",
    "    if batchnorm:\n",
    "        UpConv3 = keras.layers.BatchNormalization()(UpConv3)\n",
    "    Lr8  = keras.layers.LeakyReLU(alpha=lr)(UpConv3)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr8 = keras.layers.Dropout(dropout)(Lr8)\n",
    "    merge3  = keras.layers.concatenate([ConvDown2,Lr8],axis=-1)\n",
    "    #16\n",
    "    UpConv4 = keras.layers.Conv2DTranspose(filters=32,kernel_size=(4,4),strides=(2,2),padding=\"same\")(merge3)\n",
    "    if batchnorm:\n",
    "        UpConv4 = keras.layers.BatchNormalization()(UpConv4)\n",
    "    Lr9  = keras.layers.LeakyReLU(alpha=lr)(UpConv4)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr9 = keras.layers.Dropout(dropout)(Lr9)\n",
    "    merge4  = keras.layers.concatenate([ConvDown1,Lr9],axis=-1)\n",
    "    #32\n",
    "    UpConv5 = keras.layers.Conv2DTranspose(filters=1,kernel_size=(4,4),strides=(2,2),padding=\"same\")(merge4)\n",
    "    if batchnorm:\n",
    "        UpConv5 = keras.layers.BatchNormalization()(UpConv5)\n",
    "    Lr10  = keras.layers.LeakyReLU(alpha=lr)(UpConv5)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr10 = keras.layers.Dropout(dropout)(Lr10)\n",
    "    #64\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=Lr10)\n",
    "unet2().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
