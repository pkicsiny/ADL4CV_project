{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get rain data and visualise for overview <font color='orange'>&#9728;</font>\n",
    "- cut and split data to reasonable train, val, test sets <font color='orange'>&#9728;</font>\n",
    "- set up first generator and discriminator and overfit, play around with it, get first results (_November/December_)\n",
    "- train on small training set and improve losses, accuracy, results (_December_)\n",
    "- experiment with temporal discriminator (_December/January_)\n",
    "- experiment with wind data (_January_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data/rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6244223089538191133\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1508248780\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15382331021144768737\n",
      "physical_device_desc: \"device: 0, name: GeForce GT 740M, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization, TimeDistributed, LSTM\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" for CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rain measurements\n",
    "Measurements are downloaded from the DWD (German weather service) open data server: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/__<br>\n",
    "I'm working with the data of August 2010 (based on [this](https://tradingeconomics.com/germany/precipitation)), so I have downloaded this: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/2010/RW-201008.tar__<br>\n",
    "_DWD manual:_<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/BESCHREIBUNG_gridsgermany_hourly_radolan_historical_asc_de.pdf__<br><br>\n",
    "This contains radar maps recorded in every hour. Each map has a resolution of $900\\times900$ pixels and each pixel corresponds to an $1\\,km\\times1\\,km$ area in reality. Pixel values are the precipitation height in $0.1\\,mm$.\n",
    "Below I'm importing the data of this as a series of numpy arrays and plot them to see the acual radar map. The _sys.path[0]_ is the path on my computer and it can be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"../data/rx\")\n",
    "total_length = len(files)\n",
    "inputs = np.zeros((total_length,900,900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, file in enumerate(files):\n",
    "    if i%10 == 0:\n",
    "        print(i, end=\", \")\n",
    "    with open(sys.path[0] + '/' + file, \"rb\") as f:\n",
    "        byte = f.read()\n",
    "        start = 0\n",
    "        for j in range(len(byte)) :\n",
    "            if byte[j] == 62 :\n",
    "                start = j\n",
    "                break\n",
    "        inputs[i] = np.flip(np.reshape(np.asarray([c for c in byte[start+3:]]),(900,900)), axis=0)\n",
    "        inputs[i][inputs[i] == 250] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inputs[0][500:564,600:664]/inputs[0][500:564,600:664].max())\n",
    "plt.colorbar()\n",
    "plt.savefig(\"2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = src.generate_datasets(inputs, n=10000, size=64, length=2, normalize=True, split=(6,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(sys.path[0]+\"/5_minute.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (6000, 2, 64, 64, 1)\n",
      "Validation data: (2000, 2, 64, 64, 1)\n",
      "Test data: (2000, 2, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "#low_res_train = images[\"low_res_train\"]\n",
    "#low_res_xval = images[\"low_res_xval\"]\n",
    "#low_res_test = images[\"low_res_test\"]\n",
    "#overfit = np.reshape(images['images'],np.shape(images['images'])+(1,))\n",
    "train = np.reshape(images[\"train\"],np.shape(images[\"train\"])+(1,))\n",
    "xval = np.reshape(images[\"xval\"],np.shape(images[\"xval\"])+(1,))\n",
    "test = np.reshape(images[\"test\"],np.shape(images[\"test\"])+(1,))\n",
    "print(f\"Training data: {train.shape}\\nValidation data: {xval.shape}\\nTest data: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 64, 64, 1) \n",
      " (6000, 1, 64, 64, 1) \n",
      " (2000, 1, 64, 64, 1) \n",
      " (2000, 1, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "lstm_train     = np.reshape(train[:,0,:,:,:],((train.shape[0],1,)+train.shape[2:]))\n",
    "lstm_truth     = np.reshape(train[:,1,:,:,:],((train.shape[0],1,)+train.shape[2:]))\n",
    "lstm_val       = np.reshape(xval[:,0,:,:,:],((xval.shape[0],1,)+xval.shape[2:]))\n",
    "lstm_val_truth = np.reshape(xval[:,1,:,:,:],((xval.shape[0],1,)+xval.shape[2:]))\n",
    "print(lstm_train.shape,\"\\n\",lstm_truth.shape,\"\\n\",lstm_val.shape,\"\\n\",lstm_val_truth.shape)\n",
    "lstm_test      = np.reshape(test[:,0,:,:,:],((test.shape[0],1,)+test.shape[2:]))\n",
    "lstm_test_truth = np.reshape(test[:,1,:,:,:],((test.shape[0],1,)+test.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_train = np.reshape(train[5,0,:,:,:],((1,1,)+train.shape[2:]))\n",
    "overfit_truth = np.reshape(train[5,1,:,:,:],((1,1,)+train.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.visualise_data(xval[:,:,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 1, 32, 32, 8)      208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 32, 32, 8)      32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 32, 32, 8)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 1, 16, 16, 16)     3216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 16, 16, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 16, 16, 16)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 1, 8, 8, 32)       12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 8, 8, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 8, 8, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 1, 4, 4, 64)       51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 4, 4, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1, 4, 4, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 1, 1, 1, 128)      204928    \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1, 128)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 1, 4, 4, 64)       204864    \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 1, 8, 8, 32)       51232     \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 1, 16, 16, 16)     12816     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 1, 32, 32, 8)      3208      \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 1, 64, 64, 1)      201       \n",
      "=================================================================\n",
      "Total params: 676,833\n",
      "Trainable params: 676,593\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#batch_size=10\n",
    "lstm_model = keras.Sequential()\n",
    "# define CNN model\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=8, kernel_size=5, strides=2, padding='same'))) #8\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=16, kernel_size=5, strides=2, padding='same')))\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=32, kernel_size=5, strides=2, padding='same')))\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=5, strides=2, padding='same')))\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=128, kernel_size=5, strides=4, padding='same', activation='tanh')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "\n",
    "#LSTM\n",
    "lstm_model.add(keras.layers.LSTM(units=128, return_sequences=True))\n",
    "\n",
    "#upconv\n",
    "lstm_model.add(keras.layers.Reshape((1,1,1,128)))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=64,kernel_size=5,strides=4,padding='same', activation='relu'))) #64\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=32,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=16,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=8,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=1,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "\n",
    "lstm_model.build((None,1,)+train.shape[2:])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
    "            keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    return keras.losses.mean_squared_error(y_true, y_pred) + src.gradient_diff(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"metrics/relative_error_tensor/truediv:0\", shape=(), dtype=float32)\n",
      "Tensor(\"time_distributed_11_target:0\", shape=(?, ?, ?, ?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer=tf.train.AdamOptimizer(learning_rate = 0.0001),loss=\"mean_squared_error\", metrics=[src.relative_error_tensor]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/150\n",
      "6000/6000 [==============================] - 12s 2ms/step - loss: 0.2292 - relative_error_tensor: 0.9925 - val_loss: 0.1922 - val_relative_error_tensor: 0.9660\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 2/150\n",
      "6000/6000 [==============================] - 10s 2ms/step - loss: 0.1291 - relative_error_tensor: 0.8437 - val_loss: 0.1118 - val_relative_error_tensor: 0.8059\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 3/150\n",
      "6000/6000 [==============================] - 13s 2ms/step - loss: 0.0944 - relative_error_tensor: 0.7466 - val_loss: 0.0862 - val_relative_error_tensor: 0.7201\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 4/150\n",
      "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0759 - relative_error_tensor: 0.6500 - val_loss: 0.0761 - val_relative_error_tensor: 0.6613\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 5/150\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0704 - relative_error_tensor: 0.6139 - val_loss: 0.0693 - val_relative_error_tensor: 0.6296\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 6/150\n",
      "6000/6000 [==============================] - 21s 3ms/step - loss: 0.0665 - relative_error_tensor: 0.5928 - val_loss: 0.0648 - val_relative_error_tensor: 0.6042\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 7/150\n",
      "6000/6000 [==============================] - 21s 4ms/step - loss: 0.0612 - relative_error_tensor: 0.5646 - val_loss: 0.0594 - val_relative_error_tensor: 0.5647\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 8/150\n",
      "6000/6000 [==============================] - 23s 4ms/step - loss: 0.0579 - relative_error_tensor: 0.5423 - val_loss: 0.0580 - val_relative_error_tensor: 0.5502\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 9/150\n",
      "6000/6000 [==============================] - 23s 4ms/step - loss: 0.0555 - relative_error_tensor: 0.5250 - val_loss: 0.0548 - val_relative_error_tensor: 0.5266\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 10/150\n",
      "6000/6000 [==============================] - 23s 4ms/step - loss: 0.0538 - relative_error_tensor: 0.5131 - val_loss: 0.0528 - val_relative_error_tensor: 0.5112\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 11/150\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 0.0521 - relative_error_tensor: 0.5000 - val_loss: 0.0508 - val_relative_error_tensor: 0.4982\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 12/150\n",
      "6000/6000 [==============================] - 27s 4ms/step - loss: 0.0499 - relative_error_tensor: 0.4860 - val_loss: 0.0494 - val_relative_error_tensor: 0.4859\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 13/150\n",
      "6000/6000 [==============================] - 23s 4ms/step - loss: 0.0479 - relative_error_tensor: 0.4704 - val_loss: 0.0474 - val_relative_error_tensor: 0.4665\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 14/150\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.0468 - relative_error_tensor: 0.4607 - val_loss: 0.0464 - val_relative_error_tensor: 0.4590\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 15/150\n",
      "6000/6000 [==============================] - 30s 5ms/step - loss: 0.0460 - relative_error_tensor: 0.4532 - val_loss: 0.0456 - val_relative_error_tensor: 0.4500\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 16/150\n",
      "6000/6000 [==============================] - 26s 4ms/step - loss: 0.0450 - relative_error_tensor: 0.4453 - val_loss: 0.0447 - val_relative_error_tensor: 0.4443\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 17/150\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.0440 - relative_error_tensor: 0.4371 - val_loss: 0.0439 - val_relative_error_tensor: 0.4371\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Epoch 18/150\n",
      "5000/6000 [========================>.....] - ETA: 3s - loss: 0.0434 - relative_error_tensor: 0.4321"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "lstm_model.fit(lstm_train, lstm_truth,\n",
    "               validation_data=(lstm_val, lstm_val_truth),\n",
    "               batch_size = 100,\n",
    "               epochs=150,\n",
    "               callbacks=callback,\n",
    "               shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-58b36f0dee0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lstm_model' is not defined"
     ]
    }
   ],
   "source": [
    "hist = lstm_model.history\n",
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'],)\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig('training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "predictions = lstm_model.predict(lstm_test, batch_size=50)\n",
    "truth       = lstm_test_truth\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = src.arg_getter(truth, predictions)\n",
    "args[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = error_distribution(truth,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_distribution(truth, predictions, nbins=20, metric=\"difference\"):\n",
    "    \"\"\"\n",
    "    plot relative error dist. of results\n",
    "    :param truth: ground truth\n",
    "    :param predictions: predictions of network\n",
    "    :param metric: difference or relative_error\n",
    "    :return: nothing (plots relative error distributions)\n",
    "    \"\"\"\n",
    "\n",
    "    if metric == \"relative_error\":\n",
    "        error_images, error_vals, error_means = src.relative_error(truth, predictions)\n",
    "    elif metric == \"difference\":\n",
    "        error_images, error_vals, error_means = src.difference(truth, predictions)\n",
    "    else:\n",
    "        sys.exit(\"Metric must be 'difference' or 'relative_error'.\")\n",
    "\n",
    "    plt.hist(error_vals, nbins)\n",
    "    plt.xlabel(f\"{metric}\")\n",
    "    plt.ylabel('count')\n",
    "    plt.title('mean = ' + str(np.mean(error_vals))[0:5] + ', min = ' + str(np.min(error_vals))[0:5] + ', max = ' + str(\n",
    "        np.max(error_vals))[0:5])\n",
    "    plt.yticks(list(set([int(tick) for tick in plt.yticks()[0]])))\n",
    "    plt.savefig(f\"{metric}.png\")\n",
    "    plt.show()\n",
    "    return error_images, error_vals, error_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src.result_plotter([0], (lstm_test[:,:,:,:,0], truth[:,:,:,:,0], predictions[:,:,:,:,0], error_images[:,:,:,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D = keras.Sequential()\n",
    "depth = 2\n",
    "dropout = 0.4\n",
    "\n",
    "conv1 = keras.layers.Conv2D(filters=depth*1 ,kernel_size=10, strides=5, input_shape=(900,900,1), padding='same')\n",
    "relu1 = keras.layers.LeakyReLU(alpha=0.2)\n",
    "dropout1 = keras.layers.Dropout(dropout)\n",
    "\n",
    "conv2 = keras.layers.Conv2D(filters=depth*2, kernel_size=10, strides=5, padding='same')\n",
    "relu2 = keras.layers.LeakyReLU(alpha=0.2)\n",
    "dropout2 = keras.layers.Dropout(dropout)\n",
    "\n",
    "conv3 = keras.layers.Conv2D(filters=depth*4, kernel_size=6, strides=2, padding='same')\n",
    "relu3 = keras.layers.LeakyReLU(alpha=0.2)\n",
    "dropout3 = keras.layers.Dropout(dropout)\n",
    "\n",
    "conv4 = keras.layers.Conv2D(filters=depth*8, kernel_size=2, strides=2, padding='same')\n",
    "relu4 = keras.layers.LeakyReLU(alpha=0.2)\n",
    "dropout4 = keras.layers.Dropout(dropout)\n",
    "\n",
    "# Out: 1-dim probability\n",
    "flatten = keras.layers.Flatten()\n",
    "fcl1 = keras.layers.Dense(1)\n",
    "sig1 = keras.layers.Activation('sigmoid')\n",
    "#summary()\n",
    "D.add(conv1)\n",
    "D.add(relu1)\n",
    "D.add(dropout1)\n",
    "D.add(conv2)\n",
    "D.add(relu2)\n",
    "D.add(dropout2)\n",
    "D.add(conv3)\n",
    "D.add(relu3)\n",
    "D.add(dropout3)\n",
    "D.add(conv4)\n",
    "D.add(relu4)\n",
    "D.add(dropout4)\n",
    "D.add(flatten)\n",
    "D.add(fcl1)\n",
    "D.add(sig1)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.0001, decay=3e-8)\n",
    "AM = keras.Sequential()\n",
    "AM.add(G)\n",
    "AM.add(D)\n",
    "AM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM.fit(train_val_inputs,\n",
    "          train_val_targets,\n",
    "          batch_size = 50,\n",
    "          epochs=50,\n",
    "          validation_split = 0.1,\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train[0,0,:,:,0]\n",
    "b = train[0,1,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((a-b)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((a-b)**2).sum()/64/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.sum(np.abs(np.abs(a[1:,:]-a[:-1,:])-np.abs(b[1:,:]-b[:-1,:])))+np.sum(np.abs(np.abs(a[:,1:]-a[:,:-1])-np.abs(b[:,1:]-b[:,:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f/64/63/2-summe/(len(bb)+len(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.abs(np.abs(a[1:,:]-a[:-1,:])-np.abs(b[1:,:]-b[:-1,:])).flatten()\n",
    "bb = np.abs(np.abs(a[:,1:]-a[:,:-1])-np.abs(b[:,1:]-b[:,:-1])).flatten()\n",
    "summe = np.sum(aa+bb)/(len(bb)+len(aa))\n",
    "summe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summe = np.sum(aa+bb)\n",
    "summe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summe/(len(bb)+len(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrue = K.variable(a.reshape(1,1,64,64,1))\n",
    "yPred =  K.variable(b.reshape(1,1,64,64,1))\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = K.pow(K.flatten(K.abs(K.abs(yTrue[:,:,1:,:,:] - yTrue[:,:,:-1,:,:]) -\n",
    "                                 K.abs(yPred[:,:,1:,:,:] - yPred[:,:,:-1,:,:]))),alpha)\n",
    "pred = K.pow(K.flatten(K.abs(K.abs(yTrue[:,:,:,1:,:] - yTrue[:,:,:,:-1,:]) -\n",
    "                                 K.abs(yPred[:,:,:,1:,:] - yPred[:,:,:,:-1,:]))),alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = (K.eval(K.sum(true))+K.eval(K.sum(pred))) / tf.to_float(K.shape(true)[0] + K.shape(pred)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.int_shape(true)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.count_params(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(K.shape(vv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
