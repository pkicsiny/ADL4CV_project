{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(epoch, gan_test, gan_test_truth, past_input):\n",
    "    n = 5\n",
    "    test_batch = gan_test[:n]\n",
    "    test_truth = gan_test_truth[:n]\n",
    "    gen_imgs = generator.predict(test_batch)\n",
    "    plot_range = past_input \n",
    "    fig, axs = plt.subplots(n, plot_range+2, figsize=(16, 16))\n",
    "    for i in range(n):\n",
    "        vmax = np.max([np.max(test_batch[i]), np.max(test_truth[i])])\n",
    "        vmin = 0\n",
    "        for j in range(plot_range):\n",
    "            im = axs[i,j].imshow(test_batch[i, :,:,j], vmax=vmax,vmin=vmin)\n",
    "            axs[i,j].axis('off')\n",
    "            src.colorbar(im)\n",
    "            axs[i,j].set_title(\"Frame t\"+str([-past_input+1+j if j < past_input-1 else \"\"][0]))\n",
    "        im2 = axs[i,-2].imshow(test_truth[i, :,:,0], vmax=vmax, vmin=vmin)\n",
    "        axs[i,-2].axis('off')\n",
    "        src.colorbar(im2)                \n",
    "        axs[i,-2].set_title(\"Frame t+1\")\n",
    "        im3 = axs[i,-1].imshow(gen_imgs[i, :,:,0], vmax=vmax, vmin=vmin)\n",
    "        axs[i,-1].axis('off')\n",
    "        src.colorbar(im3)\n",
    "        axs[i,-1].set_title(\"Prediction t+1\")\n",
    "    fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(past_frames=past)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to inputs and ground truth images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth = src.split_datasets(\n",
    "            train[:2000], xval, test, past_frames=past, augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make discriminator labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial ground truths\n",
    "real = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "#Generator ground truths\n",
    "g_real = np.ones((batch_size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make generator but don't compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = src.unet(gan_train.shape[1:], dropout=0, batchnorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make discriminator and compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = src.spatial_discriminator(condition_shape=gan_train.shape[1:], dropout = 0.25, batchnorm=True)\n",
    "discriminator.compile(loss=keras.losses.binary_crossentropy,optimizer=keras.optimizers.SGD(),\n",
    "                      metrics=[keras.metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and outputs of the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_t = keras.layers.Input(shape=gan_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = generator(frame_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = discriminator([frame_t, generated])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze discriminator weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights=[0.1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = keras.models.Model(inputs=[frame_t], outputs=[generated, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined.compile(loss=[src.custom_loss(loss=\"l1\"), keras.losses.binary_crossentropy], optimizer=keras.optimizers.Adam(0.0002, 0.5),\n",
    "                 loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log = {\"g_loss\":[],\n",
    "               \"d_loss\":[],\n",
    "               \"g_metric\":[],\n",
    "               \"d_metric\":[],\n",
    "      \"d_loss_real\":[],\n",
    "      \"d_loss_fake\":[],\n",
    "      \"d_test_real\":[],\n",
    "      \"d_test_fake\":[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train x epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    discriminator.trainable = True\n",
    "    idx = np.random.randint(0, gan_truth.shape[0], batch_size)\n",
    "    real_imgs = gan_truth[idx]\n",
    "    training_batch = gan_train[idx]\n",
    "        \n",
    "    generated_imgs = generator.predict(training_batch) \n",
    "    d_loss_real = discriminator.train_on_batch([training_batch, real_imgs], real)\n",
    "    d_loss_fake = discriminator.train_on_batch([training_batch, generated_imgs], fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "     #for l in discriminator.layers:\n",
    "     #   weights = l.get_weights()\n",
    "     #   weights = [np.clip(w, -clip_value, clip_value) for w in weights] \n",
    "     #   l.set_weights(weights)\n",
    "    \n",
    "    #d_test_real = discriminator.predict([training_batch, real_imgs])\n",
    "    #d_test_fake = discriminator.predict([training_batch, generated_imgs])\n",
    "    discriminator.trainable = False    \n",
    "    idx = np.random.randint(0, gan_train.shape[0], batch_size)\n",
    "    training_batch = gan_train[idx]\n",
    "    training_truth = gan_truth[idx]\n",
    "    \n",
    "    g_loss = combined.train_on_batch(training_batch, [training_truth, g_real])\n",
    "    \n",
    "    if g_loss[1] < 0.12 and loss_weights[0] > 2**(-1):\n",
    "        loss_weights[0] /= 2\n",
    "        combined.compile(loss=[src.custom_loss(loss=\"l1\"), keras.losses.binary_crossentropy], optimizer=keras.optimizers.Adam(0.0002, 0.5),\n",
    "                 loss_weights=loss_weights)\n",
    "    \n",
    "    log[\"g_loss\"].append(g_loss)\n",
    "    log[\"d_loss_real\"].append(d_loss_real[0])\n",
    "    log[\"d_loss_fake\"].append(d_loss_fake[0])\n",
    "    #log[\"d_test_real\"].append(d_test_real)\n",
    "    #log[\"d_test_fake\"].append(d_test_fake)\n",
    "    log[\"d_loss\"].append(d_loss[0])\n",
    "    log[\"d_metric\"].append(d_loss[1])\n",
    "    print(f\"\\033[1m {epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\\033[0m\"+\n",
    "                  f\"\\033[1m[G loss: {g_loss[0]}, G obj.: {g_loss[1]}, G bce.: {g_loss[2]}]\\033[0m\")\n",
    "    print(f\"real loss: {d_loss_real}, fake loss: {d_loss_fake}\")\n",
    "    #print(f\"test real acc.: {np.mean(d_test_real)}, test fake acc.: {np.mean(d_test_fake)}\")\n",
    "    if epoch%10 == 0:\n",
    "        sample_images(epoch, gan_test, gan_test_truth, past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(log[\"g_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx, vy = src.optical_flow(gan_train[:,:,:,-2:-1], gan_train[:,:,:,-1:], window_size=4, tau=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "plt.plot(np.array(log[\"g_loss\"])[:,0], alpha=0.3,c=\"b\")\n",
    "plt.plot(np.array(log[\"d_loss\"]),alpha=0.3, c=\"orange\")\n",
    "\n",
    "plt.plot(np.array(log[\"g_loss\"])[:,1], alpha=0.9,c=\"green\", label=\"L1 objective\")\n",
    "\n",
    "plt.plot(src.smooth(np.array(log[\"g_loss\"])[:,0]),c=\"b\", label=\"generator\")\n",
    "plt.plot(src.smooth(np.array(log[\"d_loss\"])),c=\"orange\", label=\"discriminator\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"sGAN_training_curves_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Save network weights and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_params(name, model, log, scores):\n",
    "    for key in list(scores.keys()):\n",
    "        log[key] = scores[key]\n",
    "    np.save(\"C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/ADL4CV_project/trainings/\"+name+\"/\"+name, log) \n",
    "    model.save_weights(\"C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/ADL4CV_project/trainings/\"+name+\"/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"sgan_4-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = generator.predict(gan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = src.calculate_skill_scores(predictions, gan_test_truth, gan_test, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_params(name, combined, log, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = np.concatenate((gan_test[:,:,:,1:],predictions),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions = generator.predict(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_predictions[0,:,:,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[\"corr_to_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[\"corr_to_input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "plt.imshow(predictions[0,:,:,0], vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "plt.imshow(gan_test_truth[0,:,:,0], vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = src.calculate_skill_scores(predictions, gan_test_truth, gan_test, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[\"corr_to_input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[\"corr_to_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[\"csi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[\"far\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[\"pod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    \"\"\"Calculates the Wasserstein loss for a sample batch.\n",
    "    The Wasserstein loss function is very simple to calculate. In a standard GAN, the discriminator\n",
    "    has a sigmoid output, representing the probability that samples are real or generated. In Wasserstein\n",
    "    GANs, however, the output is linear with no activation function! Instead of being constrained to [0, 1],\n",
    "    the discriminator wants to make the distance between its output for real and generated samples as large as possible.\n",
    "    The most natural way to achieve this is to label generated samples -1 and real samples 1, instead of the\n",
    "    0 and 1 used in normal GANs, so that multiplying the outputs by the labels will give you the loss immediately.\n",
    "    Note that the nature of this loss means that it can be (and frequently will be) less than 0.\"\"\"\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_d_labels(real, fake):\n",
    "    # idea: https://arxiv.org/pdf/1606.03498.pdf\n",
    "    batch_size = len(real)\n",
    "    five_percent = int(0.05*batch_size)\n",
    "    idx = np.random.randint(0, batch_size, five_percent)\n",
    "    d_real = np.ones_like(real)\n",
    "    d_fake = np.zeros_like(fake)\n",
    "    d_real[idx] = 0\n",
    "    d_fake[idx] = 1\n",
    "    return d_real, d_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
