{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 20421901557549322\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "from os import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "#forces CPU usage\n",
    "environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rain measurements\n",
    "Measurements are downloaded from the DWD (German weather service) open data server: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/__<br>\n",
    "I'm working with the data of August 2010 (based on [this](https://tradingeconomics.com/germany/precipitation)), so I have downloaded this: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/2010/RW-201008.tar__<br>\n",
    "_DWD manual:_<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/BESCHREIBUNG_gridsgermany_hourly_radolan_historical_asc_de.pdf__<br><br>\n",
    "This contains radar maps recorded in every hour. Each map has a resolution of $900\\times900$ pixels and each pixel corresponds to an $1\\,km\\times1\\,km$ area in reality. Pixel values are the precipitation height in $0.1\\,mm$.\n",
    "Below I'm importing the data of this as a series of numpy arrays and plot them to see the acual radar map. The _sys.path[0]_ is the path on my computer and it can be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(\"5min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_train     = np.reshape(train[:,0,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "unet_truth     = np.reshape(train[:,1,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "unet_val       = np.reshape(xval[:,0,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "unet_val_truth = np.reshape(xval[:,1,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "print(unet_train.shape,\"\\n\",unet_truth.shape,\"\\n\",unet_val.shape,\"\\n\",unet_truth.shape)\n",
    "unet_test      = np.reshape(test[:,0,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "unet_test_truth = np.reshape(test[:,1,:,:,:],((test.shape[0],)+test.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(unet_test[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_train = np.reshape(train[5,0,:,:,:],((1,)+train.shape[2:]))\n",
    "overfit_truth = np.reshape(train[5,1,:,:,:],((1,)+train.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.visualise_data(xval[:,:,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model2=keras.Sequential()\n",
    "def unet():\n",
    "    init       = keras.layers.Input(shape=(64,64,1))\n",
    "    ConvDown1  = keras.layers.Conv2D(filters=8,kernel_size=(2,2),strides=(1,1),padding=\"same\")(init)\n",
    "    Lr1        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown1)\n",
    "    #64\n",
    "    ConvDown2  = keras.layers.Conv2D(filters=16,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr1)\n",
    "    Lr2        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown2)\n",
    "    #32\n",
    "    ConvDown3  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr2)\n",
    "    Lr3        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown3)\n",
    "    #16\n",
    "    ConvDown4  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr3)\n",
    "    Lr4        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown4)\n",
    "    #8\n",
    "    ConvDown5  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr4)\n",
    "    Lr5        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown5)\n",
    "    #4\n",
    "\n",
    "    UpSamp1 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr5)\n",
    "    #8\n",
    "    merge1  = keras.layers.concatenate([ConvDown4,UpSamp1],axis=-1)#(UpSamp1)\n",
    "    Conv1   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge1)\n",
    "    Lr6     = keras.layers.LeakyReLU(alpha=0.1)(Conv1)\n",
    "    #8\n",
    "    UpSamp2 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr6)\n",
    "    #16\n",
    "    merge2  = keras.layers.concatenate([ConvDown3,UpSamp2],axis=-1)#(UpSamp2)\n",
    "    Conv2   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge2)\n",
    "    Lr7     = keras.layers.LeakyReLU(alpha=0.1)(Conv2)\n",
    "    #16\n",
    "    UpSamp3 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr7)\n",
    "\n",
    "    #32\n",
    "    Conv3   = keras.layers.Conv2D(filters=16,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp3)\n",
    "    Lr8     = keras.layers.LeakyReLU(alpha=0.1)(Conv3)\n",
    "\n",
    "    UpSamp4 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr8)\n",
    "    #64\n",
    "    Conv4   = keras.layers.Conv2D(filters=8,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp4)\n",
    "    Lr9     = keras.layers.LeakyReLU(alpha=0.1)(Conv4)\n",
    "    \n",
    "    Conv5   = keras.layers.Conv2D(filters=1,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'tanh')(Lr9)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=Conv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ds = keras.Sequential()\n",
    "def spatial_discriminator():\n",
    "    dropout = 0.5\n",
    "    init = keras.layers.Input(shape=(64,64,1))\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=4 ,kernel_size=4, strides=2, padding='same')(init)\n",
    "    relu1 = keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    dropout1 = keras.layers.Dropout(dropout)(relu1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=8, kernel_size=4, strides=2, padding='same')(dropout1)\n",
    "    relu2 = keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    dropout2 = keras.layers.Dropout(dropout)(relu2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv2D(filters=16, kernel_size=4, strides=2, padding='same')(dropout2)\n",
    "    relu3 = keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    dropout3 = keras.layers.Dropout(dropout)(relu3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(dropout3)\n",
    "    relu4 = keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    dropout4 = keras.layers.Dropout(dropout)(relu4)\n",
    "    \n",
    "    # Out: 1-dim probability\n",
    "    flatten = keras.layers.Flatten()(dropout4)\n",
    "    fcl1 = keras.layers.Dense(1)(flatten)\n",
    "    sig1 = keras.layers.Activation('sigmoid')(fcl1)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def temporal_discriminator():\n",
    "    dropout = 0.5\n",
    "    init = keras.layers.Input(shape=(2,64,64,3)) # t - 1, t\n",
    "    advected = np.array(advect(init[0]),init[1])\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=4 ,kernel_size=4, strides=2, padding='same')(advected)\n",
    "    relu1 = keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    dropout1 = keras.layers.Dropout(dropout)(relu1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=8, kernel_size=4, strides=2, padding='same')(dropout1)\n",
    "    relu2 = keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    dropout2 = keras.layers.Dropout(dropout)(relu2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv2D(filters=16, kernel_size=4, strides=2, padding='same')(dropout2)\n",
    "    relu3 = keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    dropout3 = keras.layers.Dropout(dropout)(relu3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(dropout3)\n",
    "    relu4 = keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    dropout4 = keras.layers.Dropout(dropout)(relu4)\n",
    "    \n",
    "    # Out: 1-dim probability\n",
    "    flatten = keras.layers.Flatten()(dropout4)\n",
    "    fcl1 = keras.layers.Dense(1)(flatten)\n",
    "    sig1 = keras.layers.Activation('sigmoid')(fcl1)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advect(image): # (64,64,3)\n",
    "    padded = np.pad(image,(0,1),'edge')[:,:,:-1]\n",
    "    advected = np.empty_like(image)\n",
    "    advected[:,:,0] = image[:,:,0] + image[:,:,1]*(padded[1:,:,0] - padded[:-1,:,0])[:,:-1] + image[:,:,2]*(padded[:,1:,0] - padded[:,:-1,0])[:-1]\n",
    "    advected[:,:,1:] = image[:,:,1:]\n",
    "    return advected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (6000, 2, 64, 64, 1)\n",
      "Validation data: (2000, 2, 64, 64, 1)\n",
      "Test data: (2000, 2, 64, 64, 1)\n",
      "Shape of training data:  (6000, 64, 64, 1) \n",
      "Shape of training truth:  (6000, 64, 64, 1) \n",
      "Shape of validation data:  (2000, 64, 64, 1) \n",
      "Shape of validation truth:  (2000, 64, 64, 1)\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.707379162311554, acc.: 32.03125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.6911827921867371, acc.: 32.8125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.6522526144981384, acc.: 42.1875]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.6135437488555908, acc.: 46.875]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.5736417770385742, acc.: 51.5625]\n",
      "\u001b[1m 0 [D loss: 0.5736417770385742, acc.: 51.5625]\u001b[0m\u001b[1m[G loss: 0.6841216087341309]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.562224268913269, acc.: 52.34375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.4934326112270355, acc.: 64.84375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.4303450286388397, acc.: 82.03125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.38647279143333435, acc.: 97.65625]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.34728795289993286, acc.: 100.0]\n",
      "\u001b[1m 1 [D loss: 0.34728795289993286, acc.: 100.0]\u001b[0m\u001b[1m[G loss: 0.7784744501113892]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.3782478868961334, acc.: 82.8125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.31958088278770447, acc.: 99.21875]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.3050585985183716, acc.: 100.0]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.29656797647476196, acc.: 99.21875]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.27812811732292175, acc.: 99.21875]\n",
      "\u001b[1m 2 [D loss: 0.27812811732292175, acc.: 99.21875]\u001b[0m\u001b[1m[G loss: 1.0006762742996216]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.2674177587032318, acc.: 98.4375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.23987247049808502, acc.: 97.65625]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.22698959708213806, acc.: 99.21875]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.20673689246177673, acc.: 98.4375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.18984980881214142, acc.: 98.4375]\n",
      "\u001b[1m 3 [D loss: 0.18984980881214142, acc.: 98.4375]\u001b[0m\u001b[1m[G loss: 1.352980375289917]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.3051658868789673, acc.: 90.625]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.1978490948677063, acc.: 96.09375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.20017600059509277, acc.: 95.3125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.19683995842933655, acc.: 96.09375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.17679864168167114, acc.: 94.53125]\n",
      "\u001b[1m 4 [D loss: 0.17679864168167114, acc.: 94.53125]\u001b[0m\u001b[1m[G loss: 1.9050177335739136]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.3993273675441742, acc.: 89.0625]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.3554055392742157, acc.: 84.375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.2642005681991577, acc.: 88.28125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.17326773703098297, acc.: 95.3125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.2021103799343109, acc.: 93.75]\n",
      "\u001b[1m 5 [D loss: 0.2021103799343109, acc.: 93.75]\u001b[0m\u001b[1m[G loss: 2.2124345302581787]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.2951938807964325, acc.: 89.0625]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.6060836911201477, acc.: 68.75]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.2957726716995239, acc.: 85.9375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.26117634773254395, acc.: 89.84375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.24529200792312622, acc.: 89.0625]\n",
      "\u001b[1m 6 [D loss: 0.24529200792312622, acc.: 89.0625]\u001b[0m\u001b[1m[G loss: 2.0200181007385254]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 1.1041759252548218, acc.: 78.125]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 1.1140742301940918, acc.: 50.0]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 1.0620949268341064, acc.: 49.21875]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 1.0647103786468506, acc.: 4.6875]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.8638396263122559, acc.: 27.34375]\n",
      "\u001b[1m 7 [D loss: 0.8638396263122559, acc.: 27.34375]\u001b[0m\u001b[1m[G loss: 0.8572052121162415]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.7737654447555542, acc.: 35.9375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 [D loss: 0.744731068611145, acc.: 46.09375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.7494322657585144, acc.: 46.09375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.7482976913452148, acc.: 43.75]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.7436814904212952, acc.: 42.96875]\n",
      "\u001b[1m 8 [D loss: 0.7436814904212952, acc.: 42.96875]\u001b[0m\u001b[1m[G loss: 0.8160195350646973]\u001b[0m\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    0 [D loss: 0.7267665863037109, acc.: 46.09375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    1 [D loss: 0.7545020580291748, acc.: 35.15625]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    2 [D loss: 0.7124227285385132, acc.: 50.0]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    3 [D loss: 0.7072962522506714, acc.: 46.09375]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "    4 [D loss: 0.7137425541877747, acc.: 46.875]\n",
      "\u001b[1m 9 [D loss: 0.7137425541877747, acc.: 46.875]\u001b[0m\u001b[1m[G loss: 0.8080849647521973]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#modified from source: https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 64\n",
    "        self.img_cols = 64\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.metric = [src.relative_error_tensor]\n",
    "\n",
    "        d_optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        g_optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=d_optimizer,\n",
    "            metrics=[\"accuracy\"])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        #self.generator.compile(loss='mse',\n",
    "        #    optimizer=g_optimizer,\n",
    "        #    metrics=self.metric)\n",
    "        \n",
    "        # The generator takes a sequence of frames as input and generates the next image in that sequence\n",
    "        input_img = keras.layers.Input(shape=self.img_shape)\n",
    "        generated = self.generator(input_img)\n",
    "        \n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.discriminator.trainable = False\n",
    "        self.combined = keras.models.Model(input_img, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=g_optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self,network=\"U-net\"):  \n",
    "        generator = keras.Sequential()\n",
    "        if network in [\"Unet\", \"U-net\", \"unet\", \"u-net\"]:\n",
    "            return unet()\n",
    "\n",
    "    def build_discriminator(self, which=\"s\"):\n",
    "        if which == \"s\":\n",
    "            return spatial_discriminator()\n",
    "        elif which == \"t\":\n",
    "            return temporal_discriminator()\n",
    "\n",
    "    def train(self, epochs, g_epochs=1, d_epochs=1, dataset=\"5min\", batch_size=128):\n",
    "\n",
    "        # Load the dataset\n",
    "        train, xval, test = src.load_datasets(dataset=dataset)\n",
    "        unet_train     = np.reshape(train[:,0,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "        unet_truth     = np.reshape(train[:,1,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "        unet_val       = np.reshape(xval[:,0,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "        unet_val_truth = np.reshape(xval[:,1,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "        print(\"Shape of training data: \",unet_train.shape,\"\\nShape of training truth: \",unet_truth.shape,\n",
    "        \"\\nShape of validation data: \",unet_val.shape,\"\\nShape of validation truth: \",unet_val_truth.shape)\n",
    "        unet_test      = np.reshape(test[:,0,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "        unet_test_truth = np.reshape(test[:,1,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        #store losses\n",
    "\n",
    "        log = {\"g_loss\":[],\n",
    "               \"d_loss\":[],\n",
    "               \"g_metric\":[],\n",
    "               \"d_metric\":[]}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            idx = np.random.randint(0, unet_truth.shape[0], batch_size)\n",
    "            real_imgs = unet_truth[idx]\n",
    "            training_batch = unet_train[idx]\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            generated_imgs = self.generator.predict(training_batch)\n",
    "\n",
    "            # Train the discriminator\n",
    "            for ks in range(d_epochs):\n",
    "                d_loss_real = self.discriminator.train_on_batch(real_imgs, real)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(generated_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                print(f\"    {ks} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\")\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            idx2 = np.random.randint(0, unet_train.shape[0], batch_size)\n",
    "            training_batch = unet_train[idx2]\n",
    "            training_truth = unet_truth[idx2]\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            for kg in range(g_epochs):\n",
    "                g_loss = self.combined.train_on_batch(training_batch, real)\n",
    "\n",
    "            # Plot the progress\n",
    "            log[\"g_loss\"].append(g_loss)\n",
    "            log[\"d_loss\"].append(d_loss[0])\n",
    "            #log[\"g_metric\"].append(g_loss[1])\n",
    "            log[\"d_metric\"].append(d_loss[1])\n",
    "            print(f\"\\033[1m {epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\\033[0m\"+\n",
    "                  f\"\\033[1m[G loss: {g_loss}]\\033[0m\")#, rel. err.: {g_loss[1]}] \\033[0m\")\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch in [int(x) for x in np.linspace(0.1,1,10)*epochs]:\n",
    "                self.sample_images(epoch, unet_test, unet_test_truth)\n",
    "        return log\n",
    "\n",
    "    def sample_images(self, epoch, unet_test, unet_test_truth):\n",
    "        n = 5\n",
    "        test_batch = unet_test[:n]\n",
    "        test_truth = unet_test_truth[:n]\n",
    "        gen_imgs = self.generator.predict(test_batch)\n",
    "\n",
    "        fig, axs = plt.subplots(n, 3, figsize=(16, 16))\n",
    "        for i in range(n):\n",
    "                axs[i,0].imshow(test_batch[i, :,:,0])\n",
    "                axs[i,0].axis('off')\n",
    "                axs[i,0].set_title(\"Frame t\")\n",
    "                axs[i,1].imshow(test_truth[i, :,:,0])\n",
    "                axs[i,1].axis('off')\n",
    "                axs[i,1].set_title(\"Frame t+1\")\n",
    "                axs[i,2].imshow(gen_imgs[i, :,:,0])\n",
    "                axs[i,2].axis('off')\n",
    "                axs[i,2].set_title(\"Prediction t+1\")\n",
    "        fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    log = gan.train(epochs=10, d_epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(16,4))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "ax.plot(log[\"g_loss\"],label=\"Generator loss\")\n",
    "ax.plot(log[\"d_loss\"],label=\"Discriminator loss\")\n",
    "ax.grid()\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(log[\"g_metric\"],label=\"Generator metric\")\n",
    "ax2.plot(log[\"d_metric\"],label=\"Discriminator metric\")\n",
    "ax2.grid()\n",
    "ax2.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
