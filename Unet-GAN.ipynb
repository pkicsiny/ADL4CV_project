{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4011377195408140155\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "from os import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "#forces CPU usage\n",
    "environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rain measurements\n",
    "Measurements are downloaded from the DWD (German weather service) open data server: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/__<br>\n",
    "I'm working with the data of August 2010 (based on [this](https://tradingeconomics.com/germany/precipitation)), so I have downloaded this: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/2010/RW-201008.tar__<br>\n",
    "_DWD manual:_<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/BESCHREIBUNG_gridsgermany_hourly_radolan_historical_asc_de.pdf__<br><br>\n",
    "This contains radar maps recorded in every hour. Each map has a resolution of $900\\times900$ pixels and each pixel corresponds to an $1\\,km\\times1\\,km$ area in reality. Pixel values are the precipitation height in $0.1\\,mm$.\n",
    "Below I'm importing the data of this as a series of numpy arrays and plot them to see the acual radar map. The _sys.path[0]_ is the path on my computer and it can be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the paths are probably different for you\n",
    "w_dir = Dataset(sys.path[0]+'/wind_direction/DD_201008_CF.nc')  # direction DD\n",
    "w_vel = Dataset(sys.path[0]+'/wind_speed/FF_201008_CF.nc')  # velocity FF\n",
    "rho = Dataset(sys.path[0]+\"/rain_density/rho.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9233f618c337>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_tempoGAN_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"field\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_dir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"DD\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\TUM\\3\\ADL4CV\\ADL4CV_project\\src.py\u001b[0m in \u001b[0;36mgenerate_tempoGAN_datasets\u001b[1;34m(rain_density, wind_dir, n, length, size, split, normalize)\u001b[0m\n\u001b[0;32m    233\u001b[0m         (n, length, size, size, 3))  # n series, each of size size**2 and rho,vx,vy,future frames as channels\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"[{i+1}/{n}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;31m# draw 3 random numbers for map number and idx of top left pixel of window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'src' is not defined"
     ]
    }
   ],
   "source": [
    "data = src.generate_tempoGAN_datasets(rho[\"field\"], w_dir[\"DD\"], n=10, length=4, size=64, split=(6,2,2), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(\"5min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_train     = np.reshape(train[:,0,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "unet_truth     = np.reshape(train[:,1,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "unet_val       = np.reshape(xval[:,0,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "unet_val_truth = np.reshape(xval[:,1,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "print(unet_train.shape,\"\\n\",unet_truth.shape,\"\\n\",unet_val.shape,\"\\n\",unet_truth.shape)\n",
    "unet_test      = np.reshape(test[:,0,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "unet_test_truth = np.reshape(test[:,1,:,:,:],((test.shape[0],)+test.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(unet_test[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_train = np.reshape(train[5,0,:,:,:],((1,)+train.shape[2:]))\n",
    "overfit_truth = np.reshape(train[5,1,:,:,:],((1,)+train.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.visualise_data(xval[:,:,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model2=keras.Sequential()\n",
    "def unet():\n",
    "    init       = keras.layers.Input(shape=(64,64,1))\n",
    "    ConvDown1  = keras.layers.Conv2D(filters=8,kernel_size=(2,2),strides=(1,1),padding=\"same\")(init)\n",
    "    Lr1        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown1)\n",
    "    #64\n",
    "    ConvDown2  = keras.layers.Conv2D(filters=16,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr1)\n",
    "    Lr2        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown2)\n",
    "    #32\n",
    "    ConvDown3  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr2)\n",
    "    Lr3        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown3)\n",
    "    #16\n",
    "    ConvDown4  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr3)\n",
    "    Lr4        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown4)\n",
    "    #8\n",
    "    ConvDown5  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr4)\n",
    "    Lr5        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown5)\n",
    "    #4\n",
    "\n",
    "    UpSamp1 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr5)\n",
    "    #8\n",
    "    merge1  = keras.layers.concatenate([ConvDown4,UpSamp1],axis=-1)#(UpSamp1)\n",
    "    Conv1   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge1)\n",
    "    Lr6     = keras.layers.LeakyReLU(alpha=0.1)(Conv1)\n",
    "    #8\n",
    "    UpSamp2 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr6)\n",
    "    #16\n",
    "    merge2  = keras.layers.concatenate([ConvDown3,UpSamp2],axis=-1)#(UpSamp2)\n",
    "    Conv2   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge2)\n",
    "    Lr7     = keras.layers.LeakyReLU(alpha=0.1)(Conv2)\n",
    "    #16\n",
    "    UpSamp3 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr7)\n",
    "\n",
    "    #32\n",
    "    Conv3   = keras.layers.Conv2D(filters=16,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp3)\n",
    "    Lr8     = keras.layers.LeakyReLU(alpha=0.1)(Conv3)\n",
    "\n",
    "    UpSamp4 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr8)\n",
    "    #64\n",
    "    Conv4   = keras.layers.Conv2D(filters=8,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp4)\n",
    "    Lr9     = keras.layers.LeakyReLU(alpha=0.1)(Conv4)\n",
    "    \n",
    "    Conv5   = keras.layers.Conv2D(filters=1,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'tanh')(Lr9)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=Conv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ds = keras.Sequential()\n",
    "def spatial_discriminator():\n",
    "    dropout = 0.5\n",
    "    init = keras.layers.Input(shape=(64,64,1))\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=4 ,kernel_size=4, strides=2, padding='same')(init)\n",
    "    relu1 = keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    dropout1 = keras.layers.Dropout(dropout)(relu1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=8, kernel_size=4, strides=2, padding='same')(dropout1)\n",
    "    relu2 = keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    dropout2 = keras.layers.Dropout(dropout)(relu2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv2D(filters=16, kernel_size=4, strides=2, padding='same')(dropout2)\n",
    "    relu3 = keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    dropout3 = keras.layers.Dropout(dropout)(relu3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(dropout3)\n",
    "    relu4 = keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    dropout4 = keras.layers.Dropout(dropout)(relu4)\n",
    "    \n",
    "    # Out: 1-dim probability\n",
    "    flatten = keras.layers.Flatten()(dropout4)\n",
    "    fcl1 = keras.layers.Dense(1)(flatten)\n",
    "    sig1 = keras.layers.Activation('sigmoid')(fcl1)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def temporal_discriminator():\n",
    "    dropout = 0.5\n",
    "    init = keras.layers.Input(shape=(2,64,64,3)) # t - 1, t\n",
    "    advected = np.array(advect(init[0]),init[1])\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=4 ,kernel_size=4, strides=2, padding='same')(advected)\n",
    "    relu1 = keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    dropout1 = keras.layers.Dropout(dropout)(relu1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=8, kernel_size=4, strides=2, padding='same')(dropout1)\n",
    "    relu2 = keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    dropout2 = keras.layers.Dropout(dropout)(relu2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv2D(filters=16, kernel_size=4, strides=2, padding='same')(dropout2)\n",
    "    relu3 = keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    dropout3 = keras.layers.Dropout(dropout)(relu3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(dropout3)\n",
    "    relu4 = keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    dropout4 = keras.layers.Dropout(dropout)(relu4)\n",
    "    \n",
    "    # Out: 1-dim probability\n",
    "    flatten = keras.layers.Flatten()(dropout4)\n",
    "    fcl1 = keras.layers.Dense(1)(flatten)\n",
    "    sig1 = keras.layers.Activation('sigmoid')(fcl1)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advect(image): # (64,64,3)\n",
    "    padded = np.pad(image,(0,1),'edge')[:,:,:-1]\n",
    "    advected = np.empty_like(image)\n",
    "    advected[:,:,0] = image[:,:,0] + image[:,:,1]*(padded[1:,:,0] - padded[:-1,:,0])[:,:-1] + image[:,:,2]*(padded[:,1:,0] - padded[:,:-1,0])[:-1]\n",
    "    advected[:,:,1:] = image[:,:,1:]\n",
    "    return advected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modified from source: https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 64\n",
    "        self.img_cols = 64\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.metric = [src.relative_error_tensor]\n",
    "\n",
    "        d_optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        g_optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=d_optimizer,\n",
    "            metrics=[\"accuracy\"])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        #self.generator.compile(loss='mse',\n",
    "        #    optimizer=g_optimizer,\n",
    "        #    metrics=self.metric)\n",
    "        \n",
    "        # The generator takes a sequence of frames as input and generates the next image in that sequence\n",
    "        input_img = keras.layers.Input(shape=self.img_shape)\n",
    "        generated = self.generator(input_img)\n",
    "        \n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.discriminator.trainable = False\n",
    "        self.combined = keras.models.Model(input_img, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=g_optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self,network=\"U-net\"):  \n",
    "        generator = keras.Sequential()\n",
    "        if network in [\"Unet\", \"U-net\", \"unet\", \"u-net\"]:\n",
    "            return unet()\n",
    "\n",
    "    def build_discriminator(self, which=\"s\"):\n",
    "        if which == \"s\":\n",
    "            return spatial_discriminator()\n",
    "        elif which == \"t\":\n",
    "            return temporal_discriminator()\n",
    "\n",
    "    def train(self, epochs, g_epochs=1, d_epochs=1, dataset=\"5min\", batch_size=128):\n",
    "\n",
    "        # Load the dataset\n",
    "        train, xval, test = src.load_datasets(dataset=dataset)\n",
    "        unet_train     = np.reshape(train[:,0,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "        unet_truth     = np.reshape(train[:,1,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "        unet_val       = np.reshape(xval[:,0,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "        unet_val_truth = np.reshape(xval[:,1,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "        print(\"Shape of training data: \",unet_train.shape,\"\\nShape of training truth: \",unet_truth.shape,\n",
    "        \"\\nShape of validation data: \",unet_val.shape,\"\\nShape of validation truth: \",unet_val_truth.shape)\n",
    "        unet_test      = np.reshape(test[:,0,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "        unet_test_truth = np.reshape(test[:,1,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        #store losses\n",
    "\n",
    "        log = {\"g_loss\":[],\n",
    "               \"d_loss\":[],\n",
    "               \"g_metric\":[],\n",
    "               \"d_metric\":[]}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            idx = np.random.randint(0, unet_truth.shape[0], batch_size)\n",
    "            real_imgs = unet_truth[idx]\n",
    "            training_batch = unet_train[idx]\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            generated_imgs = self.generator.predict(training_batch)\n",
    "\n",
    "            # Train the discriminator\n",
    "            for ks in range(d_epochs):\n",
    "                d_loss_real = self.discriminator.train_on_batch(real_imgs, real)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(generated_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                print(f\"    {ks} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\")\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            idx2 = np.random.randint(0, unet_train.shape[0], batch_size)\n",
    "            training_batch = unet_train[idx2]\n",
    "            training_truth = unet_truth[idx2]\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            for kg in range(g_epochs):\n",
    "                g_loss = self.combined.train_on_batch(training_batch, real)\n",
    "\n",
    "            # Plot the progress\n",
    "            log[\"g_loss\"].append(g_loss)\n",
    "            log[\"d_loss\"].append(d_loss[0])\n",
    "            #log[\"g_metric\"].append(g_loss[1])\n",
    "            log[\"d_metric\"].append(d_loss[1])\n",
    "            print(f\"\\033[1m {epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\\033[0m\"+\n",
    "                  f\"\\033[1m[G loss: {g_loss}]\\033[0m\")#, rel. err.: {g_loss[1]}] \\033[0m\")\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch in [int(x) for x in np.linspace(0.1,1,10)*epochs]:\n",
    "                self.sample_images(epoch, unet_test, unet_test_truth)\n",
    "        return log\n",
    "\n",
    "    def sample_images(self, epoch, unet_test, unet_test_truth):\n",
    "        n = 5\n",
    "        test_batch = unet_test[:n]\n",
    "        test_truth = unet_test_truth[:n]\n",
    "        gen_imgs = self.generator.predict(test_batch)\n",
    "\n",
    "        fig, axs = plt.subplots(n, 3, figsize=(16, 16))\n",
    "        for i in range(n):\n",
    "                axs[i,0].imshow(test_batch[i, :,:,0])\n",
    "                axs[i,0].axis('off')\n",
    "                axs[i,0].set_title(\"Frame t\")\n",
    "                axs[i,1].imshow(test_truth[i, :,:,0])\n",
    "                axs[i,1].axis('off')\n",
    "                axs[i,1].set_title(\"Frame t+1\")\n",
    "                axs[i,2].imshow(gen_imgs[i, :,:,0])\n",
    "                axs[i,2].axis('off')\n",
    "                axs[i,2].set_title(\"Prediction t+1\")\n",
    "        fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    log = gan.train(epochs=10, d_epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(16,4))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "ax.plot(log[\"g_loss\"],label=\"Generator loss\")\n",
    "ax.plot(log[\"d_loss\"],label=\"Discriminator loss\")\n",
    "ax.grid()\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(log[\"g_metric\"],label=\"Generator metric\")\n",
    "ax2.plot(log[\"d_metric\"],label=\"Discriminator metric\")\n",
    "ax2.grid()\n",
    "ax2.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
