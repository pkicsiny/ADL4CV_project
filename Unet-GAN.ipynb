{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11149758456406783193\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1508248780\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5903658833352000161\n",
      "physical_device_desc: \"device: 0, name: GeForce GT 740M, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advect(image): # (64,64,3)\n",
    "    \"\"\"\n",
    "    Applies the physical advection (material derivative) on a density (rain) frame.\n",
    "    See: https://en.wikipedia.org/wiki/Advection\n",
    "    in short: r(t+1)=r(t)-vx(t)*drdx(t)-vy(t)*drdy(t)\n",
    "    :param image: one image with 3 channels: the advected material (rain desity) and the flow field (wind) x and y components. \n",
    "    \"\"\"\n",
    "    #pad image\n",
    "    padded = np.pad(image,(0,1),'edge')[:,:,:-1]\n",
    "    #set nans to 0\n",
    "    padded[np.isnan(padded)] = 0\n",
    "    #create array for advected frame\n",
    "    advected = np.empty_like(image)\n",
    "    #advect (nans will be treated as 0s)\n",
    "    advected[:,:,0] = image[:,:,0] - image[:,:,1]*(padded[1:,:,0] - padded[:-1,:,0])[:,:-1] - image[:,:,2]*(padded[:,1:,0] - padded[:,:-1,0])[:-1]\n",
    "    #renormalize (saturate)\n",
    "    advected[:,:,0][advected[:,:,0] < 0] = 0\n",
    "    advected[:,:,0][advected[:,:,0] > 1] = 1   \n",
    "    #other channels stay the same\n",
    "    advected[:,:,1:] = image[:,:,1:]\n",
    "    return advected[:,:,0:1]  # (64, 64, 1) only rain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modified from source: https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "class GAN():\n",
    "    def __init__(self, dual=False, past=1, loss_function=\"mae\", augment=False):\n",
    "        self.dual = dual #set this to True to train temporal discriminator\n",
    "        self.size = 64\n",
    "        self.past_input = past #set this to change sequence length\n",
    "        self.tempoGAN_sequence_length = past\n",
    "        self.input_shape = (self.size, self.size, self.past_input) # 64, 64, t\n",
    "        self.d_metric = [\"accuracy\"]\n",
    "        self.log = {\"g_loss\":[],\n",
    "               \"d_loss\":[],\n",
    "               \"g_metric\":[],\n",
    "               \"d_metric\":[]}\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.losses = [loss_function, \"binary_crossentropy\"]\n",
    "        self.train_data = None\n",
    "        self.xval_data = None\n",
    "        self.test_data = None\n",
    "        self.augment = augment\n",
    "        \n",
    "        d_optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        g_optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "        \n",
    "# Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes a sequence of frames as input and generates the next image in that sequence\n",
    "        input_img = keras.layers.Input(shape=self.input_shape)\n",
    "        self.inputs.append(input_img)\n",
    "        generated = self.generator(input_img)\n",
    "        self.outputs.append(generated)\n",
    "        \n",
    "# Build and compile spatial discriminator\n",
    "        self.s_discriminator = self.build_discriminator(\"s\")\n",
    "        self.s_discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=d_optimizer,\n",
    "            metrics=self.d_metric)\n",
    "        # Spatial disc. takes the x as condition and G(x) and returns a float\n",
    "        score_s = self.s_discriminator([input_img, generated])\n",
    "        self.outputs.append(score_s)\n",
    "        self.s_discriminator.trainable = False\n",
    "        \n",
    "# Build and compile temporal discriminator (same as s disc. but has different inputs\n",
    "        if self.dual:\n",
    "            self.t_discriminator = self.build_discriminator(\"t\")\n",
    "            self.t_discriminator.compile(loss='binary_crossentropy',\n",
    "                optimizer=d_optimizer,\n",
    "                metrics=self.d_metric)\n",
    "            #Temporal disc. takes in advected frame A(G(x_previous)) and G(x)\n",
    "            adv = keras.layers.Input(shape=self.input_shape)\n",
    "            self.inputs.append(adv)\n",
    "            score_t = self.t_discriminator([adv, generated])\n",
    "            self.outputs.append(score_t)\n",
    "            self.t_discriminator.trainable = False  \n",
    "            self.losses.append('binary_crossentropy')\n",
    "        \n",
    "#Combined GAN model\n",
    "        self.combined = keras.models.Model(inputs=self.inputs, outputs=self.outputs)\n",
    "        #loss on all ouputs as a list: l1 loss on generated img, cross entropy for discriminator\n",
    "        self.combined.compile(loss=self.losses, optimizer=g_optimizer)\n",
    "\n",
    "    def build_generator(self,network=\"U-net\"):  \n",
    "        generator = keras.Sequential()\n",
    "        if network in [\"Unet\", \"U-net\", \"unet\", \"u-net\"]:\n",
    "            return src.unet(self.input_shape)  # 64, 64, t\n",
    "\n",
    "    def build_discriminator(self, which=\"s\"):\n",
    "        if which == \"s\":\n",
    "            return src.spatial_discriminator(condition_shape=self.input_shape)\n",
    "        elif which == \"t\":\n",
    "            return src.temporal_discriminator()\n",
    "# ---------------------\n",
    "#  Train\n",
    "# ---------------------\n",
    "    def train(self, epochs, d_epochs=1, dataset=\"5min\", batch_size=128):\n",
    "        assert isinstance(d_epochs, int) > 0 and isinstance(epochs, int) > 0 , \"Number of epochs must be a positive integer.\"\n",
    "        \n",
    "# Load the dataset\n",
    "        if self.dual:\n",
    "            if dataset not in [\"gan\", \"GAN\", \"tempogan\", \"tempoGAN\"]:\n",
    "                dataset = \"gan\"\n",
    "                print(\"tempoGAN training: Changed dataset to GAN data.\")\n",
    "            self.past_input += 1\n",
    "            print(\"tempoGAN training: Increased input sequence length by one. First frame is only auxiliary for advection.\")\n",
    "        else:\n",
    "            if dataset in [\"gan\", \"GAN\", \"tempogan\", \"tempoGAN\"]:\n",
    "                dataset = \"5min\"\n",
    "                print(\"Normal GAN training: Changed dataset to 5min data.\")\n",
    "\n",
    "            \n",
    "        print(f\"Loading {dataset} dataset.\")\n",
    "        self.train_data, self.xval_data, self.test_data = src.load_datasets(dataset, self.past_input)\n",
    "        #replace nans with -1 (can cause bias for velocity fields)\n",
    "        #self.train_data[np.isnan(self.train_data)] = -1\n",
    "        #self.xval_data[np.isnan(self.xval_data)] = -1\n",
    "        #self.test_data[np.isnan(self.test_data)] = -1\n",
    "        \n",
    "# split the dataset to inputs and ground truths\n",
    "        gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth = src.split_datasets(\n",
    "            self.train_data[:2000], self.xval_data, self.test_data, past_frames=self.past_input, augment=self.augment)\n",
    "        \n",
    "# Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "# ---------------------\n",
    "#  Train Discriminators\n",
    "# ---------------------\n",
    "\n",
    "# Train the first discriminator\n",
    "#inputs: [frame t, generated frame t+1 (from frame t)] & [frame t, ground truth of frame t (frame t+1)]\n",
    "#batches are unmixed\n",
    "            self.s_discriminator.trainable = True\n",
    "            for ks in range(d_epochs):\n",
    "                # all 4D\n",
    "                real_imgs, training_batch, generated_imgs, _, _ = self.create_training_batch(gan_train, gan_truth, batch_size)\n",
    "                ds_loss_real = self.s_discriminator.train_on_batch([training_batch, real_imgs], real)\n",
    "                ds_loss_fake = self.s_discriminator.train_on_batch([training_batch, generated_imgs], fake)\n",
    "                ds_loss = 0.5 * np.add(ds_loss_real, ds_loss_fake)\n",
    "                if d_epochs > 1:\n",
    "                    print(f\"    {ks} [Ds loss: {ds_loss[0]}, acc.: {100*ds_loss[1]}]\")\n",
    "            d_loss = ds_loss\n",
    "            self.s_discriminator.trainable = False\n",
    "                \n",
    "# Train the second discriminator\n",
    "#inputs: [advected generated frame t (from frame t-1), generated frame t+1 (from frame t)] &\n",
    "#        [advected ground truth of frame t-1 (advected frame t), ground truth frame t (frame t+1)]\n",
    "#batches are unmixed\n",
    "            if self.dual:\n",
    "                self.t_discriminator.trainable = True\n",
    "                for kt in range(d_epochs):\n",
    "                    # 4D, 4D, 4D, 4D, 4D\n",
    "                    real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth = self.create_training_batch(\n",
    "                                                                                        gan_train, gan_truth, batch_size)\n",
    "                    #only need rain map from the synthetics\n",
    "                    dt_loss_real = self.t_discriminator.train_on_batch([advected_aux_truth, real_imgs], real)\n",
    "                    dt_loss_fake = self.t_discriminator.train_on_batch([advected_aux_gen, generated_imgs], fake)\n",
    "                    dt_loss = 0.5 * np.add(dt_loss_real, dt_loss_fake)\n",
    "                    if d_epochs > 1:\n",
    "                        print(f\"    {kt} [Dt loss: {dt_loss[0]}, acc.: {100*dt_loss[1]}]\")\n",
    "                d_loss = ds_loss + dt_loss\n",
    "                self.t_discriminator.trainable = False\n",
    "            \n",
    "# ---------------------\n",
    "#  Train Generator\n",
    "# ---------------------\n",
    "\n",
    "            idx = np.random.randint(0, gan_train.shape[0], batch_size)\n",
    "            if self.dual:\n",
    "                training_truth = gan_truth[idx,:,:,:,0]  # frame t+1, 4D: n, 64, 64, 1\n",
    "                assert training_truth.shape[-1] == 1, f\"real_imgs: (n, 64, 64, 1), {real_imgs.shape}\"\n",
    "                aux_batch = gan_train[idx,:,:,:-1, 0]  # from 0 to frame t-1 (not the last frame) 4D: n, 64, 64, past-1\n",
    "                assert aux_batch.shape[-1] == self.past_input-1, f\"aux_batch: (n, 64, 64, {self.past_input-1}), {aux_batch.shape}\"\n",
    "                training_batch = gan_train[idx,:,:,1:,0]  # from frame 1 to end (t>=2), 4D: n, 64, 64, past-1\n",
    "                assert training_batch.shape[-1] == self.past_input-1, f\"training_batch: (n, 64, 64, {self.past_input-1}), {training_batch.shape}\"\n",
    "                aux_gen_imgs = self.generator.predict(aux_batch) # 4D, n, 64, 64, 1: output is frame t  \n",
    "                assert aux_gen_imgs.shape[-1] == 1, f\"aux_gen_imgs: (n, 64, 64, 1), {aux_gen_imgs.shape}\"\n",
    "                # append velocity field of frame t (last instance of past sequence)\n",
    "                aux_gen_imgs = np.concatenate((aux_gen_imgs, gan_train[idx,:,:,-1,1:]), axis=-1) #n, 64, 64, 3\n",
    "                assert aux_gen_imgs.shape[-1] == 3, f\"aux_gen_imgs: (n, 64, 64, 3), {aux_gen_imgs.shape}\"\n",
    "                # advect generated frame t\n",
    "                advected_aux_gen = np.array([advect(sample) for sample in aux_gen_imgs]) #4D (n, h, w, m) (m: rho, vx, vy)\n",
    "                assert advected_aux_gen.shape[-1] == 1, f\"advected_aux_gen: (n, 64, 64, 1), {advected_aux_gen.shape}\"\n",
    "            else:\n",
    "                training_batch = gan_train[idx]  # frame t or all past frames, 4D\n",
    "                training_truth = gan_truth[idx]  # frame t+1 or all future frames, 4D\n",
    "\n",
    "# Train the generator (to have the discriminator label samples as real)\n",
    "            if self.dual:\n",
    "                g_loss = self.combined.train_on_batch([training_batch, advected_aux_gen], [training_truth, real, real])\n",
    "            else:\n",
    "                g_loss = self.combined.train_on_batch(training_batch, [training_truth, real])\n",
    "\n",
    "# Plot the progress\n",
    "            self.log[\"g_loss\"].append(g_loss)\n",
    "            self.log[\"d_loss\"].append(d_loss[0])\n",
    "            #log[\"g_metric\"].append(g_loss[1])\n",
    "            self.log[\"d_metric\"].append(d_loss[1])\n",
    "            print(f\"\\033[1m {epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\\033[0m\"+\n",
    "                  f\"\\033[1m[G loss: {g_loss}]\\033[0m\")#, rel. err.: {g_loss[1]}] \\033[0m\")\n",
    "\n",
    "# If at save interval => save generated image samples\n",
    "            if epoch in [int(x) for x in np.linspace(0.01,5,100)*epochs]:\n",
    "                self.sample_images(epoch, gan_test, gan_test_truth)\n",
    "    \n",
    "    def create_training_batch(self, gan_train, gan_truth, batch_size):\n",
    "        idx = np.random.randint(0, gan_truth.shape[0], batch_size)\n",
    "        # Generate a batch of new images\n",
    "        if self.dual:\n",
    "            #0,1->2\n",
    "            real_imgs = gan_truth[idx,:,:,:,0]  # frame t+1, 4D: n, 64, 64, 1\n",
    "            assert real_imgs.shape[-1] == 1, f\"real_imgs: (n, 64, 64, 1), {real_imgs.shape}\"\n",
    "            training_batch = gan_train[idx,:,:,1:,0]  # from frame 1 to end (t>=2), 4D: n, 64, 64, past-1\n",
    "            assert training_batch.shape[-1] == self.past_input-1, f\"training_batch: (n, 64, 64, {self.past_input-1}), {training_batch.shape}\"\n",
    "            aux_batch = gan_train[idx,:,:,:-1, 0]  # from 0 to frame t-1 (not the last frame) 4D: n, 64, 64, past-1\n",
    "            assert aux_batch.shape[-1] == self.past_input-1, f\"aux_batch: (n, 64, 64, {self.past_input-1}), {aux_batch.shape}\"\n",
    "            generated_imgs = self.generator.predict(training_batch) # n, h, w, 1, rho (4 dimensional, last drops)\n",
    "            assert generated_imgs.shape[-1] == 1, f\"generated_imgs: (n, 64, 64, 1), {generated_imgs.shape}\"\n",
    "            aux_gen_imgs = self.generator.predict(aux_batch) # 4D, n, 64, 64, 1: output is frame t \n",
    "            assert aux_gen_imgs.shape[-1] == 1, f\"aux_gen_imgs: (n, 64, 64, 1), {aux_gen_imgs.shape}\"\n",
    "            # append velocity fields of frame t\n",
    "            #this will be advected\n",
    "            aux_gen_imgs = np.concatenate((aux_gen_imgs, gan_train[idx,:,:,-1,1:]), axis=-1) #n, 64, 64, 3\n",
    "            assert aux_gen_imgs.shape[-1] == 3, f\"aux_gen_imgs: (n, 64, 64, 3), {aux_gen_imgs.shape}\"\n",
    "            aux_true_imgs = gan_train[idx,:,:,-1] #n, 64, 64, 3, frame t with all channels\n",
    "            assert aux_true_imgs.shape[-1] == 3, f\"aux_true_imgs: (n, 64, 64, 3), {aux_true_imgs.shape}\"\n",
    "            # advected frame t (frame t+1)\n",
    "            advected_aux_gen = np.array([advect(sample) for sample in aux_gen_imgs]) #4D (n, h, w, m) (m: rho, vx, vy)\n",
    "            assert advected_aux_gen.shape[-1] == 1, f\"advected_aux_gen: (n, 64, 64, 1), {advected_aux_gen.shape}\"\n",
    "            advected_aux_truth = np.array([advect(sample) for sample in aux_true_imgs]) #4D\n",
    "            assert advected_aux_truth.shape[-1] == 1, f\"advected_aux_truth: (n, 64, 64, 1), {advected_aux_truth.shape}\"\n",
    "            \n",
    "        else: # 4D\n",
    "            real_imgs = gan_truth[idx] # 4D\n",
    "            training_batch = gan_train[idx] # 4D\n",
    "            generated_imgs = self.generator.predict(training_batch) #4D\n",
    "            advected_aux_gen = None\n",
    "            advected_aux_truth = None\n",
    "        return real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth # all 4D\n",
    "    \n",
    "    def sample_images(self, epoch, gan_test, gan_test_truth):\n",
    "        n = 5\n",
    "        if self.dual:\n",
    "            test_batch = gan_test[:n,:,:,1:,0]  # frame 1 to t (0 is not used bc. its only used in advection), 4D\n",
    "            test_truth = gan_test_truth[:n,:,:,:,0] #4th dim is always 1 so \":\" is OK\n",
    "        else:\n",
    "            test_batch = gan_test[:n]\n",
    "            test_truth = gan_test_truth[:n]\n",
    "        gen_imgs = self.generator.predict(test_batch)\n",
    "\n",
    "        fig, axs = plt.subplots(n, 3, figsize=(16, 16))\n",
    "        for i in range(n):\n",
    "                axs[i,0].imshow(test_batch[i, :,:,0])\n",
    "                axs[i,0].axis('off')\n",
    "                axs[i,0].set_title(\"Frame t\")\n",
    "                axs[i,1].imshow(test_truth[i, :,:,0])\n",
    "                axs[i,1].axis('off')\n",
    "                axs[i,1].set_title(\"Frame t+1\")\n",
    "                axs[i,2].imshow(gen_imgs[i, :,:,0])\n",
    "                axs[i,2].axis('off')\n",
    "                axs[i,2].set_title(\"Prediction t+1\")\n",
    "        fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mae', 'binary_crossentropy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan= GAN(dual=False)\n",
    "gan.combined.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal GAN training: Changed dataset to 5min data.\n",
      "Loading 5min dataset.\n",
      "Training data: (7500, 64, 64, 2)\n",
      "Validation data: (1500, 64, 64, 2)\n",
      "Test data: (1000, 64, 64, 2)\n",
      "Shape of training data:  (2000, 64, 64, 1) \n",
      "Shape of training truth:  (2000, 64, 64, 1) \n",
      "Shape of validation data:  (1500, 64, 64, 1) \n",
      "Shape of validation truth:  (1500, 64, 64, 1) \n",
      "Shape of test data:  (1000, 64, 64, 1) \n",
      "Shape of test truth:  (1000, 64, 64, 1)\n",
      "\u001b[1m 0 [D loss: 0.7011295557022095, acc.: 40.625]\u001b[0m\u001b[1m[G loss: [0.84237826, 0.1474333, 0.694945]]\u001b[0m\n",
      "\u001b[1m 1 [D loss: 0.7029887437820435, acc.: 35.9375]\u001b[0m\u001b[1m[G loss: [0.85200715, 0.16640535, 0.6856018]]\u001b[0m\n",
      "\u001b[1m 2 [D loss: 0.705133318901062, acc.: 32.8125]\u001b[0m\u001b[1m[G loss: [0.8560422, 0.17331588, 0.6827263]]\u001b[0m\n",
      "\u001b[1m 3 [D loss: 0.7005679607391357, acc.: 42.1875]\u001b[0m\u001b[1m[G loss: [0.84826064, 0.16814318, 0.6801175]]\u001b[0m\n",
      "\u001b[1m 4 [D loss: 0.6948080062866211, acc.: 44.53125]\u001b[0m\u001b[1m[G loss: [0.8606358, 0.18312973, 0.6775061]]\u001b[0m\n",
      "\u001b[1m 5 [D loss: 0.6962077617645264, acc.: 35.15625]\u001b[0m\u001b[1m[G loss: [0.8256122, 0.14494458, 0.68066764]]\u001b[0m\n",
      "\u001b[1m 6 [D loss: 0.6947270631790161, acc.: 42.1875]\u001b[0m\u001b[1m[G loss: [0.8240671, 0.14745274, 0.6766144]]\u001b[0m\n",
      "\u001b[1m 7 [D loss: 0.6962140202522278, acc.: 43.75]\u001b[0m\u001b[1m[G loss: [0.85090154, 0.17365761, 0.67724395]]\u001b[0m\n",
      "\u001b[1m 8 [D loss: 0.6988192796707153, acc.: 42.1875]\u001b[0m\u001b[1m[G loss: [0.82093346, 0.14777479, 0.6731587]]\u001b[0m\n",
      "\u001b[1m 9 [D loss: 0.69225013256073, acc.: 44.53125]\u001b[0m\u001b[1m[G loss: [0.86192334, 0.19354469, 0.66837865]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gan.train(epochs=10,dataset=\"gan\", d_epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16,4))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "g_labels = [\"Generator loss\"]+gan.combined.loss\n",
    "#loop over gen loss components\n",
    "for curve in range(np.shape(gan.log[\"g_loss\"])[-1]):\n",
    "    ax.plot(np.array(gan.log[\"g_loss\"])[:,curve] ,label=g_labels[curve])\n",
    "ax.plot(gan.log[\"d_loss\"],label=\"Discriminator loss\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(gan.log[\"g_metric\"],label=\"Generator metric\")\n",
    "ax2.plot(gan.log[\"d_metric\"],label=\"Discriminator metric\")\n",
    "ax2.grid()\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(gan.log[\"g_loss\"])[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Load datasets\n",
    "\n",
    "__<font color='red'>SHOW</font>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(\"5min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets(train, xval, test, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(train, xval, test, past_frames=1, future_frames=1):\n",
    "    \"\"\"\n",
    "    Further splits data to input and ground truth datasets.\n",
    "    :param train: numpy array of training dataset\n",
    "    :param xval: numpy array of validation dataset\n",
    "    :param test: numpy array of test dataset\n",
    "    :param past_frames: int, no. of consec. frames that will be the input of the network\n",
    "    :param future_frames: int, no. of consec. frames that will be the ground truth of the network\n",
    "    :return: 6 numpy arrays\n",
    "    \"\"\"\n",
    "    assert past_frames + future_frames <= train.shape[1], \"Wrong frame specification!\"\n",
    "    assert past_frames > 0, \"No. of past frames must be a positive integer!\"\n",
    "    assert future_frames > 0, \"No. of future frames must be a positive integer!\"\n",
    "    training_data = train[:, :, :, :past_frames]\n",
    "    trainig_data_truth = train[:, :, :, past_frames:past_frames + future_frames]\n",
    "    validation_data = xval[:, :, :, :past_frames]\n",
    "    validation_data_truth = xval[:, :, :, past_frames:past_frames + future_frames]\n",
    "    test_data = test[:, :, :, :past_frames]\n",
    "    test_data_truth = test[:, :, :, past_frames:past_frames + future_frames]\n",
    "\n",
    "    print(\"Shape of training data: \", training_data.shape, \"\\nShape of training truth: \", trainig_data_truth.shape,\n",
    "          \"\\nShape of validation data: \", validation_data.shape, \"\\nShape of validation truth: \",\n",
    "          validation_data_truth.shape,\n",
    "          \"\\nShape of test data: \", test_data.shape, \"\\nShape of test truth: \", test_data_truth.shape)\n",
    "    return training_data, trainig_data_truth, validation_data, validation_data_truth, test_data, test_data_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[np.isnan(train)] = -2\n",
    "#xval[np.isnan(xval)] = -2\n",
    "#test[np.isnan(test)] = -2\n",
    "# split the dataset\n",
    "past_frames = 1 # at least 2 frames needed into the temporal discriminator\n",
    "future_frames = 1\n",
    "gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth2 = src.split_datasets(\n",
    "    train, xval, test, past_frames, future_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = np.random.randint(0,len(train),10)\n",
    "\n",
    "for i in indices:\n",
    "    data = [train[i,0,:,:,0], train[i,1,:,:,0], train[i,2,:,:,0],\n",
    "            train[i,2,:,:,1], train[i,2,:,:,2], train[i,3,:,:,0]]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=6, num=None, figsize=(16, 16), dpi=80, facecolor='w', edgecolor='k')\n",
    "    for j, ax in enumerate(axes.flat):\n",
    "        im = ax.imshow(data[j],cmap=\"seismic\" if j in [3,4] else None, vmin=0 if j in [0,1,2,5] else -1,\n",
    "                          vmax=max([np.max(dset[j]) if j in [0,1,2,5] else 1 for dset in data]) )\n",
    "           # , norm=colors.PowerNorm(gamma=0.5) if int(j) == 3 else None)\n",
    "        ax.set_title(f\"Index: {i}, Frame: {j}\", fontsize=10)\n",
    "        src.colorbar(im)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = load_model(\"spatial_GAN_5000.h5\")\n",
    "log = np.load(\"log_Spatial_GAN_5000.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = reloaded.layers[1]\n",
    "discriminator = reloaded.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = discriminator.predict([predictions,gan_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generator.predict(gan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(gan_test_truth2, predictions)\n",
    "args[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(gan_test_truth2,predictions, metric=\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.result_plotter(args[-5:], (gan_test2[:,:,:,0], gan_test_truth2[:,:,:,0], predictions[:,:,:,0], error_images[:,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN learns:\n",
    "#sharper but not more accurate\n",
    "#small rain patches disappear\n",
    "#learns an average wind motion: mostly to the right: applies that everywhere--> data augmentation based on optical flow\n",
    "#hourly dataset with wind is still not accurate enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train unet for 5min data, 1-1, 2-1, 3-1, best-more\n",
    "#train a single disc gan for the 5min and the h data, 1-1, 2-1, 3-1, best-more\n",
    "#train dual disc for hour data, 1-1, 2-1, 3-1, best-more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 frames to predict one future frame, use that as input for further predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =gan_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(4,4,2)\n",
    "plt.imshow(augmented[0,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,3)\n",
    "plt.imshow(augmented[4,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,8)\n",
    "plt.imshow(augmented[1,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,12)\n",
    "plt.imshow(augmented[5,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,14)\n",
    "plt.imshow(augmented[2,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,15)\n",
    "plt.imshow(augmented[6,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,5)\n",
    "plt.imshow(augmented[3,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,9)\n",
    "plt.imshow(augmented[7,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augment_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(data):\n",
    "    #dimensions are n, h, w, c\n",
    "    print(\"Data augmentig done.\")\n",
    "    return np.reshape([np.array([\n",
    "        data_sample,\n",
    "        rotate(data_sample, \"90\"),\n",
    "        rotate(data_sample, \"180\"),\n",
    "        rotate(data_sample, \"270\"),\n",
    "        np.flip(data_sample, axis=1),\n",
    "        np.flip(rotate(data_sample, \"90\"), axis=1),\n",
    "        np.flip(rotate(data_sample, \"180\"), axis=1),\n",
    "        np.flip(rotate(data_sample, \"270\"), axis=1)]) for data_sample in data], ((data.shape[0]*8,)+data.shape[1:]))\n",
    "\n",
    "def rotate(img, degree):\n",
    "\n",
    "    assert degree in [\"90\",\"-270\", \"180\", \"-90\", \"270\"], \"Rotation degree must be in: [90, 180, 270, -90, -270]\"\n",
    "    rotated = np.rot90(img)\n",
    "    if degree in [\"180\", \"-90\", \"270\"]:\n",
    "        rotated = np.rot90(rotated)\n",
    "    if degree in [\"-90\", \"270\"]:\n",
    "        rotated = np.rot90(rotated)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
