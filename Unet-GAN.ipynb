{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6811653098696647002\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1508248780\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6478351300822622701\n",
      "physical_device_desc: \"device: 0, name: GeForce GT 740M, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advect(image): # (64,64,3)\n",
    "    \"\"\"\n",
    "    Applies the physical advection (material derivative) on a density (rain) frame.\n",
    "    See: https://en.wikipedia.org/wiki/Advection\n",
    "    in short: r(t+1)=r(t)-vx(t)*drdx(t)-vy(t)*drdy(t)\n",
    "    :param image: one image with 3 channels: the advected material (rain desity) and the flow field (wind) x and y components. \n",
    "    \"\"\"\n",
    "    #pad image\n",
    "    padded = np.pad(image,(0,1),'edge')[:,:,:-1]\n",
    "    #set nans to 0\n",
    "    padded[np.isnan(padded)] = 0\n",
    "    #create array for advected frame\n",
    "    advected = np.empty_like(image)\n",
    "    #advect (nans will be treated as 0s)\n",
    "    advected[:,:,0] = image[:,:,0] - image[:,:,1]*(padded[1:,:,0] - padded[:-1,:,0])[:,:-1] - image[:,:,2]*(padded[:,1:,0] - padded[:,:-1,0])[:-1]\n",
    "    #renormalize (saturate)\n",
    "    advected[:,:,0][advected[:,:,0] < 0] = 0\n",
    "    advected[:,:,0][advected[:,:,0] > 1] = 1   \n",
    "    #other channels stay the same\n",
    "    advected[:,:,1:] = image[:,:,1:]\n",
    "    return advected[:,:,0:1]  # (64, 64, 1) only rain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modified from source: https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "class GAN():\n",
    "    def __init__(self, dual=False, past=1, loss_function=\"mae\", augment=False):\n",
    "        self.dual = dual #set this to True to train temporal discriminator\n",
    "        self.size = 64\n",
    "        self.past_input = past #set this to change sequence length\n",
    "        self.tempoGAN_sequence_length = past\n",
    "        self.input_shape = (self.size, self.size, None)\n",
    "        self.d_metric = [\"accuracy\"]\n",
    "        self.log = {\"g_loss\":[],\n",
    "               \"d_loss\":[],\n",
    "               \"g_metric\":[],\n",
    "               \"d_metric\":[]}\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.losses = [loss_function, \"binary_crossentropy\"]\n",
    "        self.train_data = None\n",
    "        self.xval_data = None\n",
    "        self.test_data = None\n",
    "        self.augment = augment\n",
    "        \n",
    "        d_optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        g_optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "        \n",
    "# Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes a sequence of frames as input and generates the next image in that sequence\n",
    "        input_img = keras.layers.Input(shape=self.input_shape)\n",
    "        self.inputs.append(input_img)\n",
    "        generated = self.generator(input_img)\n",
    "        self.outputs.append(generated)\n",
    "        \n",
    "# Build and compile spatial discriminator\n",
    "        self.s_discriminator = self.build_discriminator(\"s\")\n",
    "        self.s_discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=d_optimizer,\n",
    "            metrics=self.d_metric)\n",
    "        # Spatial disc. takes the x as condition and G(x) and returns a float\n",
    "        score_s = self.s_discriminator([input_img, generated])\n",
    "        self.outputs.append(score_s)\n",
    "        self.s_discriminator.trainable = False\n",
    "        \n",
    "# Build and compile temporal discriminator (same as s disc. but has different inputs\n",
    "        if self.dual:\n",
    "            self.t_discriminator = self.build_discriminator(\"t\")\n",
    "            self.t_discriminator.compile(loss='binary_crossentropy',\n",
    "                optimizer=d_optimizer,\n",
    "                metrics=self.d_metric)\n",
    "            #Temporal disc. takes in advected frame A(G(x_previous)) and G(x)\n",
    "            adv = keras.layers.Input(shape=self.input_shape)\n",
    "            self.inputs.append(adv)\n",
    "            score_t = self.t_discriminator([adv, generated])\n",
    "            self.outputs.append(score_t)\n",
    "            self.t_discriminator.trainable = False  \n",
    "            self.losses.append('binary_crossentropy')\n",
    "        \n",
    "#Combined GAN model\n",
    "        self.combined = keras.models.Model(inputs=self.inputs, outputs=self.outputs)\n",
    "        #loss on all ouputs as a list: l1 loss on generated img, cross entropy for discriminator\n",
    "        self.combined.compile(loss=self.losses, optimizer=g_optimizer)\n",
    "\n",
    "    def build_generator(self,network=\"U-net\"):  \n",
    "        generator = keras.Sequential()\n",
    "        if network in [\"Unet\", \"U-net\", \"unet\", \"u-net\"]:\n",
    "            return src.unet(self.input_shape)\n",
    "\n",
    "    def build_discriminator(self, which=\"s\"):\n",
    "        if which == \"s\":\n",
    "            return src.spatial_discriminator()\n",
    "        elif which == \"t\":\n",
    "            return src.temporal_discriminator()\n",
    "\n",
    "    def train(self, epochs, d_epochs=1, dataset=\"5min\", batch_size=128):\n",
    "        assert isinstance(d_epochs, int) > 0 and isinstance(epochs, int) > 0 , \"Number of epochs must be a positive integer.\"\n",
    "        \n",
    "# Load the dataset\n",
    "        if self.dual:\n",
    "            dataset = \"gan\"\n",
    "            print(\"tempoGAN training: Changed dataset to GAN data.\")\n",
    "            if self.past_input == 1:\n",
    "                print(\"tempoGAN training: Increased input sequence length from 1 to 2. \\nStill uses 1 frame as input.\")\n",
    "                self.past_input = 2\n",
    "            \n",
    "        if self.train_data is None or self.xval_data is None or self.test_data is None:\n",
    "            print(f\"Loading {dataset} dataset.\")\n",
    "            self.train_data, self.xval_data, self.test_data = src.load_datasets(dataset, self.past_input)\n",
    "            #replace nans with -1 (can cause bias for velocity fields)\n",
    "            self.train_data[np.isnan(self.train_data)] = -1\n",
    "            self.xval_data[np.isnan(self.xval_data)] = -1\n",
    "            self.test_data[np.isnan(self.test_data)] = -1\n",
    "        \n",
    "# split the dataset to inputs and ground truths\n",
    "        gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth = src.split_datasets(\n",
    "            self.train_data[:2000], self.xval_data, self.test_data, past_frames=self.past_input, augment=self.augment)\n",
    "        \n",
    "# Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "# ---------------------\n",
    "#  Train Discriminators\n",
    "# ---------------------\n",
    "\n",
    "# Train the first discriminator\n",
    "#inputs: [frame t, generated frame t+1 (from frame t)] & [frame t, ground truth of frame t (frame t+1)]\n",
    "#batches are unmixed\n",
    "            self.s_discriminator.trainable = True\n",
    "            for ks in range(d_epochs):\n",
    "                # all 4D\n",
    "                real_imgs, training_batch, generated_imgs, _, _ = self.create_training_batch(gan_train, gan_truth, batch_size)\n",
    "                ds_loss_real = self.s_discriminator.train_on_batch([training_batch, real_imgs], real)\n",
    "                ds_loss_fake = self.s_discriminator.train_on_batch([training_batch, generated_imgs], fake)\n",
    "                ds_loss = 0.5 * np.add(ds_loss_real, ds_loss_fake)\n",
    "                if d_epochs > 1:\n",
    "                    print(f\"    {ks} [Ds loss: {ds_loss[0]}, acc.: {100*ds_loss[1]}]\")\n",
    "            d_loss = ds_loss\n",
    "            self.s_discriminator.trainable = False\n",
    "                \n",
    "# Train the second discriminator\n",
    "#inputs: [advected generated frame t (from frame t-1), generated frame t+1 (from frame t)] &\n",
    "#        [advected ground truth of frame t-1 (advected frame t), ground truth frame t (frame t+1)]\n",
    "#batches are unmixed\n",
    "            if self.dual:\n",
    "                self.t_discriminator.trainable = True\n",
    "                for kt in range(d_epochs):\n",
    "                    # 4D, 4D, 4D, 4D, 4D\n",
    "                    real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth = self.create_training_batch(\n",
    "                                                                                        gan_train, gan_truth, batch_size)\n",
    "                    #only need rain map from the synthetics\n",
    "                    dt_loss_real = self.t_discriminator.train_on_batch([advected_aux_truth, real_imgs], real)\n",
    "                    dt_loss_fake = self.t_discriminator.train_on_batch([advected_aux_gen, generated_imgs], fake)\n",
    "                    dt_loss = 0.5 * np.add(dt_loss_real, dt_loss_fake)\n",
    "                    if d_epochs > 1:\n",
    "                        print(f\"    {kt} [Dt loss: {dt_loss[0]}, acc.: {100*dt_loss[1]}]\")\n",
    "                d_loss = ds_loss + dt_loss\n",
    "                self.t_discriminator.trainable = False\n",
    "            \n",
    "# ---------------------\n",
    "#  Train Generator\n",
    "# ---------------------\n",
    "\n",
    "            idx = np.random.randint(0, gan_train.shape[0], batch_size)\n",
    "            if self.dual:\n",
    "                #0,1->2\n",
    "                training_truth = gan_truth[idx,:,:,:,0] #4D\n",
    "                if self.tempoGAN_sequence_length == 1:\n",
    "                    training_batch = gan_train[idx,:,:,-1:,0]  # frame t (the last in the past sequence), 4D\n",
    "                else:\n",
    "                    training_batch = gan_train[idx,:,:,:,0] #4D, all past frames\n",
    "                aux_batch = gan_train[idx,:,:,-2:-1,0]  # frame t-1, 4D\n",
    "                \n",
    "                aux_gen_imgs = self.generator.predict(aux_batch) # 4D (n, h, w, 1) only rain !!!\n",
    "                #append velocity field of frame t (last instance of past sequence)\n",
    "                aux_gen_imgs = np.concatenate((aux_gen_imgs, gan_train[idx,:,:,-1,1:]), axis=-1) # 4D but (n, h, w, 3)\n",
    "                #advect generated frame t (synthetic frame t+1)\n",
    "                advected_aux_gen = np.array([advect(sample) for sample in aux_gen_imgs]) #4D (n, h, w, m) (m: rho, vx, vy)\n",
    "            else:\n",
    "                training_batch = gan_train[idx]  # frame t or all past frames, 4D\n",
    "                training_truth = gan_truth[idx]  # frame t+1 or all future frames, 4D\n",
    "\n",
    "# Train the generator (to have the discriminator label samples as real)\n",
    "            if self.dual:\n",
    "                g_loss = self.combined.train_on_batch([training_batch, advected_aux_gen], [training_truth, real, real])\n",
    "            else:\n",
    "                g_loss = self.combined.train_on_batch(training_batch, [training_truth, real])\n",
    "\n",
    "# Plot the progress\n",
    "            self.log[\"g_loss\"].append(g_loss)\n",
    "            self.log[\"d_loss\"].append(d_loss[0])\n",
    "            #log[\"g_metric\"].append(g_loss[1])\n",
    "            self.log[\"d_metric\"].append(d_loss[1])\n",
    "            print(f\"\\033[1m {epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\\033[0m\"+\n",
    "                  f\"\\033[1m[G loss: {g_loss}]\\033[0m\")#, rel. err.: {g_loss[1]}] \\033[0m\")\n",
    "\n",
    "# If at save interval => save generated image samples\n",
    "            if epoch in [int(x) for x in np.linspace(0.01,5,100)*epochs]:\n",
    "                self.sample_images(epoch, gan_test, gan_test_truth)\n",
    "    \n",
    "    def create_training_batch(self, gan_train, gan_truth, batch_size):\n",
    "        idx = np.random.randint(0, gan_truth.shape[0], batch_size)\n",
    "        # Generate a batch of new images\n",
    "        if self.dual:\n",
    "            #0,1->2\n",
    "            real_imgs = gan_truth[idx,:,:,:,0]  # frame t+1, 4D: n, 64, 64, 1\n",
    "            print(f\"(n, 64, 64, 1), {real_imgs.shape}\")\n",
    "            if self.tempoGAN_sequence_length == 1:\n",
    "                training_batch = gan_train[idx,:,:,-1:,0]  # frame t (the last in the past sequence), 4D: n, 64, 64, 1\n",
    "                print(f\"(n, 64, 64, 1), {training_batch.shape}\")\n",
    "            else:\n",
    "                training_batch = gan_train[idx,:,:,:,0] #4D, all past frames: n, 64, 64, t_past\n",
    "                print(f\"(n, 64, 64, t_past), {training_batch.shape}\")\n",
    "            aux_batch = gan_train[idx,:,:,-2:-1, 0]  # only frame t-1 (second last in the past sequence) 4D: n, 64, 64, 1\n",
    "            print(f\"(n, 64, 64, 1), {aux_batch.shape}\")\n",
    "            generated_imgs = self.generator.predict(training_batch) # n, h, w, 1, rho (4 dimensional, last drops)\n",
    "            print(f\"(n, 64, 64, 1), {generated_imgs.shape}\")\n",
    "            aux_gen_imgs = self.generator.predict(aux_batch) # 4D, n, 64, 64, 1: frame t !!! fill up with 0s\n",
    "            print(f\"(n, 64, 64, 1), {aux_gen_imgs.shape}\")\n",
    "            # append velocity fields (the generated image is frame t so append vx, vy of the frame t), 4D\n",
    "            #this will be advected\n",
    "            #aux_gen_imgs shape: (n, 64, 64, 1)\n",
    "            aux_gen_imgs = np.concatenate((aux_gen_imgs, gan_train[idx,:,:,-1,1:]), axis=-1) #n, 64, 64, 3\n",
    "            print(f\"(n, 64, 64, 3), {aux_gen_imgs.shape}\")\n",
    "            print(gan_train[idx,:,:,-1,1:].shape)\n",
    "            aux_true_imgs = np.concatenate((training_batch[:,:,:,-1:], gan_train[idx,:,:,-1,1:]), axis=-1) #n, 64, 64, 3\n",
    "            print(f\"(n, 64, 64, 3), {aux_true_imgs.shape}\")\n",
    "            # synthetic frame t+1\n",
    "            advected_aux_gen = np.array([advect(sample) for sample in aux_gen_imgs]) #4D (n, h, w, m) (m: rho, vx, vy)\n",
    "            print(f\"(n, 64, 64, 1), {advected_aux_gen.shape}\")\n",
    "            advected_aux_truth = np.array([advect(sample) for sample in aux_true_imgs]) #4D\n",
    "            print(f\"(n, 64, 64, 1), {advected_aux_truth.shape}\")\n",
    "            \n",
    "        else: # 4D\n",
    "            real_imgs = gan_truth[idx] # 4D\n",
    "            training_batch = gan_train[idx] # 4D\n",
    "            generated_imgs = self.generator.predict(training_batch) #4D\n",
    "            advected_aux_gen = None\n",
    "            advected_aux_truth = None\n",
    "        return real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth # all 4D\n",
    "    \n",
    "    def sample_images(self, epoch, gan_test, gan_test_truth):\n",
    "        n = 5\n",
    "        if self.dual:\n",
    "            if self.tempoGAN_sequence_length == 1:\n",
    "                test_batch = gan_test[:n,:,:,-1,0]  # frame t (the last in the past sequence), 4D\n",
    "            else:\n",
    "                test_batch = gan_test[:n,:,:,:,0] #4D, all past frames\n",
    "            test_truth = gan_test_truth[:n,:,:,0]\n",
    "        else:\n",
    "            test_batch = gan_test[:n]\n",
    "            test_truth = gan_test_truth[:n]\n",
    "        gen_imgs = self.generator.predict(test_batch)\n",
    "\n",
    "        fig, axs = plt.subplots(n, 3, figsize=(16, 16))\n",
    "        for i in range(n):\n",
    "                axs[i,0].imshow(test_batch[i, :,:,0])\n",
    "                axs[i,0].axis('off')\n",
    "                axs[i,0].set_title(\"Frame t\")\n",
    "                axs[i,1].imshow(test_truth[i, :,:,0])\n",
    "                axs[i,1].axis('off')\n",
    "                axs[i,1].set_title(\"Frame t+1\")\n",
    "                axs[i,2].imshow(gen_imgs[i, :,:,0])\n",
    "                axs[i,2].axis('off')\n",
    "                axs[i,2].set_title(\"Prediction t+1\")\n",
    "        fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mae', 'binary_crossentropy', 'binary_crossentropy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan= GAN(dual=True)\n",
    "gan.combined.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempoGAN training: Changed dataset to GAN data.\n",
      "tempoGAN training: Increased input sequence length from 1 to 2. \n",
      "Still uses 1 frame as input.\n",
      "Loading gan dataset.\n",
      "Training data: (7500, 64, 64, 3, 3)\n",
      "Validation data: (1500, 64, 64, 3, 3)\n",
      "Test data: (1000, 64, 64, 3, 3)\n",
      "Shape of training data:  (2000, 64, 64, 2, 3) \n",
      "Shape of training truth:  (2000, 64, 64, 1, 3) \n",
      "Shape of validation data:  (1500, 64, 64, 2, 3) \n",
      "Shape of validation truth:  (1500, 64, 64, 1, 3) \n",
      "Shape of test data:  (1000, 64, 64, 2, 3) \n",
      "Shape of test truth:  (1000, 64, 64, 1, 3)\n",
      "(n, 64, 64, 1), (64, 64, 64, 1)\n",
      "(n, 64, 64, 1), (64, 64, 64, 1)\n",
      "(n, 64, 64, 1), (64, 64, 64, 1)\n",
      "(n, 64, 64, 1), (64, 64, 64, 1)\n",
      "(n, 64, 64, 1), (64, 64, 64, 1)\n",
      "(n, 64, 64, 3), (64, 64, 64, 3)\n",
      "(64, 64, 64, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4bea7898a1a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gan\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-7230bb2554b9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, d_epochs, dataset, batch_size)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;31m# all 4D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                 \u001b[0mreal_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgan_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgan_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[0mds_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_discriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0mds_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_discriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_imgs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7230bb2554b9>\u001b[0m in \u001b[0;36mcreate_training_batch\u001b[1;34m(self, gan_train, gan_truth, batch_size)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"(n, 64, 64, 3), {aux_gen_imgs.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgan_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0maux_true_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgan_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#n, 64, 64, 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"(n, 64, 64, 3), {aux_true_imgs.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[1;31m# synthetic frame t+1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "gan.train(epochs=10,dataset=\"gan\", d_epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16,4))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "g_labels = [\"Generator loss\"]+gan.combined.loss\n",
    "#loop over gen loss components\n",
    "for curve in range(np.shape(gan.log[\"g_loss\"])[-1]):\n",
    "    ax.plot(np.array(gan.log[\"g_loss\"])[:,curve] ,label=g_labels[curve])\n",
    "ax.plot(gan.log[\"d_loss\"],label=\"Discriminator loss\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(gan.log[\"g_metric\"],label=\"Generator metric\")\n",
    "ax2.plot(gan.log[\"d_metric\"],label=\"Discriminator metric\")\n",
    "ax2.grid()\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(gan.log[\"g_loss\"])[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Load datasets\n",
    "\n",
    "__<font color='red'>SHOW</font>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(\"5min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets(train, xval, test, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(train, xval, test, past_frames=1, future_frames=1):\n",
    "    \"\"\"\n",
    "    Further splits data to input and ground truth datasets.\n",
    "    :param train: numpy array of training dataset\n",
    "    :param xval: numpy array of validation dataset\n",
    "    :param test: numpy array of test dataset\n",
    "    :param past_frames: int, no. of consec. frames that will be the input of the network\n",
    "    :param future_frames: int, no. of consec. frames that will be the ground truth of the network\n",
    "    :return: 6 numpy arrays\n",
    "    \"\"\"\n",
    "    assert past_frames + future_frames <= train.shape[1], \"Wrong frame specification!\"\n",
    "    assert past_frames > 0, \"No. of past frames must be a positive integer!\"\n",
    "    assert future_frames > 0, \"No. of future frames must be a positive integer!\"\n",
    "    training_data = train[:, :, :, :past_frames]\n",
    "    trainig_data_truth = train[:, :, :, past_frames:past_frames + future_frames]\n",
    "    validation_data = xval[:, :, :, :past_frames]\n",
    "    validation_data_truth = xval[:, :, :, past_frames:past_frames + future_frames]\n",
    "    test_data = test[:, :, :, :past_frames]\n",
    "    test_data_truth = test[:, :, :, past_frames:past_frames + future_frames]\n",
    "\n",
    "    print(\"Shape of training data: \", training_data.shape, \"\\nShape of training truth: \", trainig_data_truth.shape,\n",
    "          \"\\nShape of validation data: \", validation_data.shape, \"\\nShape of validation truth: \",\n",
    "          validation_data_truth.shape,\n",
    "          \"\\nShape of test data: \", test_data.shape, \"\\nShape of test truth: \", test_data_truth.shape)\n",
    "    return training_data, trainig_data_truth, validation_data, validation_data_truth, test_data, test_data_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[np.isnan(train)] = -2\n",
    "#xval[np.isnan(xval)] = -2\n",
    "#test[np.isnan(test)] = -2\n",
    "# split the dataset\n",
    "past_frames = 1 # at least 2 frames needed into the temporal discriminator\n",
    "future_frames = 1\n",
    "gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth2 = src.split_datasets(\n",
    "    train, xval, test, past_frames, future_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = np.random.randint(0,len(train),10)\n",
    "\n",
    "for i in indices:\n",
    "    data = [train[i,0,:,:,0], train[i,1,:,:,0], train[i,2,:,:,0],\n",
    "            train[i,2,:,:,1], train[i,2,:,:,2], train[i,3,:,:,0]]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=6, num=None, figsize=(16, 16), dpi=80, facecolor='w', edgecolor='k')\n",
    "    for j, ax in enumerate(axes.flat):\n",
    "        im = ax.imshow(data[j],cmap=\"seismic\" if j in [3,4] else None, vmin=0 if j in [0,1,2,5] else -1,\n",
    "                          vmax=max([np.max(dset[j]) if j in [0,1,2,5] else 1 for dset in data]) )\n",
    "           # , norm=colors.PowerNorm(gamma=0.5) if int(j) == 3 else None)\n",
    "        ax.set_title(f\"Index: {i}, Frame: {j}\", fontsize=10)\n",
    "        src.colorbar(im)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = load_model(\"spatial_GAN_5000.h5\")\n",
    "log = np.load(\"log_Spatial_GAN_5000.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = reloaded.layers[1]\n",
    "discriminator = reloaded.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = discriminator.predict([predictions,gan_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generator.predict(gan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(gan_test_truth2, predictions)\n",
    "args[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(gan_test_truth2,predictions, metric=\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.result_plotter(args[-5:], (gan_test2[:,:,:,0], gan_test_truth2[:,:,:,0], predictions[:,:,:,0], error_images[:,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN learns:\n",
    "#sharper but not more accurate\n",
    "#small rain patches disappear\n",
    "#learns an average wind motion: mostly to the right: applies that everywhere--> data augmentation based on optical flow\n",
    "#hourly dataset with wind is still not accurate enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train unet for 5min data, 1-1, 2-1, 3-1, best-more\n",
    "#train a single disc gan for the 5min and the h data, 1-1, 2-1, 3-1, best-more\n",
    "#train dual disc for hour data, 1-1, 2-1, 3-1, best-more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 frames to predict one future frame, use that as input for further predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =gan_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(4,4,2)\n",
    "plt.imshow(augmented[0,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,3)\n",
    "plt.imshow(augmented[4,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,8)\n",
    "plt.imshow(augmented[1,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,12)\n",
    "plt.imshow(augmented[5,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,14)\n",
    "plt.imshow(augmented[2,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,15)\n",
    "plt.imshow(augmented[6,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,5)\n",
    "plt.imshow(augmented[3,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4,4,9)\n",
    "plt.imshow(augmented[7,:,:,0])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augment_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(data):\n",
    "    #dimensions are n, h, w, c\n",
    "    print(\"Data augmentig done.\")\n",
    "    return np.reshape([np.array([\n",
    "        data_sample,\n",
    "        rotate(data_sample, \"90\"),\n",
    "        rotate(data_sample, \"180\"),\n",
    "        rotate(data_sample, \"270\"),\n",
    "        np.flip(data_sample, axis=1),\n",
    "        np.flip(rotate(data_sample, \"90\"), axis=1),\n",
    "        np.flip(rotate(data_sample, \"180\"), axis=1),\n",
    "        np.flip(rotate(data_sample, \"270\"), axis=1)]) for data_sample in data], ((data.shape[0]*8,)+data.shape[1:]))\n",
    "\n",
    "def rotate(img, degree):\n",
    "\n",
    "    assert degree in [\"90\",\"-270\", \"180\", \"-90\", \"270\"], \"Rotation degree must be in: [90, 180, 270, -90, -270]\"\n",
    "    rotated = np.rot90(img)\n",
    "    if degree in [\"180\", \"-90\", \"270\"]:\n",
    "        rotated = np.rot90(rotated)\n",
    "    if degree in [\"-90\", \"270\"]:\n",
    "        rotated = np.rot90(rotated)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
