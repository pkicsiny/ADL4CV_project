{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2447111106651953373\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (6000, 4, 64, 64, 3)\n",
      "Validation data: (2000, 4, 64, 64, 3)\n",
      "Test data: (2000, 4, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "train, xval, test = src.load_datasets(\"gan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#visualise channels\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4,figsize=(9,9))\n",
    "for ax in [ax1,ax2,ax3,ax4]:\n",
    "    ax.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left=False,      # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "line1 = ax1.imshow(train[0,0,:,:,0]) # start from index 0 which means 0:50:00\n",
    "line2 = ax2.imshow(train[0,1,:,:,0]) # start from index 1 which means 1:00:00\n",
    "line3 = ax3.imshow(train[0,2,:,:,0])\n",
    "line4 = ax4.imshow(train[0,3,:,:,0])\n",
    "\n",
    "line = [line1, line2, line3, line4]\n",
    "\n",
    "def run(i):\n",
    "    line[0].set_data(train[i,0,:,:,0])\n",
    "    line[1].set_data(train[i,1,:,:,0])\n",
    "    line[2].set_data(train[i,2,:,:,0])\n",
    "    line[3].set_data(train[i,3,:,:,0])\n",
    "    fig.suptitle(f\"Index in array: {i}\")\n",
    "    return line\n",
    "\n",
    "ani = FuncAnimation(fig, run, blit=True, interval=200, frames=100,\n",
    "    repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.visualise_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model2=keras.Sequential()\n",
    "def unet():\n",
    "    init       = keras.layers.Input(shape=(64,64,1))\n",
    "    ConvDown1  = keras.layers.Conv2D(filters=8,kernel_size=(2,2),strides=(1,1),padding=\"same\")(init)\n",
    "    Lr1        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown1)\n",
    "    #64\n",
    "    ConvDown2  = keras.layers.Conv2D(filters=16,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr1)\n",
    "    Lr2        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown2)\n",
    "    #32\n",
    "    ConvDown3  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr2)\n",
    "    Lr3        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown3)\n",
    "    #16\n",
    "    ConvDown4  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr3)\n",
    "    Lr4        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown4)\n",
    "    #8\n",
    "    ConvDown5  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr4)\n",
    "    Lr5        = keras.layers.LeakyReLU(alpha=0.1)(ConvDown5)\n",
    "    #4\n",
    "\n",
    "    UpSamp1 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr5)\n",
    "    #8\n",
    "    merge1  = keras.layers.concatenate([ConvDown4,UpSamp1],axis=-1)#(UpSamp1)\n",
    "    Conv1   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge1)\n",
    "    Lr6     = keras.layers.LeakyReLU(alpha=0.1)(Conv1)\n",
    "    #8\n",
    "    UpSamp2 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr6)\n",
    "    #16\n",
    "    merge2  = keras.layers.concatenate([ConvDown3,UpSamp2],axis=-1)#(UpSamp2)\n",
    "    Conv2   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge2)\n",
    "    Lr7     = keras.layers.LeakyReLU(alpha=0.1)(Conv2)\n",
    "    #16\n",
    "    UpSamp3 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr7)\n",
    "\n",
    "    #32\n",
    "    Conv3   = keras.layers.Conv2D(filters=16,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp3)\n",
    "    Lr8     = keras.layers.LeakyReLU(alpha=0.1)(Conv3)\n",
    "\n",
    "    UpSamp4 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr8)\n",
    "    #64\n",
    "    Conv4   = keras.layers.Conv2D(filters=8,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp4)\n",
    "    Lr9     = keras.layers.LeakyReLU(alpha=0.1)(Conv4)\n",
    "    \n",
    "    Conv5   = keras.layers.Conv2D(filters=1,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'tanh')(Lr9)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=Conv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spatial_discriminator():\n",
    "    dropout = 0.5\n",
    "    init = keras.layers.Input(shape=(64,64,1))\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=4 ,kernel_size=4, strides=2, padding='same')(init)\n",
    "    relu1 = keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    dropout1 = keras.layers.Dropout(dropout)(relu1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=8, kernel_size=4, strides=2, padding='same')(dropout1)\n",
    "    relu2 = keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    dropout2 = keras.layers.Dropout(dropout)(relu2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv2D(filters=16, kernel_size=4, strides=2, padding='same')(dropout2)\n",
    "    relu3 = keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    dropout3 = keras.layers.Dropout(dropout)(relu3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(dropout3)\n",
    "    relu4 = keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    dropout4 = keras.layers.Dropout(dropout)(relu4)\n",
    "    \n",
    "    # Out: 1-dim probability\n",
    "    flatten = keras.layers.Flatten()(dropout4)\n",
    "    fcl1 = keras.layers.Dense(1)(flatten)\n",
    "    sig1 = keras.layers.Activation('sigmoid')(fcl1)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def temporal_discriminator():\n",
    "    dropout = 0.5\n",
    "    init = keras.layers.Input(shape=(2,64,64,3)) # t - 1, t\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(filters=4 ,kernel_size=4, strides=2, padding='same')(init)\n",
    "    relu1 = keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    dropout1 = keras.layers.Dropout(dropout)(relu1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(filters=8, kernel_size=4, strides=2, padding='same')(dropout1)\n",
    "    relu2 = keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    dropout2 = keras.layers.Dropout(dropout)(relu2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv2D(filters=16, kernel_size=4, strides=2, padding='same')(dropout2)\n",
    "    relu3 = keras.layers.LeakyReLU(alpha=0.2)(conv3)\n",
    "    dropout3 = keras.layers.Dropout(dropout)(relu3)\n",
    "    \n",
    "    conv4 = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(dropout3)\n",
    "    relu4 = keras.layers.LeakyReLU(alpha=0.2)(conv4)\n",
    "    dropout4 = keras.layers.Dropout(dropout)(relu4)\n",
    "    \n",
    "    # Out: 1-dim probability\n",
    "    flatten = keras.layers.Flatten()(dropout4)\n",
    "    fcl1 = keras.layers.Dense(1)(flatten)\n",
    "    sig1 = keras.layers.Activation('sigmoid')(fcl1)\n",
    "    \n",
    "    return keras.models.Model(inputs=init, outputs=sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advect(image): # (64,64,3)\n",
    "    padded = np.pad(image,(0,1),'edge')[:,:,:-1]\n",
    "    advected = np.empty_like(image)\n",
    "    advected[:,:,0] = image[:,:,0] + image[:,:,1]*(padded[1:,:,0] - padded[:-1,:,0])[:,:-1] + image[:,:,2]*(padded[:,1:,0] - padded[:,:-1,0])[:-1]\n",
    "    advected[:,:,1:] = image[:,:,1:]\n",
    "    return advected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (6000, 64, 64, 3) \n",
      "Shape of training truth:  (6000, 2, 64, 64, 3) \n",
      "Shape of validation data:  (2000, 64, 64, 3) \n",
      "Shape of validation truth:  (2000, 2, 64, 64, 3) \n",
      "Shape of test data:  (2000, 64, 64, 3) \n",
      "Shape of test truth:  (2000, 2, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e,f = split_datasets(train, xval, test, past_frames=1, future_frames=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(train, xval, test, past_frames=1, future_frames=1):\n",
    "    assert past_frames + future_frames <= train.shape[1], \"Wrong frame specification!\"\n",
    "    assert past_frames > 0, \"No. of past frames must be a positive integer!\"\n",
    "    assert future_frames > 0,  \"No. of future frames must be a positive integer!\"\n",
    "    training_data         = np.reshape(train[:,:past_frames,:,:,:],\n",
    "                                       ((train.shape[0],)+train.shape[2:]) if past_frames == 1 else ((train.shape[0],past_frames)+train.shape[2:]))\n",
    "    trainig_data_truth    = np.reshape(train[:,past_frames:past_frames+future_frames,:,:,:],\n",
    "                                       ((train.shape[0],)+train.shape[2:]) if future_frames == 1 else ((train.shape[0],future_frames)+train.shape[2:]))\n",
    "    validation_data       = np.reshape(xval[:,:past_frames,:,:,:],\n",
    "                                       ((xval.shape[0],)+xval.shape[2:]) if past_frames == 1 else ((xval.shape[0],past_frames)+xval.shape[2:]))\n",
    "    validation_data_truth = np.reshape(xval[:,past_frames:past_frames+future_frames,:,:,:],\n",
    "                                       ((xval.shape[0],)+xval.shape[2:]) if future_frames == 1 else ((xval.shape[0],future_frames)+xval.shape[2:]))\n",
    "    test_data             = np.reshape(test[:,:past_frames,:,:,:],\n",
    "                                       ((test.shape[0],)+test.shape[2:]) if past_frames == 1 else ((test.shape[0],past_frames)+test.shape[2:]))\n",
    "    test_data_truth       = np.reshape(test[:,past_frames:past_frames+future_frames,:,:,:],\n",
    "                                       ((test.shape[0],)+test.shape[2:]) if future_frames == 1 else ((test.shape[0],future_frames)+test.shape[2:]))\n",
    "    \n",
    "    print(\"Shape of training data: \",training_data.shape,\"\\nShape of training truth: \",trainig_data_truth.shape,\n",
    "    \"\\nShape of validation data: \",validation_data.shape,\"\\nShape of validation truth: \",validation_data_truth.shape,\n",
    "    \"\\nShape of test data: \",test_data.shape,\"\\nShape of test truth: \",test_data_truth.shape)\n",
    "    return training_data, trainig_data_truth, validation_data, validation_data_truth, test_data, test_data_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modified from source: https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 64\n",
    "        self.img_cols = 64\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.metric = [src.relative_error_tensor]\n",
    "\n",
    "        d_optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        g_optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=d_optimizer,\n",
    "            metrics=[\"accuracy\"])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        #self.generator.compile(loss='mse',\n",
    "        #    optimizer=g_optimizer,\n",
    "        #    metrics=self.metric)\n",
    "        \n",
    "        # The generator takes a sequence of frames as input and generates the next image in that sequence\n",
    "        input_img = keras.layers.Input(shape=self.img_shape)\n",
    "        generated = self.generator(input_img)\n",
    "        \n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.discriminator.trainable = False\n",
    "        self.combined = keras.models.Model(input_img, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=g_optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self,network=\"U-net\"):  \n",
    "        generator = keras.Sequential()\n",
    "        if network in [\"Unet\", \"U-net\", \"unet\", \"u-net\"]:\n",
    "            return unet()\n",
    "\n",
    "    def build_discriminator(self, which=\"s\"):\n",
    "        if which == \"s\":\n",
    "            return spatial_discriminator()\n",
    "        elif which == \"t\":\n",
    "            return temporal_discriminator()\n",
    "\n",
    "    def train(self, epochs, g_epochs=1, d_epochs=1, dataset=\"5min\", batch_size=128, dual=False):\n",
    "\n",
    "        # Load the dataset\n",
    "        train, xval, test = src.load_datasets(dataset=dataset)\n",
    "        \n",
    "        # split the dataset\n",
    "        gan_train     = np.reshape(train[:,0,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "        gan_truth     = np.reshape(train[:,1,:,:,:],((train.shape[0],)+train.shape[2:]))\n",
    "        gan_val       = np.reshape(xval[:,0,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "        gan_val_truth = np.reshape(xval[:,1,:,:,:],((xval.shape[0],)+xval.shape[2:]))\n",
    "        gan_test      = np.reshape(test[:,0,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "        gan_test_truth = np.reshape(test[:,1,:,:,:],((test.shape[0],)+test.shape[2:]))\n",
    "        \n",
    "        print(\"Shape of training data: \",gan_train.shape,\"\\nShape of training truth: \",gan_truth.shape,\n",
    "        \"\\nShape of validation data: \",gan_val.shape,\"\\nShape of validation truth: \",gan_val_truth.shape,\n",
    "        \"\\nShape of test data: \",gan_test.shape,\"\\nShape of test truth: \",gan_test_truth.shape)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        #store losses\n",
    "\n",
    "        log = {\"g_loss\":[],\n",
    "               \"d_loss\":[],\n",
    "               \"g_metric\":[],\n",
    "               \"d_metric\":[]}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminators\n",
    "            # ---------------------\n",
    "\n",
    "            idx = np.random.randint(0, gan_truth.shape[0], batch_size)\n",
    "            real_imgs = gan_truth[idx]\n",
    "            training_batch = gan_train[idx]\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            generated_imgs = self.generator.predict(training_batch)\n",
    "\n",
    "            # Train the first discriminator\n",
    "            for ks in range(d_epochs):\n",
    "                d_loss_real = self.discriminator.train_on_batch(real_imgs, real)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(generated_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                print(f\"    {ks} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\")\n",
    "                \n",
    "            \n",
    "            # Train the second discriminator\n",
    "            if dual:\n",
    "                for kt in range(d_epochs):\n",
    "                    advected = np.array([advect(sample) for sample in real_imgs])\n",
    "                    d_loss_real = self.discriminator.train_on_batch(real_imgs, real)\n",
    "                    d_loss_fake = self.discriminator.train_on_batch(generated_imgs, fake)\n",
    "                    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                    print(f\"    {ks} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\")\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            idx2 = np.random.randint(0, gan_train.shape[0], batch_size)\n",
    "            training_batch = gan_train[idx2]\n",
    "            training_truth = gan_truth[idx2]\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            for kg in range(g_epochs):\n",
    "                g_loss = self.combined.train_on_batch(training_batch, real)\n",
    "\n",
    "            # Plot the progress\n",
    "            log[\"g_loss\"].append(g_loss)\n",
    "            log[\"d_loss\"].append(d_loss[0])\n",
    "            #log[\"g_metric\"].append(g_loss[1])\n",
    "            log[\"d_metric\"].append(d_loss[1])\n",
    "            print(f\"\\033[1m {epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\\033[0m\"+\n",
    "                  f\"\\033[1m[G loss: {g_loss}]\\033[0m\")#, rel. err.: {g_loss[1]}] \\033[0m\")\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch in [int(x) for x in np.linspace(0.1,1,10)*epochs]:\n",
    "                self.sample_images(epoch, gan_test, gan_test_truth)\n",
    "        return log\n",
    "\n",
    "    def sample_images(self, epoch, gan_test, gan_test_truth):\n",
    "        n = 5\n",
    "        test_batch = gan_test[:n]\n",
    "        test_truth = gan_test_truth[:n]\n",
    "        gen_imgs = self.generator.predict(test_batch)\n",
    "\n",
    "        fig, axs = plt.subplots(n, 3, figsize=(16, 16))\n",
    "        for i in range(n):\n",
    "                axs[i,0].imshow(test_batch[i, :,:,0])\n",
    "                axs[i,0].axis('off')\n",
    "                axs[i,0].set_title(\"Frame t\")\n",
    "                axs[i,1].imshow(test_truth[i, :,:,0])\n",
    "                axs[i,1].axis('off')\n",
    "                axs[i,1].set_title(\"Frame t+1\")\n",
    "                axs[i,2].imshow(gen_imgs[i, :,:,0])\n",
    "                axs[i,2].axis('off')\n",
    "                axs[i,2].set_title(\"Prediction t+1\")\n",
    "        fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    log = gan.train(epochs=10, d_epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(16,4))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "ax.plot(log[\"g_loss\"],label=\"Generator loss\")\n",
    "ax.plot(log[\"d_loss\"],label=\"Discriminator loss\")\n",
    "ax.grid()\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(log[\"g_metric\"],label=\"Generator metric\")\n",
    "ax2.plot(log[\"d_metric\"],label=\"Discriminator metric\")\n",
    "ax2.grid()\n",
    "ax2.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
