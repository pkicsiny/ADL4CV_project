{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6300244754473936994\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1508248780\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6841102337555056500\n",
      "physical_device_desc: \"device: 0, name: GeForce GT 740M, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modified from source: https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "class GAN():\n",
    "    def __init__(self,\n",
    "                 dual=False,\n",
    "                 past=1,\n",
    "                 loss_function=\"l1\",\n",
    "                 augment=False,\n",
    "                 g_dropout=0.5,\n",
    "                 d_dropout=0.5,\n",
    "                 batchnorm=True,\n",
    "                 obj=1,\n",
    "                 bce_s=1,\n",
    "                 bce_t=1,\n",
    "                 dynamic_loss = False,\n",
    "                 noisy_labels=False,\n",
    "                 loss_constraint=0):\n",
    "        \n",
    "        self.dual = dual #set this to True to train temporal discriminator\n",
    "        self.size = 64\n",
    "        self.batchnorm = batchnorm # in G\n",
    "        self.g_dropout = g_dropout\n",
    "        self.d_dropout = d_dropout\n",
    "        self.noisy_labels = noisy_labels\n",
    "        self.past_input = past #set this to change sequence length\n",
    "        self.input_shape = (self.size, self.size, self.past_input) # 64, 64, t\n",
    "        self.log = {\"g_loss\":[],\n",
    "               \"d_loss\":[],\n",
    "               \"g_metric\":[],\n",
    "               \"d_metric\":[]}\n",
    "        self.gradients = {\"g_grads\":[],\n",
    "                         \"ds_grads\":[],\n",
    "                         \"dt_grads\":[]}\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.train_data = None\n",
    "        self.xval_data = None\n",
    "        self.test_data = None\n",
    "        self.augment = augment\n",
    "#Loss params      \n",
    "        self.loss_weights = [obj, bce_s]\n",
    "        self.dynamic_loss = dynamic_loss\n",
    "        self.objective_loss_constraint = loss_constraint\n",
    "        #self.tenpercent_obj = obj*0.1\n",
    "        self.losses = [src.custom_loss(loss=loss_function), keras.losses.binary_crossentropy]\n",
    "        self.d_metric = [keras.metrics.binary_accuracy]\n",
    "#Optimizers\n",
    "        self.d_optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        #0.01\n",
    "        self.g_optimizer = keras.optimizers.Adam(0.0002, 0.5)#, decay=1e-6)\n",
    "        #lr=0.0002, 0.5\n",
    "\n",
    "        \n",
    "# Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes a sequence of frames as input and generates the next image in that sequence\n",
    "        input_img = keras.layers.Input(shape=self.input_shape)\n",
    "        self.inputs.append(input_img)\n",
    "        generated = self.generator(input_img)\n",
    "        self.outputs.append(generated)\n",
    "        \n",
    "# Build and compile spatial discriminator\n",
    "        self.s_discriminator = self.build_discriminator(\"s\")\n",
    "        self.s_discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=self.d_optimizer,\n",
    "            metrics=self.d_metric)\n",
    "        # Spatial disc. takes the x as condition and G(x) and returns a float\n",
    "        score_s = self.s_discriminator([input_img, generated])\n",
    "        self.outputs.append(score_s)\n",
    "        self.s_discriminator.trainable = False\n",
    "        \n",
    "# Build and compile temporal discriminator (same as s disc. but has different inputs\n",
    "        if self.dual:\n",
    "            self.t_discriminator = self.build_discriminator(\"t\")\n",
    "            self.t_discriminator.compile(loss='binary_crossentropy',\n",
    "                optimizer=self.d_optimizer,\n",
    "                metrics=self.d_metric)\n",
    "            #Temporal disc. takes in advected frame A(G(x_previous)) and G(x)\n",
    "            adv = keras.layers.Input(shape=self.input_shape)\n",
    "            self.inputs.append(adv)\n",
    "            score_t = self.t_discriminator([adv, generated])\n",
    "            self.outputs.append(score_t)\n",
    "            self.t_discriminator.trainable = False  \n",
    "            self.losses.append(keras.losses.binary_crossentropy)\n",
    "            self.loss_weights.append(bce_t)\n",
    "        \n",
    "#Combined GAN model\n",
    "        self.combined = keras.models.Model(inputs=self.inputs, outputs=self.outputs)\n",
    "        #loss on all ouputs as a list: l1 loss on generated img, cross entropy for discriminator\n",
    "        self.combined.compile(loss=self.losses, optimizer=self.g_optimizer, loss_weights=self.loss_weights)\n",
    "\n",
    "    def build_generator(self,network=\"U-net\"):  \n",
    "        generator = keras.Sequential()\n",
    "        if network in [\"Unet\", \"U-net\", \"unet\", \"u-net\"]:\n",
    "            return src.unet(self.input_shape,dropout=self.g_dropout, batchnorm=self.batchnorm)  # 64, 64, t\n",
    "\n",
    "    def build_discriminator(self, which=\"s\"):\n",
    "        if which == \"s\":\n",
    "            return src.spatial_discriminator(condition_shape=self.input_shape, dropout=self.d_dropout)\n",
    "        elif which == \"t\":\n",
    "            return src.temporal_discriminator()\n",
    "        \n",
    "        \n",
    "# ----------------------------------------------------\n",
    "#  Train\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "    def train(self, epochs, d_epochs=1, batch_size=64, overfit=False):        \n",
    "# Load the dataset\n",
    "        if self.dual:\n",
    "            self.past_input += 1\n",
    "            print(\"tempoGAN training: Increased input sequence length by one. First frame is only auxiliary for advection.\")\n",
    "        else:\n",
    "            print(\"Normal GAN training: Changed dataset to 5min data.\")\n",
    "\n",
    "            \n",
    "        print(f\"Loading dataset.\")\n",
    "        self.train_data, self.xval_data, self.test_data = src.load_datasets(self.past_input)\n",
    "        self.train_data[np.isnan(self.train_data)] = 0\n",
    "        self.xval_data[np.isnan(self.xval_data)] = 0\n",
    "        self.test_data[np.isnan(self.test_data)] = 0\n",
    "# split the dataset to inputs and ground truths\n",
    "        gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth = src.split_datasets(\n",
    "            self.train_data, self.xval_data, self.test_data, past_frames=self.past_input, augment=self.augment)\n",
    "        \n",
    "        \n",
    "        if overfit:\n",
    "            batch_size = 1\n",
    "            gan_train = gan_train[0:1]\n",
    "            gan_truth = gan_truth[0:1]\n",
    "            print(\"Overfit test: use only 1 sample.\")\n",
    "            \n",
    "# Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        print(f\"Adversarial labels shape: {real.shape}\")\n",
    "#Generator ground truths\n",
    "        g_real = np.ones((batch_size, 1))\n",
    "        #print(f\"Initial loss weights: {self.loss_weights}\")\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "# update loss weights\n",
    "            if self.dynamic_loss and epoch > 0 and self.loss_weights[0] > 0.3:\n",
    "                self.update_loss_weights(epoch)\n",
    "# ---------------------\n",
    "#  Train Discriminators\n",
    "# ---------------------\n",
    "\n",
    "# Train the first discriminator\n",
    "#inputs: [frame t, generated frame t+1 (from frame t)] & [frame t, ground truth of frame t (frame t+1)]\n",
    "#batches are unmixed\n",
    "            self.s_discriminator.trainable = True\n",
    "            for ks in range(d_epochs):\n",
    "                # all 4D\n",
    "                real_imgs, training_batch, generated_imgs, _, _ = self.create_training_batch(gan_train, gan_truth, batch_size, \"s\")\n",
    "                #print(f\"Input shape: {training_batch.shape}\\nGround truth shape: {real_imgs.shape} \")\n",
    "                #mix 5% of labels\n",
    "                if self.noisy_labels:\n",
    "                    d_real, d_fake = self.noisy_d_labels(real, fake)\n",
    "                    #print(\"Switching 5% of labels for spatial discriminator.\")\n",
    "                else:\n",
    "                    d_real = real\n",
    "                    d_fake = fake\n",
    "                    \n",
    "                ds_loss_real = self.s_discriminator.train_on_batch([training_batch, real_imgs], d_real)\n",
    "                ds_loss_fake = self.s_discriminator.train_on_batch([training_batch, generated_imgs], d_fake)\n",
    "                ds_loss = 0.5 * np.add(ds_loss_real, ds_loss_fake)\n",
    "                if d_epochs > 1:\n",
    "                    print(f\"    {ks} [Ds loss: {ds_loss[0]}, acc.: {100*ds_loss[1]}]\")\n",
    "            self.s_discriminator.trainable = False\n",
    "            d_loss = ds_loss\n",
    "\n",
    "            #true_xval = self.s_discriminator.predict([gan_val[:batch_size], gan_val_truth[:batch_size]])\n",
    "            #fake_xval = self.generator.predict(gan_val[:batch_size])\n",
    "            #fake_xval = self.s_discriminator.predict([gan_val[:batch_size], fake_xval])\n",
    "                \n",
    "# Train the second discriminator\n",
    "#inputs: [advected generated frame t (from frame t-1), generated frame t+1 (from frame t)] &\n",
    "#        [advected ground truth of frame t-1 (advected frame t), ground truth frame t (frame t+1)]\n",
    "#batches are unmixed\n",
    "            if self.dual:\n",
    "                self.t_discriminator.trainable = True\n",
    "                for kt in range(d_epochs):\n",
    "                    real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth = self.create_training_batch(\n",
    "                                                                                        gan_train, gan_truth, batch_size, \"t\")\n",
    "                    #only need rain map from the synthetics\n",
    "                    if self.noisy_labels:\n",
    "                        d_real, d_fake = self.noisy_d_labels(real, fake)\n",
    "                        #print(\"Switching 5% of labels for spatial discriminator.\")\n",
    "                    else:\n",
    "                        d_real = real\n",
    "                        d_fake = fake\n",
    "                        \n",
    "                    dt_loss_real = self.t_discriminator.train_on_batch([advected_aux_truth, real_imgs], d_real)\n",
    "                    dt_loss_fake = self.t_discriminator.train_on_batch([advected_aux_gen, generated_imgs], d_fake)\n",
    "                    dt_loss = 0.5 * np.add(dt_loss_real, dt_loss_fake)\n",
    "                    #self.gradients[\"dt_grads\"].append(self.get_gradients(self.t_discriminator))\n",
    "                    if d_epochs > 1:\n",
    "                        print(f\"    {kt} [Dt loss: {dt_loss[0]}, acc.: {100*dt_loss[1]}]\")\n",
    "                d_loss = ds_loss + dt_loss\n",
    "                self.t_discriminator.trainable = False\n",
    "            \n",
    "# ---------------------\n",
    "#  Train Generator\n",
    "# ---------------------\n",
    "\n",
    "            idx = np.random.randint(0, gan_train.shape[0], batch_size)\n",
    "            if self.dual:\n",
    "                training_truth = gan_truth[idx]  # frame t+1, 4D: n, 64, 64, 1\n",
    "                aux_batch = gan_train[idx,:,:,:-1]  # from 0 to frame t-1 (not the last frame) 4D: n, 64, 64, past-1\n",
    "                training_batch = gan_train[idx,:,:,1:]  # from frame 1 to frame t, 4D: n, 64, 64, past-1\n",
    "                aux_gen_imgs = self.generator.predict(aux_batch) # 4D, n, 64, 64, 1: output is frame t  \n",
    "                # calculate optical flow for frame t-1 -> t\n",
    "                print(\"Calculating optical flow with Lucas Kanade method.\")\n",
    "                vx, vy = src.optical_flow(aux_batch[:,:,:,-1:], training_batch[:,:,:,-1:], window_size=4, tau=1e-2)\n",
    "                # concat channels\n",
    "                aux_gen_imgs = np.concatenate((aux_gen_imgs, vx, vy), axis=-1) #n, 64, 64, 3\n",
    "                # advect generated frame t\n",
    "                advected_aux_gen = np.array([src.advect(sample) for sample in aux_gen_imgs]) #4D (n, 64, 64, 1)\n",
    "            else:\n",
    "                training_batch = gan_train[idx]  # frame t or all past frames, 4D\n",
    "                training_truth = gan_truth[idx]  # frame t+1 or all future frames, 4D\n",
    "                #print(f\"Input shape: {training_batch.shape}\\nGround truth shape: {training_truth.shape} \")\n",
    "\n",
    "# Train the generator (to have the discriminator label samples as real)\n",
    "            if self.dual:\n",
    "                g_loss = self.combined.train_on_batch([training_batch, advected_aux_gen], [training_truth, g_real, g_real])\n",
    "            else:\n",
    "                g_loss = self.combined.train_on_batch(training_batch, [training_truth, g_real])\n",
    "\n",
    "# Plot the progress\n",
    "            self.log[\"g_loss\"].append(g_loss)\n",
    "            self.log[\"d_loss\"].append(d_loss[0])\n",
    "            #self.log[\"g_metric\"].append(g_loss[1])\n",
    "            self.log[\"d_metric\"].append([d_loss[1], ds_loss_fake[1], ds_loss_real[1]])\n",
    "            print(f\"\\033[1m {epoch}\\n[D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\"+\n",
    "                  f\"\\033[1m[G loss: {np.round(g_loss[0], 4)}, obj.: {np.round(g_loss[1], 4)},\"+\n",
    "                  f\"bce.: {np.round(g_loss[2], 4)}]\\033[0m\")#, xval fake.: {np.mean(fake_xval)}, \"+\n",
    "                  #f\"xval true: {np.mean(true_xval)}]\\033[0m\\n\"+\n",
    "                  \n",
    "           # self.gradients[\"g_grads\"].append(self.get_gradients(self.combined))\n",
    "\n",
    "\n",
    "# If at save interval => save generated image samples\n",
    "            if epoch in [int(x) for x in np.linspace(0,1,21)*epochs]: #20 figures\n",
    "                self.sample_images(epoch, gan_test, gan_test_truth)\n",
    "    \n",
    "    def create_training_batch(self, gan_train, gan_truth, batch_size, disc):\n",
    "        idx = np.random.randint(0, gan_truth.shape[0], batch_size)\n",
    "        # Generate a batch of new images\n",
    "        if self.dual:\n",
    "            #0,1->2\n",
    "            real_imgs = gan_truth[idx]  # frame t+1, 4D: n, 64, 64, 1\n",
    "            training_batch = gan_train[idx,:,:,1:]  # from frame 1 to end (t>=2), 4D: n, 64, 64, past-1\n",
    "            generated_imgs = self.generator.predict(training_batch) # n, h, w, 1, rho (4 dimensional, last drops)\n",
    "            if disc == \"t\":\n",
    "                aux_batch = gan_train[idx,:,:,:-1]  # from 0 to frame t-1 (not the last frame) 4D: n, 64, 64, past-1\n",
    "                aux_gen_imgs = self.generator.predict(aux_batch) # 4D, n, 64, 64, 1: output is frame t \n",
    "                # calculate optical flow for frame t-1 -> t\n",
    "                print(\"Calculating optical flow with Lucas Kanade method.\")\n",
    "                vx, vy = src.optical_flow(aux_batch[:,:,:,-1:], training_batch[:,:,:,-1:], window_size=4, tau=1e-2)\n",
    "                # concat channels\n",
    "                aux_gen_imgs = np.concatenate((aux_gen_imgs, vx, vy), axis=-1) #n, 64, 64, 3\n",
    "                aux_true_imgs = training_batch[:,:,:,-1:] #n, 64, 64, 1, frame t with all channels\n",
    "                aux_true_imgs = np.concatenate((aux_gen_imgs, vx, vy), axis=-1) #n, 64, 64, 3\n",
    "                # advected frame t (frame t+1)\n",
    "                advected_aux_gen = np.array([src.advect(sample) for sample in aux_gen_imgs]) #4D (n, h, w, m) (m: rho, vx, vy)\n",
    "                advected_aux_truth = np.array([src.advect(sample) for sample in aux_true_imgs]) #4D\n",
    "            else:\n",
    "                advected_aux_gen = None\n",
    "                advected_aux_truth = None\n",
    "            \n",
    "        else: # 4D\n",
    "            real_imgs = gan_truth[idx] # 4D\n",
    "            training_batch = gan_train[idx] # 4D\n",
    "            generated_imgs = self.generator.predict(training_batch) #4D\n",
    "            advected_aux_gen = None\n",
    "            advected_aux_truth = None\n",
    "        return real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth # all 4D\n",
    "    \n",
    "    def sample_images(self, epoch, gan_test, gan_test_truth):\n",
    "        n = 5\n",
    "        if self.dual:\n",
    "            test_batch = gan_test[:n,:,:,1:]  # frame 1 to t (0 is not used bc. its only used in advection), 4D\n",
    "        else:\n",
    "            test_batch = gan_test[:n]\n",
    "        test_truth = gan_test_truth[:n]\n",
    "        gen_imgs = self.generator.predict(test_batch)\n",
    "        plot_range = self.past_input if not self.dual else self.past_input-1\n",
    "        fig, axs = plt.subplots(n, plot_range+2, figsize=(16, 16))\n",
    "        for i in range(n):\n",
    "                vmax = np.max([np.max(test_batch[i]), np.max(test_truth[i])])\n",
    "                for j in range(plot_range):\n",
    "                    im = axs[i,j].imshow(test_batch[i, :,:,j], vmax=vmax)\n",
    "                    axs[i,j].axis('off')\n",
    "                    src.colorbar(im)\n",
    "                    axs[i,j].set_title(\"Frame t\"+str([-self.past_input+1+j if j < self.past_input-1 else \"\"][0]))\n",
    "                im2 = axs[i,-2].imshow(test_truth[i, :,:,0], vmax=vmax)\n",
    "                axs[i,-2].axis('off')\n",
    "                src.colorbar(im2)                \n",
    "                axs[i,-2].set_title(\"Frame t+1\")\n",
    "                im3 = axs[i,-1].imshow(gen_imgs[i, :,:,0], vmax=vmax)\n",
    "                axs[i,-1].axis('off')\n",
    "                src.colorbar(im3)\n",
    "                axs[i,-1].set_title(\"Prediction t+1\")\n",
    "        fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    def noisy_d_labels(self, real, fake):\n",
    "        # idea: https://arxiv.org/pdf/1606.03498.pdf\n",
    "        batch_size = len(real)\n",
    "        five_percent = int(0.08*batch_size)\n",
    "        idx = np.random.randint(0, batch_size, five_percent)\n",
    "        d_real = np.ones_like(real)*0.9\n",
    "        d_fake = np.zeros_like(fake)\n",
    "        d_real[idx] = 0\n",
    "        d_fake[idx] = 0.9\n",
    "        return d_real, d_fake\n",
    "    \n",
    "    def get_gradients(self, model):\n",
    "        \"\"\"Return the gradient of every trainable weight in model\n",
    "    \n",
    "        Parameters\n",
    "        -----------\n",
    "        model : a keras model instance\n",
    "    \n",
    "        First, find all tensors which are trainable in the model. Surprisingly,\n",
    "        `model.trainable_weights` will return tensors for which\n",
    "        trainable=False has been set on their layer (last time I checked), hence the extra check.\n",
    "        Next, get the gradients of the loss with respect to the weights.\n",
    "    \n",
    "        \"\"\"\n",
    "        weights = [tensor for tensor in model.trainable_weights]\n",
    "        optimizer = model.optimizer\n",
    "\n",
    "        return optimizer.get_gradients(model.total_loss, weights)\n",
    "    def update_loss_weights(self, epoch):\n",
    "        if epoch == self.objective_loss_constraint: # objective function constraint\n",
    "                self.loss_weights[0] -= 0.1#self.tenpercent_obj\n",
    "                #self.loss_weights[1:] = [x+self.tenpercent_obj for x in self.loss_weights[1:]]\n",
    "                self.objective_loss_constraint += 20\n",
    "                print(f\"***Updated loss weights: {self.loss_weights}***\\nNew threshold: {self.objective_loss_constraint}\")\n",
    "                self.combined.compile(loss=self.losses, optimizer=self.g_optimizer, loss_weights=self.loss_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#d dropout= 0.25\n",
    "gan= GAN(dual=False,\n",
    "         augment=True,\n",
    "         past=2,\n",
    "         g_dropout=0.1,\n",
    "         d_dropout=0.25,\n",
    "         batchnorm=True,\n",
    "         obj=1,\n",
    "         bce_s=1,\n",
    "         dynamic_loss = True,\n",
    "         noisy_labels=True,\n",
    "         loss_constraint=50)\n",
    "gan.combined.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.train(epochs=10000, d_epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(np.array(gan.log[\"g_loss\"])[:,1][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.log[\"d_metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "f = plt.figure(figsize=(16,4))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "g_labels = [\"Generator loss\"]\n",
    "#loop over gen loss components\n",
    "#for curve in range(np.shape(gan.log[\"g_loss\"])[-1]):\n",
    "ax.plot(np.array(gan.log[\"g_loss\"])[:,2], c=\"g\", label=\"Generator crossentropy\")\n",
    "\n",
    "ax.plot(np.array(gan.log[\"g_loss\"])[:,0] , alpha=0.3, c=\"b\")\n",
    "ax.plot(src.smooth(np.array(gan.log[\"g_loss\"])[:,0]) ,label=\"Generator loss\", c=\"b\")\n",
    "ax.plot(gan.log[\"d_loss\"], alpha=0.6, c=\"orange\")\n",
    "ax.plot(src.smooth(gan.log[\"d_loss\"]),label=\"Discriminator loss\", c=\"orange\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(np.array(gan.log[\"d_metric\"])[:,1],label=\"Fake metric\")\n",
    "ax2.plot(np.array(gan.log[\"d_metric\"])[:,2],label=\"Real metric\")\n",
    "\n",
    "ax2.grid()\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.legend(loc=\"best\")\n",
    "\n",
    "plt.savefig(f\"best_GAN_training_1_{gan.g_dropout}_{gan.d_dropout}.png\") #g dropout, d dropout, g batchnorm, noisy labels, loss weights, augment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Load datasets\n",
    "\n",
    "__<font color='red'>SHOW</font>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth = src.split_datasets(gan.train_data,\n",
    "                                                                                             gan.xval_data,\n",
    "                                                                                             gan.test_data,\n",
    "                                                            past_frames=2, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.combined.save(\"test\")\n",
    "reloaded = load_model(\"test\")\n",
    "#log = np.load(\"log_Spatial_GAN_5000.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = gan.combined.layers[1]\n",
    "discriminator = gan.combined.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generator.predict(gan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = src.calculate_skill_scores(predictions, gan_test_truth, gan_test, threshold=0.1)\n",
    "#print(np.mean(csi), np.mean(far), np.mean(pod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gan_test_truth[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predictions[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = discriminator.predict([predictions,gan_test])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmax(labels)\n",
    "worst = np.argmin(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(gan_test_truth, predictions)\n",
    "args[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(gan_test_truth,predictions, metric=\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src.result_plotter(args[:5], (gan_test[:,:,:,0], gan_test_truth[:,:,:,0], predictions[:,:,:,0], error_images[:,:,:,0]), save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN learns:\n",
    "#sharper but not more accurate\n",
    "#small rain patches disappear\n",
    "#learns an average wind motion: mostly to the right: applies that everywhere--> data augmentation based on optical flow\n",
    "#hourly dataset with wind is still not accurate enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train unet for 5min data, 1-1, 2-1, 3-1, best-more\n",
    "#train a single disc gan for the 5min and the h data, 1-1, 2-1, 3-1, best-more\n",
    "#train dual disc for hour data, 1-1, 2-1, 3-1, best-more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 frames to predict one future frame, use that as input for further predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN w.o. class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual = False #set this to True to train temporal discriminator\n",
    "augment = False\n",
    "noisy_labels = True\n",
    "g_batchnorm = True # in G\n",
    "d_batchnorm = True\n",
    "g_dropout = 0\n",
    "d_dropout = 0.25\n",
    "size = 64\n",
    "past_input = 1 #set this to change sequence length\n",
    "input_shape = (size, size, past_input) # 64, 64, t\n",
    "\n",
    "log = {\"g_loss\":[], \n",
    "       \"d_loss\":[],\n",
    "       \"g_metric\":[],\n",
    "       \"d_metric\":[]}\n",
    "gradients = {\"g_grads\":[],\n",
    "            \"ds_grads\":[],\n",
    "            \"dt_grads\":[]}\n",
    "inputs = []\n",
    "outputs = []\n",
    "train_data = None\n",
    "xval_data = None\n",
    "test_data = None\n",
    "     \n",
    "loss_weights = [1, 1]\n",
    "dynamic_loss = True\n",
    "objective_loss_constraint = 50\n",
    "tenpercent_obj = loss_weights[0]*0.1\n",
    "losses = [src.custom_loss(loss=\"l1\"), keras.losses.binary_crossentropy]\n",
    "d_metric = [keras.metrics.binary_accuracy]\n",
    "d_optimizer = keras.optimizers.SGD(lr=0.01)\n",
    "g_optimizer = keras.optimizers.Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-512aebe64e82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#build and compile temporal discriminator (same as s disc. but has different inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mt_discriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_dropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_batchnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mt_discriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_metric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "#build the generator\n",
    "generator = build_generator(input_shape, g_dropout, g_batchnorm)\n",
    "# The generator takes a sequence of frames as input and generates the next image in that sequence\n",
    "input_img = keras.layers.Input(shape=input_shape)\n",
    "generated = generator(input_img)\n",
    "inputs.append(input_img)\n",
    "outputs.append(generated)\n",
    "\n",
    "#build and compile spatial discriminator\n",
    "s_discriminator = build_discriminator(input_shape, d_dropout, d_batchnorm, \"s\")\n",
    "s_discriminator.compile(loss='binary_crossentropy', optimizer=d_optimizer, metrics=d_metric)\n",
    "# Spatial disc. takes the x as condition and G(x) and returns a float\n",
    "score_s = s_discriminator([input_img, generated])\n",
    "for layer in s_discriminator.layers:\n",
    "    layer.trainable = False\n",
    "s_discriminator.trainable = False\n",
    "outputs.append(score_s)\n",
    "\n",
    "#build and compile temporal discriminator (same as s disc. but has different inputs\n",
    "if self.dual:\n",
    "    t_discriminator = build_discriminator(input_shape, d_dropout, d_batchnorm, \"t\")\n",
    "    t_discriminator.compile(loss='binary_crossentropy', optimizer=self.d_optimizer, metrics=self.d_metric)\n",
    "    #Temporal disc. takes in advected frame A(G(x_previous)) and G(x)\n",
    "    adv = keras.layers.Input(shape=input_shape)\n",
    "    score_t = t_discriminator([adv, generated])\n",
    "    for layer in t_discriminator.layers:\n",
    "        layer.trainable = False\n",
    "    t_discriminator.trainable = False  \n",
    "    losses.append(keras.losses.binary_crossentropy)\n",
    "    loss_weights.append(1)\n",
    "    outputs.append(score_t)\n",
    "    inputs.append(adv)\n",
    "\n",
    "#build GAN model\n",
    "combined = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "#loss on all ouputs as a list: l1 loss on generated img, cross entropy for discriminator\n",
    "combined.compile(loss=losses, optimizer=g_optimizer, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(input_shape, g_dropout, g_batchnorm):  \n",
    "    generator = keras.Sequential()\n",
    "    return src.unet(input_shape, dropout=g_dropout, batchnorm=g_batchnorm)  # 64, 64, t\n",
    "\n",
    "def build_discriminator(input_shape, d_dropout, d_batchnorm, which=\"s\"):\n",
    "    if which == \"s\":\n",
    "        return src.spatial_discriminator(condition_shape=input_shape, dropout=d_dropout, batchnorm=d_batchnorm)\n",
    "    elif which == \"t\":\n",
    "        return src.temporal_discriminator(dropout=d_dropout, batchnorm=d_batchnorm)\n",
    "    \n",
    "def create_training_batch(gan_train, gan_truth, batch_size, disc, dual, generator):\n",
    "    idx = np.random.randint(0, gan_truth.shape[0], batch_size)\n",
    "    if dual:\n",
    "        real_imgs = gan_truth[idx]\n",
    "        training_batch = gan_train[idx,:,:,1:]\n",
    "        generated_imgs = generator.predict(training_batch)\n",
    "        if disc == \"t\":\n",
    "            aux_batch = gan_train[idx,:,:,:-1]\n",
    "            aux_gen_imgs = generator.predict(aux_batch)\n",
    "            # calculate optical flow for frame t-1 -> t\n",
    "            print(\"Calculating optical flow with Lucas Kanade method.\")\n",
    "            vx, vy = src.optical_flow(aux_batch[:,:,:,-1:], training_batch[:,:,:,-1:], window_size=4, tau=1e-2)\n",
    "            aux_gen_imgs = np.concatenate((aux_gen_imgs, vx, vy), axis=-1) #n, 64, 64, 3\n",
    "            aux_true_imgs = training_batch[:,:,:,-1:] #n, 64, 64, 1, frame t with all channels\n",
    "            aux_true_imgs = np.concatenate((aux_gen_imgs, vx, vy), axis=-1) #n, 64, 64, 3\n",
    "            # advected frame t (frame t+1)\n",
    "            advected_aux_gen = np.array([src.advect(sample) for sample in aux_gen_imgs]) #4D (n, h, w, m) (m: rho, vx, vy)\n",
    "            advected_aux_truth = np.array([src.advect(sample) for sample in aux_true_imgs]) #4D\n",
    "        else:\n",
    "            advected_aux_gen = None\n",
    "            advected_aux_truth = None\n",
    "        \n",
    "    else:\n",
    "        real_imgs = gan_truth[idx]\n",
    "        training_batch = gan_train[idx]\n",
    "        generated_imgs = generator.predict(training_batch)\n",
    "        advected_aux_gen = None\n",
    "        advected_aux_truth = None\n",
    "    return real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth\n",
    "    \n",
    "def sample_images(epoch, gan_test, gan_test_truth, dual, generator, past_input):\n",
    "    n = 5\n",
    "    if dual:\n",
    "        test_batch = gan_test[:n,:,:,1:]\n",
    "    else:\n",
    "        test_batch = gan_test[:n]\n",
    "    test_truth = gan_test_truth[:n]\n",
    "    gen_imgs = generator.predict(test_batch)\n",
    "    plot_range = past_input if not dual else past_input-1\n",
    "    fig, axs = plt.subplots(n, plot_range+2, figsize=(16, 16))\n",
    "    for i in range(n):\n",
    "        vmax = np.max([np.max(test_batch[i]), np.max(test_truth[i])])\n",
    "        for j in range(plot_range):\n",
    "            im = axs[i,j].imshow(test_batch[i, :,:,j], vmax=vmax)\n",
    "            axs[i,j].axis('off')\n",
    "            src.colorbar(im)\n",
    "            axs[i,j].set_title(\"Frame t\"+str([-past_input+1+j if j < past_input-1 else \"\"][0]))\n",
    "        im2 = axs[i,-2].imshow(test_truth[i, :,:,0], vmax=vmax)\n",
    "        axs[i,-2].axis('off')\n",
    "        src.colorbar(im2)                \n",
    "        axs[i,-2].set_title(\"Frame t+1\")\n",
    "        im3 = axs[i,-1].imshow(gen_imgs[i, :,:,0], vmax=vmax)\n",
    "        axs[i,-1].axis('off')\n",
    "        src.colorbar(im3)\n",
    "        axs[i,-1].set_title(\"Prediction t+1\")\n",
    "    fig.savefig(\"Plots/epoch %d.png\" % epoch)\n",
    "    plt.close()\n",
    "    \n",
    "def noisy_d_labels(real, fake, batch_size):\n",
    "    # idea: https://arxiv.org/pdf/1606.03498.pdf\n",
    "    batch_size = len(real)\n",
    "    five_percent = int(0.05*batch_size)\n",
    "    idx = np.random.randint(0, batch_size, five_percent)\n",
    "    d_real = np.ones_like(real)*0.9\n",
    "    d_fake = np.zeros_like(fake)\n",
    "    d_real[idx] = 0\n",
    "    d_fake[idx] = 0.9\n",
    "    return d_real, d_fake\n",
    "\n",
    "def update_loss_weights(epoch, objective_loss_constraint, loss_weights, combined, losses, g_optimizer):\n",
    "    if epoch == objective_loss_constraint:\n",
    "        loss_weights[0] -= 0.1\n",
    "        objective_loss_constraint += 20\n",
    "        print(f\"***Updated loss weights: {loss_weights}***\\nNew threshold: {objective_loss_constraint}\")\n",
    "        combined.compile(loss=losses, optimizer=g_optimizer, loss_weights=loss_weights)\n",
    "    return loss_weights, objective_loss_constraint, combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.dual:\n",
    "    past_input += 1\n",
    "    print(\"tempoGAN training: Increased input sequence length by one. First frame is only auxiliary for advection.\")\n",
    "else:\n",
    "    print(\"Normal GAN training.\")\n",
    "print(f\"Loading dataset.\")\n",
    "train_data, xval_data, test_data = src.load_datasets(past_input)\n",
    "train_data[np.isnan(train_data)] = 0\n",
    "xval_data[np.isnan(xval_data)] = 0\n",
    "test_data[np.isnan(test_data)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset to inputs and ground truths\n",
    "gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth = src.split_datasets(\n",
    "            train_data, xval_data, test_data, past_frames=past_input, augment=augment)\n",
    "# Adversarial ground truths\n",
    "real = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "#Generator ground truths\n",
    "g_real = np.ones((batch_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):           \n",
    "# update loss weights\n",
    "    if dynamic_loss and epoch > 0 and loss_weights[0] > 0.2:\n",
    "        update_loss_weights(epoch)\n",
    "# ---------------------\n",
    "#  Train Discriminators\n",
    "# ---------------------\n",
    "#inputs: [frame t, generated frame t+1 (from frame t)] & [frame t, ground truth of frame t (frame t+1)]\n",
    "    for layer in s_discriminator.layers:\n",
    "        layer.trainable = True\n",
    "    s_discriminator.trainable = True\n",
    "    for ks in range(d_epochs):\n",
    "        real_imgs, training_batch, generated_imgs, _, _ = create_training_batch(gan_train, gan_truth, batch_size, \"s\")\n",
    "        if noisy_labels:\n",
    "            d_real, d_fake = noisy_d_labels(real, fake)\n",
    "        else:\n",
    "            d_real = real\n",
    "            d_fake = fake\n",
    "                    \n",
    "        ds_loss_real = s_discriminator.train_on_batch([training_batch, real_imgs], d_real)\n",
    "        ds_loss_fake = s_discriminator.train_on_batch([training_batch, generated_imgs], d_fake)\n",
    "        ds_loss = 0.5 * np.add(ds_loss_real, ds_loss_fake)\n",
    "        if d_epochs > 1:\n",
    "                print(f\"    {ks} [Ds loss: {ds_loss[0]}, acc.: {100*ds_loss[1]}]\")\n",
    "        d_loss = ds_loss\n",
    "        for layer in s_discriminator.layers:\n",
    "            layer.trainable = False\n",
    "        s_discriminator.trainable = False\n",
    "    \n",
    "# Train the second discriminator\n",
    "#inputs: [advected generated frame t (from frame t-1), generated frame t+1 (from frame t)] &\n",
    "#        [advected ground truth of frame t-1 (advected frame t), ground truth frame t (frame t+1)]\n",
    "#batches are unmixed\n",
    "    if dual:\n",
    "        for layer in t_discriminator.layers:\n",
    "            layer.trainable = True\n",
    "        t_discriminator.trainable = True\n",
    "        for kt in range(d_epochs):\n",
    "            real_imgs, training_batch, generated_imgs, advected_aux_gen, advected_aux_truth = create_training_batch(\n",
    "                                                                                        gan_train, gan_truth, batch_size, \"t\")\n",
    "            #only need rain map from the synthetics\n",
    "            if noisy_labels:\n",
    "                d_real, d_fake = self.noisy_d_labels(real, fake)\n",
    "            else:\n",
    "                d_real = real\n",
    "                d_fake = fake    \n",
    "            dt_loss_real = t_discriminator.train_on_batch([advected_aux_truth, real_imgs], d_real)\n",
    "            dt_loss_fake = t_discriminator.train_on_batch([advected_aux_gen, generated_imgs], d_fake)\n",
    "            dt_loss = 0.5 * np.add(dt_loss_real, dt_loss_fake)\n",
    "            if d_epochs > 1:\n",
    "                    print(f\"    {kt} [Dt loss: {dt_loss[0]}, acc.: {100*dt_loss[1]}]\")\n",
    "            d_loss = ds_loss + dt_loss\n",
    "            for layer in t_discriminator.layers:\n",
    "                layer.trainable = False\n",
    "            t_discriminator.trainable = False \n",
    "# ---------------------\n",
    "#  Train Generator\n",
    "# ---------------------\n",
    "    idx = np.random.randint(0, gan_train.shape[0], batch_size)\n",
    "    if dual:\n",
    "        training_truth = gan_truth[idx] \n",
    "        aux_batch = gan_train[idx,:,:,:-1]\n",
    "        training_batch = gan_train[idx,:,:,1:]\n",
    "        aux_gen_imgs = self.generator.predict(aux_batch) # 4D, n, 64, 64, 1: output is frame t  \n",
    "        # calculate optical flow for frame t-1 -> t\n",
    "        vx, vy = src.optical_flow(aux_batch[:,:,:,-1:], training_batch[:,:,:,-1:], window_size=4, tau=1e-2)\n",
    "        # concat channels\n",
    "        aux_gen_imgs = np.concatenate((aux_gen_imgs, vx, vy), axis=-1) #n, 64, 64, 3\n",
    "        # advect generated frame t\n",
    "        advected_aux_gen = np.array([src.advect(sample) for sample in aux_gen_imgs]) #4D (n, 64, 64, 1)\n",
    "    else:\n",
    "        training_batch = gan_train[idx]  # frame t or all past frames, 4D\n",
    "        training_truth = gan_truth[idx]  # frame t+1 or all future frames, 4D\n",
    "# Train the generator (to have the discriminator label samples as real)\n",
    "    if dual:\n",
    "        g_loss = combined.train_on_batch([training_batch, advected_aux_gen], [training_truth, g_real, g_real])\n",
    "    else:\n",
    "        g_loss = combined.train_on_batch(training_batch, [training_truth, g_real])\n",
    "# Plot the progress\n",
    "    log[\"g_loss\"].append(g_loss)\n",
    "    log[\"d_loss\"].append(d_loss[0])\n",
    "    log[\"d_metric\"].append([d_loss[1], ds_loss_fake[1], ds_loss_real[1]])\n",
    "    print(f\"\\033[1m {epoch}\\n[D loss: {d_loss[0]}, acc.: {100*d_loss[1]}]\"+\n",
    "        f\"\\033[1m[G loss: {np.round(g_loss[0], 4)}, obj.: {np.round(g_loss[1], 4)},\"+\n",
    "        f\"bce.: {np.round(g_loss[2], 4)}]\\033[0m\")\n",
    "# If at save interval => save generated image samples\n",
    "    if epoch in [int(x) for x in np.linspace(0,1,21)*epochs]: #20 figures\n",
    "        sample_images(epoch, gan_test, gan_test_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
