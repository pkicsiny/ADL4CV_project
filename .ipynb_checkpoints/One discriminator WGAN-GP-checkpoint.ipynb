{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the datasets from here: https://drive.google.com/open?id=1mNEblJS0622w5-2mB6yCyMbu7RbcfENL<br>\n",
    "This should contain the following:\n",
    "- __5_min_train__: training data as np array. Shape: (7500, 64, 64, 8)\n",
    "- __5_min_xval__: validation data (currently unused) as np array. Shape: (1500, 64, 64, 8)\n",
    "- __5_min_test__: test data (used as visual validation during training) as np array. Shape: (1000, 64, 64, 8)\n",
    "- __5_min_norms__: list of floats containing the maximum pixel intensity value prior to normalization for each sequence. Shape: (10000,)\n",
    "- __5_min_long_pred__: test data for sequence prediction as np array. We used it for testing after training. Shape: (1000, 64, 64, 20)\n",
    "- __5_min_long_pred_norms__: list of floats containing the maximum pixel intensity value prior to normalization for each sequence for the 5_min_long_pred dataset. Shape: (1000,)\n",
    "- __tgan_1/2/4-1_vx/vy_2000__: optical flow images between the last and second last frames of the input for the first 2000 sequences of the training dataset (__5_min_train__) as np array. The 1/2/4 means the length of the input sequence. We mostly used 2. Shape: (2000, 64, 64, 1)\n",
    "- __germany__: Not needed. (GPS coordinates of Germany. Used for experimenting before.)\n",
    "\n",
    "In the datasets the first axis is stands for the sample, the next two for the frame height and width and the last for the channels which is the time axis here.<br>\n",
    "If data is missing or you cannot acces the drive, please write me an E-Mail: pkicsiny@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from functools import partial\n",
    "import importlib.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to src.py\n",
    "spec = importlib.util.spec_from_file_location(\"src.py\", \"C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/ADL4CV_project/src.py\")\n",
    "src = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(src)\n",
    "\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/ADL4CV_project/models/')\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset\n",
    "PAST is about the number of before frame. As we presented in 2nd presentation, our reference paper used 2 frames for input data. And we followed them. Also we augmented the training data by rotating the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAST = 2\n",
    "name = \"sgan_2-1_iw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set this to true if you want to use a pretrained model and load its weights from file\n",
    "use_loaded=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (7500, 64, 64, 3)\n",
      "Validation data: (1500, 64, 64, 3)\n",
      "Test data: (1000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "train, val, test = src.load_datasets(past_frames=PAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation.\n",
      "Shape of training data:  (8000, 64, 64, 2) \n",
      "Shape of training truth:  (8000, 64, 64, 1) \n",
      "Shape of validation data:  (1500, 64, 64, 2) \n",
      "Shape of validation truth:  (1500, 64, 64, 1) \n",
      "Shape of test data:  (1000, 64, 64, 2) \n",
      "Shape of test truth:  (1000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, T_train, X_val, T_val, X_test, T_test = src.split_datasets(\n",
    "            train[:2000], val, test, past_frames=PAST, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x203c8d11518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203c85b7128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of the our data\n",
    "plt.imshow(X_train[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to save images, and plot the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is to save the predicted image for every nth iteration.\n",
    "def sample_images(epoch, gan_test, gan_test_truth, generator, past_input, save_path):\n",
    "    # epoch: the iteration number of training\n",
    "    # gan_test: input data frames for testing\n",
    "    # gan_test_truth: output data frame for testing\n",
    "    # generator: trained generator model\n",
    "    # past_input: the number of frames for input data\n",
    "    # save_path: directory path to save \n",
    "    n = 5\n",
    "    test_batch = gan_test[:n]\n",
    "    test_truth = gan_test_truth[:n]\n",
    "    gen_imgs = generator.predict(test_batch)\n",
    "    plot_range = past_input \n",
    "    fig, axs = plt.subplots(n, plot_range+2, figsize=(16, 16))\n",
    "    for i in range(n):\n",
    "        vmax = np.max([np.max(test_batch[i]), np.max(test_truth[i])])\n",
    "        vmin = 0\n",
    "        for j in range(plot_range):\n",
    "            im = axs[i,j].imshow(test_batch[i, :,:,j], vmax=vmax,vmin=vmin)\n",
    "            axs[i,j].axis('off')\n",
    "            src.colorbar(im)\n",
    "            axs[i,j].set_title(\"Frame t\"+str([-past_input+1+j if j < past_input-1 else \"\"][0]))\n",
    "        im2 = axs[i,-2].imshow(test_truth[i, :,:,0], vmax=vmax, vmin=vmin)\n",
    "        axs[i,-2].axis('off')\n",
    "        src.colorbar(im2)                \n",
    "        axs[i,-2].set_title(\"Frame t+1\")\n",
    "        im3 = axs[i,-1].imshow(gen_imgs[i, :,:,0], vmax=vmax, vmin=vmin)\n",
    "        axs[i,-1].axis('off')\n",
    "        src.colorbar(im3)\n",
    "        axs[i,-1].set_title(\"Prediction t+1\")\n",
    "    fig.savefig(save_path+'epoch'+str(epoch)+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is to save the training curve for every nth iteration.\n",
    "def plot_training_curves(log, epoch, name, wgan=False, gp=False):\n",
    "    # log: a dictionary variable for losses\n",
    "    # epoch: the iteration number of training\n",
    "    # name: directory path to save \n",
    "    # wgan: is used for wgan(-gp) model or not\n",
    "    # gp: is used for wgan-gp model or not\n",
    "    total_g_loss = np.array(log[\"g_loss\"])[:, 0]\n",
    "    if gp == True and wgan == True : \n",
    "        total_d_loss = np.array(log[\"d_loss\"])[:, 0]\n",
    "    elif gp == False and wgan == True:\n",
    "        total_d_loss = np.array(log[\"d_loss\"])\n",
    "    elif wgan == False :\n",
    "        total_d_loss = np.array(log[\"d_loss\"])[:, 0]\n",
    "    smoothed_tgl = src.smooth(np.array(log[\"g_loss\"])[:, 0])\n",
    "    smoothed_tdl = src.smooth(total_d_loss)\n",
    "    objective_loss = np.array(log[\"g_loss\"])[:, 1]\n",
    "\n",
    "    f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [5, 2]})\n",
    "    a0.plot(total_g_loss, alpha=0.3, c=\"b\")\n",
    "    a0.plot(smoothed_tgl, c=\"b\", label=\"generator\")\n",
    "    a0.grid()\n",
    "    if wgan:\n",
    "        a0.plot(np.array(log[\"d_loss_real\"]), c=\"g\", label=\"real\")\n",
    "        a0.plot(np.array(log[\"d_loss_fake\"]), c=\"r\", label=\"fake\")\n",
    "    else:\n",
    "        a0.plot(total_d_loss, alpha=0.3, c=\"orange\")\n",
    "        a0.plot(smoothed_tdl, c=\"orange\", label=\"discriminator\")\n",
    "    a0.legend()\n",
    "    a1.plot(objective_loss, alpha=0.9, c=\"green\", label=\"L1 objective\")\n",
    "    a1.grid()\n",
    "    a1.legend()\n",
    "    f.text(0.5, 0, 'Iterations', ha='center', va='center')\n",
    "    f.text(0, 0.5, 'Loss', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "    f.tight_layout()\n",
    "    f.savefig(name+'epoch_'+str(epoch)+'_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is to save the image with real test dataset (only once after whole training)\n",
    "def save_examples(path, test, predictions_dict, past, future, samples=0):\n",
    "    # path: directory path to save \n",
    "    # test: test dataset\n",
    "    # prediction_dict: predicted images by the generator\n",
    "    # past: the number of frames for input data\n",
    "    # future: the number of framse to predict\n",
    "    # samples: indexes of test dataset to save\n",
    "    fig, axs = plt.subplots(len(samples)*2,past+future, figsize=(32, 32))\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.0)\n",
    "    for n in range(len(samples)):\n",
    "        vmax = np.max(test[n,:,:,:past])\n",
    "        vmin = 0\n",
    "        print(test.shape)\n",
    "        for i in range(past):\n",
    "            im = axs[2*n,i].imshow(test[samples[n], :,:,i], vmax=vmax,vmin=vmin)\n",
    "            axs[2*n,i].axis('off')\n",
    "            axs[2*n,i].set_title(f\"Past frame {i+1}\")\n",
    "            src.colorbar(im)\n",
    "            im = axs[2*n+1,i].imshow(test[samples[n], :,:,i], vmax=vmax,vmin=vmin)\n",
    "            axs[2*n+1,i].axis('off')\n",
    "            axs[2*n+1,i].set_title(f\"Past frame {i+1}\")\n",
    "            src.colorbar(im)\n",
    "        for i in range(past,past+future):\n",
    "            im = axs[2*n,i].imshow(predictions_dict[f\"{i-past}\"][samples[n], :,:,0], vmax=vmax, vmin=vmin)\n",
    "            axs[2*n,i].axis('off')\n",
    "            axs[2*n,i].set_title(f\"Predicted frame {i-past+1}\")\n",
    "            src.colorbar(im)\n",
    "            im = axs[2*n+1,i].imshow(test[samples[n], :,:,i], vmax=vmax, vmin=vmin)\n",
    "            axs[2*n+1,i].axis('off')\n",
    "            axs[2*n+1,i].set_title(f\"Reference frame {i-past+1}\")\n",
    "            src.colorbar(im)\n",
    "    fig.savefig(path+\"_sequence_prediction.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN    \n",
    "    reference sources:\n",
    "* https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "* https://myurasov.github.io/2017/09/24/wasserstein-gan-keras.html\n",
    "* https://github.com/bobchennan/Wasserstein-GAN-Keras/blob/master/mnist_wacgan.py\n",
    "* https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from 4nd reference\n",
    "# Funtion is to merge the ground truth and generated image with random weights\n",
    "class RandomWeightedAverage(keras.layers.Concatenate):\n",
    "    \"\"\"Takes a randomly-weighted average of two tensors. In geometric terms, this outputs a random point on the line\n",
    "    between each pair of input points.\n",
    "    Inheriting from _Merge is a little messy but it was the quickest solution I could think of.\n",
    "    Improvements appreciated.\"\"\"\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        weights = K.random_uniform((BATCH_SIZE, 1, 1, 1))\n",
    "        return (weights * inputs[0]) + ((1 - weights) * inputs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet is used for Generator\n",
    "G = src.unet(X_train.shape[1:], dropout=0, batchnorm=True, kernel_size=4, feature_mult=1)\n",
    "if use_loaded:\n",
    "    G.load_weights(sys.path[1]+name+\"/G_model.h5\")\n",
    "# G.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using loaded weights for prediction only then please skip to the __prediction__ section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convoluntional classifier is used for Discriminator\n",
    "SD = src.spatial_discriminator(condition_shape=X_train.shape[1:], dropout = 0.25, batchnorm=True, wgan=True)\n",
    "# SD.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters for training\n",
    "# random seed\n",
    "RND = 777\n",
    "np.random.seed(RND)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "ITERATIONS = 50\n",
    "\n",
    "# we train the discriminator 100 times for first 25 iterations (every start of 500 iterations)\n",
    "# and normally train the discriminator 10 times for each iteration\n",
    "INIT_D_ITERS = 100\n",
    "D_ITERS = 10\n",
    "\n",
    "GRADIENT_PENALTY_WEIGHT = 10\n",
    "#path to plot validation images\n",
    "PATH = '/Users/jlee/Desktop/JONG/TUM/18W/Advanced_Deep_Learning_for_Computer_Vision/project/results/wgan_results/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the discriminator's weights\n",
    "for l in SD.layers:\n",
    "    l.trainable = False\n",
    "SD.trainable = False\n",
    "\n",
    "# make a whole network to train the generator with freezed discriminator\n",
    "condition = keras.layers.Input(shape=X_train.shape[1:], name='input_condition_')\n",
    "generated = G(condition)\n",
    "output_is_fake = SD(inputs = [condition, generated])\n",
    "DG = keras.models.Model(inputs=[condition], outputs=[generated, output_is_fake])\n",
    "\n",
    "# keras.optimizers.Adam(0.0001, beta_1=0.5, beta_2=0.9)\n",
    "# in our reference code, they used Adam. But we found that RMSprop provides better results for our case.\n",
    "DG.compile(optimizer=keras.optimizers.RMSprop(lr=0.00005), \n",
    "           loss = [src.custom_loss(loss='l1'), src.wasserstein_loss],\n",
    "           loss_weights = [0,1]\n",
    ")\n",
    "DG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in SD.layers:\n",
    "    l.trainable = True\n",
    "for l in G.layers:\n",
    "    l.trainable = False\n",
    "SD.trainable = True\n",
    "G.trainable = False\n",
    "\n",
    "# make a network to train the discriminator with gradient penalty loss.\n",
    "real_samples = keras.layers.Input(shape=T_train.shape[1:])\n",
    "condition = keras.layers.Input(shape=X_train.shape[1:])\n",
    "generated = G(condition)\n",
    "d_output_generated = SD([condition, generated])\n",
    "d_output_real = SD([condition, real_samples])\n",
    "\n",
    "averaged_samples = RandomWeightedAverage()([real_samples, generated])\n",
    "averaged_samples_out = SD([condition, averaged_samples])\n",
    "\n",
    "partial_gp_loss = partial(src.gradient_penalty_loss,\n",
    "                          averaged_samples=averaged_samples,\n",
    "                          gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT)\n",
    "partial_gp_loss.__name__ = 'gradient_penalty' \n",
    "\n",
    "D = keras.models.Model(inputs=[condition, real_samples],\n",
    "          outputs=[d_output_real,\n",
    "                   d_output_generated,\n",
    "                   averaged_samples_out])\n",
    "\n",
    "# keras.optimizers.Adam(0.0001, beta_1=0.5, beta_2=0.9)\n",
    "# in our reference code, they used Adam. But we found that RMSprop provides more good results for our case.\n",
    "D.compile(optimizer=keras.optimizers.RMSprop(lr=0.00005),\n",
    "          loss=[src.wasserstein_loss, src.wasserstein_loss, partial_gp_loss])\n",
    "\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warning message (because there are huge messages when you freeze weights)\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "progress_bar = Progbar(target=ITERATIONS)\n",
    "\n",
    "log = {\"g_loss\":[],\n",
    "       \"d_loss\":[],\n",
    "       \"d_loss_gp\":[],\n",
    "       \"d_loss_real\":[],\n",
    "       \"d_loss_fake\":[],\n",
    "       \"d_loss_wgan\":[]}\n",
    "\n",
    "positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "negative_y = -positive_y\n",
    "dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for it in range(ITERATIONS+1):\n",
    "\n",
    "    if len(log['d_loss_real']) > 5:\n",
    "        progress_bar.update(\n",
    "            it,\n",
    "            values=[ # avg of 5 most recent\n",
    "                    ('d_loss_r', np.mean(log['d_loss_real'][-5:], axis=0)),\n",
    "                    ('d_loss_f', np.mean(log['d_loss_fake'][-5:], axis=0)),\n",
    "                    ('g_loss', np.mean(log['g_loss'][-5:],axis=0))\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        progress_bar.update(it)\n",
    "        \n",
    "    # 1: train D on real+generated images\n",
    "\n",
    "    if (it % 500) < 25 or it % 250 == 0: # 25 times in 1000, every 500th\n",
    "        d_iters = INIT_D_ITERS\n",
    "    else:\n",
    "        d_iters = D_ITERS\n",
    "     \n",
    "    # freeze G\n",
    "    for l in SD.layers:\n",
    "        l.trainable = True\n",
    "    for l in G.layers:\n",
    "        l.trainable = False\n",
    "    SD.trainable = True\n",
    "    G.trainable = False\n",
    "\n",
    "    for d_it in range(d_iters):\n",
    "\n",
    "        # random samples from training dataset\n",
    "        index = np.random.choice(len(X_train), BATCH_SIZE, replace=False)\n",
    "        base_images = X_train[index]\n",
    "        real_images = T_train[index]\n",
    "\n",
    "        # maximize D output on reals === minimize -1*(D(real))\n",
    "        # minimize D output on fakes === minimize 1*(D(fake))\n",
    "        D_loss = D.train_on_batch([base_images, real_images], [negative_y, positive_y, dummy_y])\n",
    "\n",
    "    # 2: train D(G) \n",
    "    \n",
    "    # freeze D\n",
    "    for l in SD.layers:\n",
    "        l.trainable = False\n",
    "    for l in G.layers:\n",
    "        l.trainable = True\n",
    "    SD.trainable = False\n",
    "    G.trainable = True\n",
    "        \n",
    "    # random samples from training dataset\n",
    "    index = np.random.choice(len(X_train), BATCH_SIZE, replace=False)\n",
    "    base_images = X_train[index]\n",
    "    real_images = T_train[index]\n",
    "\n",
    "    # maximize D output on fakes === minimize -1*(D(fake))\n",
    "    DG_loss = DG.train_on_batch(base_images, [real_images, negative_y])\n",
    "    \n",
    "    # store the losses \n",
    "    log['g_loss'].append(DG_loss)\n",
    "    log['d_loss_real'].append(D_loss[1])\n",
    "    log['d_loss_fake'].append(D_loss[2])\n",
    "    log['d_loss'].append(D_loss)\n",
    "    log['d_loss_gp'].append(D_loss[3])\n",
    "    log['d_loss_wgan'].append(-1 * D_loss[1] + D_loss[2])\n",
    "    \n",
    "    if it%100 == 0:\n",
    "        # every 100 iterations, save the predicted image\n",
    "        sample_images(it, X_test, T_test, G, PAST, PATH)\n",
    "    if it != 0 and it % 50 == 0:\n",
    "        # every 50 iterations, save the training curve\n",
    "        plot_training_curves(log, it, PATH, wgan=True, gp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models' weights\n",
    "G.save_weights(PATH+'G_model.h5')\n",
    "SD.save_weights(PATH+'SD_model.h5')\n",
    "DG.save_weights(PATH+'DG_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the losses\n",
    "np.save(PATH+\"_log\",log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predicted images\n",
    "G_imgs = G.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the difference with predicted image and ground truth image\n",
    "error_images, error_vals, error_means = src.error_distribution(T_test, G_imgs, metric=\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 images in test dataset with predicted image\n",
    "src.result_plotter(range(5), (X_test[:,:,:,0], T_test[:,:,:,0], G_imgs[:,:,:,0], error_images[:,:,:,0]), save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential prediction for future frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: (1000, 64, 64, 20)\n"
     ]
    }
   ],
   "source": [
    "# if the prediction is True with load_datasets function, it load test dataset and it contains 20 frames\n",
    "past = 2\n",
    "sequence_test = src.load_datasets(prediction=True)\n",
    "sequence_test = src.augment_data(sequence_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# predict the future frames (if past is 2, then 18 future frames will predicted) (ex. past: 3 --> 17)\n",
    "n_next = 5\n",
    "predictions = {}\n",
    "past_frames = sequence_test[...,0:past]\n",
    "test_truth = sequence_test[...,past:past+1]\n",
    "for t in range(n_next):\n",
    "    src.update_output(t)\n",
    "    future = gen.predict(past_frames, batch_size=64)\n",
    "    predictions[f\"{t}\"] = future\n",
    "    past_frames = np.concatenate((past_frames[:,:,:,1:], predictions[f\"{t}\"]), axis=-1)\n",
    "    test_truth = sequence_test[...,past+1+t:past+2+t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44, 110 in whole data w.o. augmenting, 33, 67 in augmented of the first 100\n",
    "src.sequence_prediction_plot(name, sequence_test, predictions, past, samples=[33,67,57])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation for scores and correlation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset to calculate the scores and correlation\n",
    "test_norms = np.load(sys.path[0]+\"/5min_long_pred_norms_compressed.npz\")[\"arr_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renormalize test samples\n",
    "renormalized_test = np.array([sample * np.array(test_norms)[i] for i, sample in enumerate(sequence_test)])\n",
    "renormalized_predictions = np.transpose((np.array([[sample * np.array(test_norms)[i] for i, sample in enumerate(predictions[key])] for key in list(map(str,np.arange(0,n_next)))])[:,:,:,:,0]), (1,2,3,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate pixel intensities back to dBZ and from there to mm/h. <br>\n",
    "Sources: <br>\n",
    "- https://www.dwd.de/DE/leistungen/radolan/radolan_info/radolan_radvor_op_komposit_format_pdf.pdf?__blob=publicationFile&v=11 (page 10)\n",
    "- <https://web.archive.org/web/20160113151652/http://www.desktopdoppler.com/help/nws-nexrad.htm#rainfall%20rates>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.5**(8/5)*200)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dBZ\n",
    "dBZ_t = renormalized_test*0.5 - 32.5\n",
    "dBZ_p = renormalized_predictions*0.5 - 32.5\n",
    "#mm/h\n",
    "I_t = (0.005*10**(0.1*dBZ_t))**(0.625)\n",
    "I_p = (0.005*10**(0.1*dBZ_p))**(0.625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_scores = src.get_scores(renormalized_predictions, renormalized_test, n_next, past, thresholds_as_list=[18])\n",
    "scores = src.get_scores(I_p, I_t, n_next, past, thresholds_as_list=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I_p[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I_t[0,:,:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(renormalized_predictions[0,:,:,0], vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(renormalized_test[0,:,:,-1], vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(name+\"_scores\",scores)\n",
    "np.save(name+\"_intensity_scores\",intensity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(scores['pred_1'][\"corr_to_truth\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(intensity_scores['pred_1'][\"corr_to_truth\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(intensity_scores['pred_1'][\"corr_to_input\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
