{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization, TimeDistributed, LSTM\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" for CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________-\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rain measurements\n",
    "Measurements are downloaded from the DWD (German weather service) open data server: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/__<br>\n",
    "I'm working with the data of August 2010 (based on [this](https://tradingeconomics.com/germany/precipitation)), so I have downloaded this: __ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/2010/RW-201008.tar__<br>\n",
    "_DWD manual:_<br>\n",
    "__ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/asc/BESCHREIBUNG_gridsgermany_hourly_radolan_historical_asc_de.pdf__<br><br>\n",
    "This contains radar maps recorded in every hour. Each map has a resolution of $900\\times900$ pixels and each pixel corresponds to an $1\\,km\\times1\\,km$ area in reality. Pixel values are the precipitation height in $0.1\\,mm$.\n",
    "Below I'm importing the data of this as a series of numpy arrays and plot them to see the acual radar map. The _sys.path[0]_ is the path on my computer and it can be different for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past = 2\n",
    "name = f\"lstm_{past}-1\"\n",
    "batch_size=64\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(past_frames=past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train, lstm_truth, lstm_val, lstm_val_truth, lstm_test, lstm_test_truth = src.split_datasets(\n",
    "            train[:2000], xval, test, past_frames=past, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_train = np.transpose(lstm_train, (0,3,1,2))\n",
    "#lstm_val = np.transpose(lstm_val, (0,3,1,2))\n",
    "#lstm_test = np.transpose(lstm_test, (0,3,1,2))\n",
    "lstm_train = np.reshape(lstm_train,(lstm_train.shape[0],)+(1,)+(lstm_train.shape[1:]))\n",
    "lstm_val = np.reshape(lstm_val,(lstm_val.shape[0],)+(1,)+(lstm_val.shape[1:]))\n",
    "lstm_test = np.reshape(lstm_test,(lstm_test.shape[0],)+(1,)+(lstm_test.shape[1:]))\n",
    "\n",
    "#lstm_truth = np.transpose(lstm_truth, (0,3,1,2))\n",
    "#lstm_val_truth = np.transpose(lstm_val_truth, (0,3,1,2))\n",
    "#lstm_test_truth = np.transpose(lstm_test_truth, (0,3,1,2))\n",
    "lstm_truth = np.reshape(lstm_truth,(lstm_truth.shape[0],)+(1,)+(lstm_truth.shape[1:]))\n",
    "lstm_val_truth = np.reshape(lstm_val_truth,(lstm_val_truth.shape[0],)+(1,)+(lstm_val_truth.shape[1:]))\n",
    "lstm_test_truth = np.reshape(lstm_test_truth,(lstm_test_truth.shape[0],)+(1,)+(lstm_test_truth.shape[1:]))\n",
    "print(f\"Training data: {lstm_train.shape}\\nValidation data: {lstm_val.shape}\\nTest data: {lstm_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_model = keras.Sequential()\n",
    "# define CNN model\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=8, kernel_size=5, strides=2, padding='same'))) #8\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=16, kernel_size=5, strides=2, padding='same')))\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=32, kernel_size=5, strides=2, padding='same')))\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=5, strides=2, padding='same')))\n",
    "lstm_model.add(keras.layers.BatchNormalization())\n",
    "lstm_model.add(keras.layers.Activation(\"relu\"))\n",
    "\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(\n",
    "    filters=128, kernel_size=5, strides=4, padding='same', activation='tanh')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "\n",
    "#LSTM\n",
    "lstm_model.add(keras.layers.LSTM(units=128, return_sequences=True))\n",
    "\n",
    "#upconv\n",
    "lstm_model.add(keras.layers.Reshape((1,1,1,128)))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=64,kernel_size=5,strides=4,padding='same', activation='relu'))) #64\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=32,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=16,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=8,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "lstm_model.add(keras.layers.TimeDistributed(keras.layers.Conv2DTranspose(\n",
    "    filters=1,kernel_size=5,strides=2,padding='same', activation='relu')))\n",
    "\n",
    "lstm_model.build((None,1,)+lstm_train.shape[2:])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
    "            keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=tf.train.AdamOptimizer(learning_rate = 0.0001),loss=src.custom_loss(\"l2+gdl\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "lstm_model.fit(lstm_train, lstm_truth,\n",
    "               validation_data=(lstm_val, lstm_val_truth),\n",
    "               batch_size = batch_size,\n",
    "               epochs=epochs,\n",
    "               callbacks=callback,\n",
    "               shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = lstm_model.history\n",
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'],)\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig('training.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "predictions = lstm_model.predict(lstm_test, batch_size=50)\n",
    "truth       = lstm_test_truth\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ordered predictions by pixelwise difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = src.arg_getter(truth, predictions)\n",
    "args[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(truth,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot and save examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src.result_plotter(args[:5], (lstm_test[:,0,:,:,0], truth[:,0,:,:,0], predictions[:,0,:,:,0], error_images[:,0,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
