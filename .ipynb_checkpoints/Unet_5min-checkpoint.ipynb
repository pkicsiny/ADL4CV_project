{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import keras.backend as K\n",
    "from os import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/ADL4CV_project/trainings')\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/TUM/3/ADL4CV/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forces CPU usage\n",
    "environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(past_frames=past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_train, gan_truth, gan_val, gan_val_truth, gan_test, gan_test_truth = src.split_datasets(\n",
    "            train[:2000], xval, test, past_frames=past, augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT!!!\n",
    "name = f\"unet_{past}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = src.unet(input_shape=(64, 64, past), dropout=0, batchnorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(learning_rate = 0.0001),loss=src.custom_loss(\"l1\"), metrics=[src.relative_error_tensor]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(gan_train,\n",
    "          gan_truth,\n",
    "          batch_size = 64,\n",
    "          epochs=20,\n",
    "          validation_data=(gan_val,gan_val_truth),\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.history\n",
    "hist.history.keys()\n",
    "plt.plot(hist.history['loss'],)\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig(name+'_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(name+\"_log\",hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(name+\"_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(sys.path[1]+f\"/U-net_{past}-1/\"+name+\"_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict future frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, xval, test = src.load_datasets(past_frames=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = src.augment_data(test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "predictions = {}\n",
    "past_frames = test_data[...,0:past]\n",
    "test_truth = test_data[...,past:past+1]\n",
    "for t in range(4): #predict 4 next\n",
    "    predictions[f\"{t}\"] = model.predict(past_frames, batch_size=64)\n",
    "    past_frames = np.concatenate((past_frames[:,:,:,1:], predictions[f\"{t}\"]), axis=-1)\n",
    "    test_truth = test_data[...,past+1+t:past+2+t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_examples(name, test_data, predictions, past, samples=[33,46,54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples(name, test, predictions_dict, past_frames, samples=0):\n",
    "    fig, axs = plt.subplots(len(samples)*2,past+4, figsize=(32, 32))\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.0)\n",
    "    for n in range(len(samples)):\n",
    "        vmax = np.max(test[n,:,:,:past])\n",
    "        vmin = 0\n",
    "        for i in range(past):\n",
    "            im = axs[2*n,i].imshow(test[samples[n], :,:,i], vmax=vmax,vmin=vmin)\n",
    "            axs[2*n,i].axis('off')\n",
    "            axs[2*n,i].set_title(f\"Past frame {i+1}\")\n",
    "            src.colorbar(im)\n",
    "            im = axs[2*n+1,i].imshow(test[samples[n], :,:,i], vmax=vmax,vmin=vmin)\n",
    "            axs[2*n+1,i].axis('off')\n",
    "            axs[2*n+1,i].set_title(f\"Past frame {i+1}\")\n",
    "            src.colorbar(im)\n",
    "        for i in range(past,past+4):\n",
    "            im = axs[2*n,i].imshow(predictions_dict[f\"{i-past}\"][samples[n], :,:,0], vmax=vmax, vmin=vmin)\n",
    "            axs[2*n,i].axis('off')\n",
    "            axs[2*n,i].set_title(f\"Predicted frame {i-past+1}\")\n",
    "            src.colorbar(im)                \n",
    "            im = axs[2*n+1,i].imshow(test[samples[n], :,:,i], vmax=vmax, vmin=vmin)\n",
    "            axs[2*n+1,i].axis('off')\n",
    "            axs[2*n+1,i].set_title(f\"Reference frame {i-past+1}\")\n",
    "            src.colorbar(im)\n",
    "    fig.savefig(f\"Plots/{name}_sequence_prediction.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(predictions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.load(sys.path[0]+\"/5min_norms_compressed.npz\")[\"arr_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *4 bc of augmentaion (it concats the frames so the 0th 1000th 2000th and 3000th are the same sample just rotated)\n",
    "test_norms = list(norms[9000:])*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#renormalize test samples\n",
    "renormalized_test = np.array([sample * np.array(test_norms)[i] for i, sample in enumerate(test_data)])\n",
    "renormalized_predictions = np.transpose((np.array([[sample * np.array(test_norms)[i] for i, sample in enumerate(predictions[key])] for key in list(predictions.keys())])[:,:,:,:,0]), (1,2,3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renormalized_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholds: 2, 8, 42\n",
    "thresholds = [10, 50, 100]\n",
    "scores = {}\n",
    "for t in range(renormalized_predictions.shape[-1]): # loop over the predictions (4)\n",
    "    for s in thresholds: # make a dict entry for each threshold score\n",
    "        scores[f\"pred_{t+1}_threshold_{s}\"] = src.calculate_skill_scores(renormalized_predictions[...,t:t+1],\n",
    "                                                                                     renormalized_test[...,past+t:past+1+t],\n",
    "                                                                                     x=renormalized_test[...,:past],\n",
    "                                                                                     threshold=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"pred_1_threshold_10\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(name+\"_scores\",scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_scores = np.load(sys.path[1]+f\"/U-net_{past}-1/\"+name+\"_scores.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(loaded_scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((pd.Series(loaded_scores[\"pred_1_threshold_100\"][\"corr_to_truth\"]).dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((pd.Series(loaded_scores[\"pred_2_threshold_100\"][\"corr_to_truth\"]).dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((pd.Series(loaded_scores[\"pred_3_threshold_100\"][\"corr_to_truth\"]).dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((pd.Series(loaded_scores[\"pred_4_threshold_100\"][\"corr_to_truth\"]).dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
