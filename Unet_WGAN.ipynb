{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../ADL4CV_project/')\n",
    "import src\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import math\n",
    "import io\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/Users/jlee/Desktop/JONG/TUM/18W/\\\n",
    "Advanced_Deep_Learning_for_Computer_Vision/project/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17445472360613635407\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (7500, 64, 64, 2)\n",
      "Validation data: (1500, 64, 64, 2)\n",
      "Test data: (1000, 64, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "train, val, test = src.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (7500, 64, 64, 1) \n",
      "Shape of training truth:  (7500, 64, 64, 1) \n",
      "Shape of validation data:  (1500, 64, 64, 1) \n",
      "Shape of validation truth:  (1500, 64, 64, 1) \n",
      "Shape of test data:  (1000, 64, 64, 1) \n",
      "Shape of test truth:  (1000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, T_train, X_val, T_val, X_test, T_test = src.split_datasets(\n",
    "            train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 64, 64, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ca8b6e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXuUXFd1p3+7qqvr0U+1Wo/Ww2pZb9nIkq3YsiHg2NiYpxMWsBJI7Mk4CCaQwYwTjGcyrCTDLGBlJThMBogGSEwGYjsOjj0Oy+AomEAA2fJLfklqSdajpW5J3ep3V1fX48wfVaq993HdVknqrm7n7m+tXn1unXPvPffeOnX3Pnufvck5B8MwwkVktjtgGEbtsYFvGCHEBr5hhBAb+IYRQmzgG0YIsYFvGCHEBr5hhJCLGvhEdAsR7SOiA0T02enqlGEYMwtdqAMPEUUB7AdwE4BuAE8D+A3n3CvT1z3DMGaCuovY92oAB5xzhwCAiO4HcCuAwIFfT3GXQMNFnNK4UAqtU9x3Cq6KDIxNf2fmAJMd+n64RKFcpkjwy7DuTFRtz7X7M4ExTLrMFE+0yMUM/KUAjontbgDXTLVDAg24hm68iFMaF8r4DcGPphAL/p40PviLmejOrHPsd65T25Mb0uVyfTwbuN+8BxvV9ly7P7vczqraXczAr/Rted1PJRFtB7AdABJIXcTpDMOYLi5m4HcDWC62lwE44Tdyzu0AsAMAmqnNVgTNEqmHd6nt9K1Xl8vRjH4syUeeqkmfZpPln/+Z2h790LZyufHB5wL3k+3eyFzMrP7TANYQ0Uoiqgfw6wAenZ5uGYYxk1zwG985lyOiTwL4AYAogG85516etp4ZhjFjXIyoD+fc9wF8f5r6YhhGjbhgO/6F0Extzmb1DWPm2OV2YtidOac5z1x2DSOE2MA3jBBiA98wQogNfMMIITbwDSOE2MA3jBBiA98wQogNfMMIITbwDSOEXJTLrlEbohvXqu38K/urqjPCQ/LHiwAAkY9WN6TtjW8YIcQGvmGEEBP15ygH7g0O+OAiHEZr/dcHatEdYw5w6Luby+VEclLVtU8WY//lXXXvcnvjG0YIsYFvGCHEBr5hhBDT8ecQMgCmpCBivvscuG2+2l5p+Yze0HR9hedvXFI/9zoEh/1elBoBAMQi+arOY298wwghNvANI4SYqD9HWfe1vnJ5//Z2Vbd2B9fl9x2oWZ+MmUHH6g+OgbluyclpO6e98Q0jhNjAN4wQYgPfMEKI6fhzCJmzThplVt2l9fjqDDbTQ2TT+nK5sGdvDc8cTqLtmXLZd8vtG+fU3u0pnZ770lRx3iceyVV1nnO+8YnoW0R0ioheEp+1EdETRNRV+j+vqrMZhjEnqEbU/xsAt3iffRbATufcGgA7S9uGYbxBOKeo75z7VyLq9D6+FcD1pfJ9AJ4EcPc09suYYYY/HLz6r/WlwXLZxPvpp/fT16ntkc0T5XJ0iv1aE+lyeWlqUNX1Z4tqQG6GV+ctcs71AEDp/8ILPI5hGLPAjE/uEdF2ANsBIIHUTJ/OMIwquNCBf5KIOpxzPUTUAeBUUEPn3A4AO4BittwLPJ8RQNdfXhNYV9fOomEkom99/OfBwl7zd028ny3q47wQp1DQSW9PjTYG7nflvGMAgDoKXtAluVBR/1EAt5fKtwN45AKPYxjGLFCNOe/vAPwcwDoi6iaiOwB8EcBNRNQF4KbStmEYbxCqmdX/jYCqG6e5L4Zh1Ajz3HsDsv/rImCHp9Ol2sfL5WyWjUPRqG43vJ51SUpoX8CR+64sl9fc/uxF9dV4PU3H8t52rFw+/k4WwlOtadWuMc6efO0J7bl3vpivvmGEEBv4hhFCTNSfQ0TXra74+b6Pt3ufsNjevnRI1eSFCai1gUXFwbGkajevY7hcHujXZqLEa/Gq+mtcGA0P7VLbYx8INslK+keD/WD2nSn60A1P/qyqY9kb3zBCiA18wwghNvANI4SYjj+LRC9bp7aP38wx8oc3cUAGiuiADLE4B1sYz8RUXUq4fKYnuW5+47hq1zvQxMdL6njt8/brYxozi9T51z7En3ffo1fxpdfzKr5+7xjyuVeDvfENI4TYwDeMEGKi/hxidIXwrsuIkAxJHUctm45VLANAOsKmuNZ57N3V098SeN7CyYTa7nlrQZTZS3Dt7z4FY25AT+nnedZwWxitbkjbG98wQogNfMMIISbqzyIj61rVtqsLiFMy5M2yy3ZJveCDRMCNoSH29IpEg2OgRBZNqO3Gp3m/xV+uzhPMmH6WfaH6e3/87uvO3Uhgb3zDCCE28A0jhNjAN4wQYjr+LJL6nl6ltX4fe/J13dZWLhfqtX5OeV6BV/B094IwA0Ym+He9blD/xic40zZGVuogHS2HqkvDZMwdln6pOB/Q7aoL0GFvfMMIITbwDSOEmKg/w+z/q19S22s/9nRV+63+zkC5fPDDOidprpFFc8oG/3aTsPStfLBP1e2/g1WJxiP6GMMreFuH7zD+vWBvfMMIITbwDSOE2MA3jBBiOv40cPBPr1Xb+eZgc9j+r/JqN8rp3GjSZVfWuXrtlrvsh1zXfbM250XHKv+WH7htvtqOTBG3Yck/83xAPriZ8QammhRay4noR0T0KhG9TESfKn3eRkRPEFFX6f+8cx3LMIy5QTWifg7AXc65DQC2AfgEEW0E8FkAO51zawDsLG0bhvEGoJrceT0AekrlESJ6FcBSALcCuL7U7D4ATwK4e0Z6OccpJLXnW2Q8GtASgJDunZe6Oprm3+FIhhvmU97KOidUAi9IRyHHK/nqhvl4zuuS9gbUKkf+lf0Vu278++G8JveIqBPAFgC7ACwq/Sic/XFYON2dMwxjZqh64BNRI4B/AHCnc274XO3FftuJaDcR7c4ic+4dDMOYcaoa+EQUQ3HQf8c5973SxyeJqKNU3wHgVKV9nXM7nHNbnXNbY7DUTIYxFzinjk9EBOCbAF51zv25qHoUwO0Avlj6/8iM9LDGTN7CLrb1j1fnXrvmk7sC607+Zx0ZZegKESPfc7eVK+gK4sn4kXmO3yg2RoJj4Mu5ATln4DO+JDg6j6GJblyrP8jz/E5+34Ea9+bCqcaO/2YAvwXgRSJ6vvTZf0VxwD9IRHcAOArggzPTRcMwpptqZvV/Cn/al7kx4HPDMOYwc9JzL7rmUrWd7zo0Y+c68ifa667jZ9MbhGLRV3TAxKFvbi2Xo03afW5+J3vMDYiUyG5SP6bcWHUprpyYUinU69/ulr18TL+PRjC+qVOK/mce43LkQe0p2frtn89sx84T89U3jBBiA98wQsicEfVzN15VLr92U72qyy7goBFr79gdeIzDn2exvfMPqxOtVnxuZkUwP+NpSkz8bniXFht7xporHiPvzf6TWLTjct5vt/QGlHVebL6hy1jNWFTxrOHl1Cf1MxvcyOofFbTKlOwYLZdT4Hva/w6dq6D129PZw4vH3viGEUJs4BtGCLGBbxghZNZ0fLrqMrUdybDeunhLr6rreX5xuXzgb7eUy23zdAzxJfET09nFC0aaI8dXaPNgagH3OVfQS+YWJLmuPsr34/BIu2pHY+Kx+bnzxio/Uj9AhwzmWfAbh5DIpvXl8uCWSV2ZEascY/puZSZ4PiqbFTkNovq5HPwOf29XfeS5i+rrdGBvfMMIITbwDSOE1FTUj66rQ9M3i2Lrsy80qrr5z4rfoOy4qlt4xclyOT3JXmutyXTgucbff43a9tNVBdH7aTblLP2BjkUPYlPO8ZvYM2vxvdrzbe/vLSiX25cNIIgrWrv1uTNsznv5eAdXpLVKQC0sivq+1AVhzouI9NrkrcMZWylMhyuvVnXJR54K7HMYiJ3WnpEyjwE8c15+lIfQqo8Fi/CjH9o2PZ2bJuyNbxghxAa+YYQQG/iGEULIudoFYViwcb771W+/GwAwltPRePZ+a0O5XHjfGVWXL/DvU30dm0mSMb26rbuLw/7JQJMAsOxJbhv7Ibv9Ri9bp9rt+x2OEl5o1CaZ5Y8JHf8D4tx9+lqiHTxH0dKoXTdXzeN5gzrSpqEXTi4pl9sb2bTXM6BdeZtSHMJsPKP1UWlekkhdFABQz+eOntHHyDfzdW+4l6Os5V/ep9pdiIu0MbPscjsx7M4ER10pYW98wwghNvANI4TU1Jw3nq3Hs6eWAwDynlmkkOLtaxYfVXWHhOdaJsddjvyF9miLvk3ErItrFab/MiECX8Ymu/Q1o6pdFCymt/li+j095XJf94pyObFKmx+T9awGTOb0Lb6p7RU+Rq5J1cUj7OXXNcQmwVRCe5JN5ti8VxfV6oKL87mbU9z/4XhCtUsPcAJs/16R8FQ78N+FGnNYBy1x4hFOvEebBBOPhdskONexN75hhBAb+IYRQmoq6ucydeg/VJw1l+miAGDVrx4pl39ydJXeTwSUyI6xyL72+zr8de7XODR2e8eQqmvdzF5+41mexS6ktQgcES5u/oz5SJbF3rULTpfLZyZSqt3NHa8iiMWxwXL5udEVqm4sz9fWHGcxfTSjZ+qlKtE/qD0gE0lWC5Y1iXPtX63ate9hOb1vq5cTVzyaXB+rBK5Vt6sbYpVjuFN/lYZFMIuFf8mejX6QC1ln1A574xtGCLGBbxghxAa+YYSQ2gbiqCsgMr+og+YHtN66/5Vl5fLyx7V5qXcb65JyLz+Yx7xn+HJu+tjeqrr0ynCH2s45/i30PesWJ0bK5S2NPCfhm+Xe0sAebmMF7dX3b2Mce31+vTYldo+3VuzjxGRwHP1UKjgR6USe97v2an0/9u1hT0n/5z8yIQJP1AWn5M6J2zOyQq8gzDfwfMDwvbwyrdnLMnXwz7iuZV+ww1n7DvMMnE7O+cYnogQRPUVELxDRy0T0x6XPVxLRLiLqIqIHiKiyr6hhGHOOakT9DIAbnHNXANgM4BYi2gbgSwC+7JxbA2AAwB0z103DMKaTanLnOQBnZdJY6c8BuAHAh0uf3wfgjwB8bcqD5SIo9BcFA1fvLQ4Scd/d7+kAGNleXjizYkl/uXwoskS1u/p6NqP1ZFoCu3F6gk1gRwbmqTppzvvgpTqwQtaxOCvNcq1R7bn3T0Oby+VNqWOqrjvN52uKac9AqWYc6uNAH9FocFS8DQtOqu39/ezxNzDBpjj/Ohsmxf33Yu4XhJieauNri8e0qL9kBS/gefk1/SzU8eLc/6G10cB2EW9xlvRQHJxgr8G5lo7qjUhVk3tEFC1lyj0F4AkABwEMOufOfhO6ASydmS4ahjHdVDXwnXN559xmAMsAXA1gQ6VmlfYlou1EtJuIdudHRys1MQyjxpyXOc85NwjgSQDbALQS0VlVYRmAirGtnXM7nHNbnXNbo42NlZoYhlFjzqnjE9ECAFnn3CARJQG8HcWJvR8B+ACA+wHcDuCRc54t4uBK+l5yvg6UOa9R6JJ1WpfcuIJXxW1o5pj7t7z3FdXuUJpX6y2OD6u69jqWNr7xwLvL5dE1+lw3XMnH3JI6XPk6AEwU2Ijx6oTWbzvq2V34QEZnpmur5wAb6bw2hMhrk/q5jLcP6LmAXEH/dstAJZKEp59Hf/MUbxz24vYLs50M7OHr+I0xNiW2LxhBEGPiGIUmbbLLjAUbg6Rr8sltfF1zLQ9drZCx/wt7qjNXB1GNHb8DwH1EFEVRQnjQOfcYEb0C4H4i+jyA5wB886J6YhhGzahmVn8PgC0VPj+Eor5vGMYbjJp67s1vGMVt24qrsXb1d6q6QSHa+qxu4pVwUoxeEtMx69clWCWYKGhvt0lhimt8B4vUn7v0nwPPuzSqV/jFhCffT8Z5tduxCW0q29J2OPCY+4Ra0DOpTY4/O7WyXB4Y5RV/b+/Qse6yIvXWJfF+VXewgeMO9k3ynMrPj3aqdrlsQ2Afk40swm9YeDKwnfRs3NSup3hkIBEp6i9s0RO8zQvZpOl7SsrcAnWtvOrwwL06Rv26HWwGzL+iU49PB35cRsnwBva2bHioutwNM8H+rxbfwZkvVGfqNF99wwghNvANI4TUVNRPRLLYkCiKhKuWaBFyXCxmeW70ElV3ffP5z2A2RYPTa/31hr8tl3+R1sEw6klkqc3NV3XDeQ7aIb313tcWnDqpgXS8vPY6tja8OKp9njoauO66ha+Vy5uS2vtPctpbIJSK8vmkh2IuW/2jdiKYnlyY5C8qOjjG4vyevmDPvQYRMzAa0eL8WDZ4Vl8GFZlIi3aex8i+j7aVy6s/HXi4C0aGFfdTsx1/hwhTfi2rIB3/pjtZbQq3nrs4UMmIZ3FSFC5ues3e+IYRQmzgG0YIsYFvGCGkpjp+wUXKgSn8FW1Zx13Z0qjj6i+pY7PdsSzr3YN5HeRSrp7zjx+jyh5tDRGtg/uedpIV9bxqUM4hdNZps+KgmK84ndfprw6K41+S1KvRWhpFQFDhGehfp1wZ6HNJPZv3ngHPlazuOKXa9Y+zOa9vVJsVf3XVHu5TXeU+ATrlV3NSrzQcndABSM4yVNDBTUdG2YzrBxVJj/MxSKyaLDR7uq/IAxDduFZVzYR5L4i8TLnmLuydOr6Yr7OpSw9PqfNTTntAnvWIfV3e9ADsjW8YIcQGvmGEkJqK+sP5BJ44sxEAsDjhLaKJsalodVyb+l6cWF4uvykRbNqKCs+v1ogW9fdm2AvsYSFub0keVu06hDfgUF57t8n4eW1R7u/hnPbck+yb6Ais89UPqUpIM11DRIvAUi365ZQOYrd3kq/tqnmsMn3v0BWq3fgoX8vyTh34RCLvz3PpTlX3m6s5r8FDR7RX98hQsCemJBoLDjJSEOJsU4tIB5YO/tp2/aGnFv09m99SD1dnUjvrBcedZPF78Y+1LB1Nsfj9uozEVTL+a9xHGbRkdGWl1tODvfENI4TYwDeMEGID3zBCSG1z5xUiGMwky2WFUM06PHOVdOedSt+X7QYLWtdLCT25J8srqnpz2pQlzW2+Di7NhfJcfbngyEL+MVLCfCiPBwB70nxt8h745rwFxG60XdkFqu4nI2zOGslq05lk8QJeeXjNgsOqTq74OzTJq/06vNWQPx7kwBB+nkESeRMK9ay3Lv0XrSMff7cwzenLhBOp1IcHuDLZ4gUpFbkVnfe9ajzI1ylnE0Y/pFf4NT74C1RD71u8OYkAvf7E2/R1rn64qsNj3Te4v/u2ewFjhUnTJQNSm7vq7Hn2xjeMEGID3zBCSM1F/VOjRbG41Yu598F5T5XLvpj+6Bk2FclgGEcn9eo56bXmm8B+eObycrkjweLUs2Odgf2VJsbiuUW8eXV8LeoP5diU9ehLm1Tdx678ScXjAUBLVHrJsSrhB+xY3szX+cTQ5apuKFvZjBaL6nMNi/Tgu/v1ashsG6sg65Mc3OQbR35Ztevp537lRrSoL98oqW7+mkWy2usu8Rpf5+Rr2tuPVrFIL8X+dL++xmgjH7OhQasBqr93XRdYByX6e+J8ns/9Oo85UV7/dTZRn09MvOM3cnndwap3U1BLSYWcIgeDxN74hhFCbOAbRgipqagfjTi0lBZzyFRPAPDDxjeVy76X2Xs7XyqXH9rH6alu2/iUaidF/xYvEEd7nMV2KdouSumw0Jc3cew4/xgLRBCN0zlefONbIWQobyna+7R4C4mkeC9n/OVCGQB4Scz+++pCe33lpCVLmrWn5Gv9HLzieL9WJfpG2WPx2RSf69hB/cyiaX5vtB7U75CFX/1ZxX4c/ZwWt1U23oIWo5N7WR0ZXxucFXheC4cf9wN9UD44ZZfkxDtYXWjcqxcjja7lMN9+1hi/z9UgPfV8tIqg21GW7/Hin+rz9pxVF6rsj73xDSOE2MA3jBBiA98wQkhNdfzJiRiO7FsMAFjzSb1S6sHPva1cbtmmg0YcTbM+evMqDnzo6+CSdXEd570vyya3a9s5kKUfXEIidXpAB9+QZalz+8jzAjovgI/U+eV8hTRT+kjTIaCDbY6LFF1943ql4fig2C+iNdf2f2Rz6rHruf9rf1fPqZz4A9bXc16Y/sy7fqlcjn+fV/E1Xq1XArYm+T4eOa1XOWaP8UEjday7Fyb1+yoZYx38RF+rqmsD39Nlj/N9fPX3PW/LKXTj5gU8bzJ82tsvw/tdbForQOcMWLdDzx3t/498bU33a0/DpvuL/wecnjcKouo3filV9nNE9FhpeyUR7SKiLiJ6gIiCR5BhGHOK8xH1PwXgVbH9JQBfds6tATAA4I7p7JhhGDNHVaI+ES0D8G4A/xPAfyEiAnADgA+XmtwH4I8AfG2q49QPOSx/vChWSlEQACZWsIi6rU0H4riyiQNK/NNJ9lQb87LNdsRZjH5P48uqbrzxULncm2XzlTSh+YxNUSdTcqW8uH3Sq++5Ya0GvDbGIvzaRq3SSDG9Ox0c3EOaC31V5WSGzYx7B3mBzel+HX+fxoLNXK0v8mKc1j1CDfDi2S35UzbZ+Wa6I7eKjQ9exX2HNp8uSvL2SLO+38nN/DyHhKfheDxYuMx7asDezwgdZIi9CyN1+pkVJngojK7OqjodNVEjPflkqi0Zix94fTx+yZInudzzlilONo1U+8a/F8BnwL6M8wEMOufOGj+7ASyttKNhGHOPcw58InoPgFPOuWfkxxWa+r4NZ/ffTkS7iWh3dnKsUhPDMGpMNaL+mwG8j4jeBSCBouRzL4BWIqorvfWXAThRaWfn3A4AOwCgqXVZxR8HwzBqyzkHvnPuHgD3AAARXQ/g951zHyGivwfwAQD3A7gdwCPnOhYNjSPx2FOVK4Ue+GzvMlXVEmOTz+omNgdtaTyi2v10aE25/NV+vZJMsq2Rl0BlPfOHjKvvp+FeHmNzkFxB6Mfml8EwnjmiV75JjjS3qe0zA6yPXrqEr7OtXktKfWI1YPe4Nl8loiL4owhKURjXjzo2OoWwl2M34Py+A4HNDv4Zm57cQm1ajQYc3nepnQqp10sinvmxd6CpYjuf5FKeG8lm9RxHRATUbGrU1zI0xM86Oqz3c9V5BGN4BTf0Q+53/BnPlax+iD/379TqO6s7VzVcjAPP3ShO9B1AUef/5vR0yTCMmea8HHicc08CeLJUPgTg4lJ2GoYxK9Q2hVZbA0beURQPxxZrYYPGWLwcLmg3sL6FLNq+0seieO88LeI9c0CnvNYn5/nIS7Zx6qrlnlfcltThwEPIeH9DIg7esQktsu86yf0gT7TN9/J+A158NDfEZqrxBWx6OjOp78c/7OPAJIkGrWYsamHz2GSOxct5HdoLsfkRNlKlDmqVZirxPogNy3vVdmOMTZqvnuZn1prQYnROyL2dLTql2AmR2kuK8wVvxZ2Mvy89/AAgGqucOs0nWsftFjbqFY6Ncb7Hx7zgL3V9/Jy6buPvQSHuxfTTWml1fVq3Wm3L59J9jzafjl9aNEFm/sfPqzq2+eobRgixgW8YIaSmon6+jkX8+KCemV32+cPl8uHfXqXqTt/BixXar2Mx+sBW7UmWEBPcl/5fbV0c3chebD9ey7P/ucJ61e79i9hd4a8Ov7XidQB6xvzkSS8MsvAeo4z+ba2bECrHN7Son23ge3L0vSxSnjimxcvoID+2iaSOdXekl9UCJ9IxNe3V7VKH2WowlWgvs8+m/0IHw4gPs1qxqeW4quvPcj/kTH4mr79yJ8dZhF/aELyAKS9m4eNJ7VlXiPF9zIxo7z8Zqy8mxP5sWt+PuKcyBdG+SKtMyWXcF6WOnNEWiZZDfA9cxEvDNYXH30xhb3zDCCE28A0jhNjAN4wQUlMdP1IA6oeLemzjCa2n5Xp5Rd6yL+jVeZLYMTa/JTt1EIpFX+HgBDp6O0DrOVDks8/xHIJLavNP+m187vpbtG59/Hq+XSs/y2YTT8NXFN6m00dHfvxcYFtppFr72BQHrRJlDiro6xx5E9+Pnju06Ul6o1GW9dHL6w+pdi3twTHscwU+yJaFrP/LFYMA0FTP8waj2eDVkNUSTWjznUxdPT4h8jV4r7xcltsd6NF9jIicBC2NwdesiOk5LBfhEzbt1wE2Xv2E+AbFeNVqrEnPqbgCB5ot5L0gNJNVuhCWsDe+YYQQG/iGEUJqa86LA0Ml6dNFtDllfoX2Z+nbfm25fOZKFrvip7RZZORu9mZq6AleCNj+LJcbeoMXjdQ//rTaXvn4FJ0MYCrRfqaZykzXfVd7ubx8pQ4IEq9jRUlmNZ4X1wuaLklqTzvJ2gZWmV4cCQ7VkBeeezlv9cpCkfNgoJHVukxGf239RTuS+DwWzQvCtDfVPlLsB7QpUS6kAoBUI4vj8Tjft+zIxastfh+zQu1ac29l8+PAaUuhZRhGADbwDSOE2MA3jBBS29x5qRzaNp8GAJxs1Svasneyfj56lTZVtM0TK+iOsl9upl2bbjKstiLb5AVMEFe65F9ZF/P1+H+v9N6pV3N1rmIT26VNeoViMsqm1sNj/JxOT+iY8uk8z9Osaww2wfZNsF6cimkzbiZXV7EMACez7AIr03xHElr3HR9nfTqZ0iYwP+DGWQpeHH254k+aAIsfiLZJ/Z0blfkJhKt2JK3Pe0J4f3dEdfAUkfkdrq661YRdd+qAo0E6fxD2xjeMEGID3zBCSE1F/UQ0h9WtxVVhZ9pSqm74MhbX/HhtZ7pY3JRV7nXeUbw9udQTfTIiDv5hXgVWnWD1xsdXn8ZFuqq1LdqclxVmtaUp9jI7mdYR5qWpT6Y5A4CBjH6+QfSNsBrgi9+ZMRZno/VidZtnsYoJM5oSvT1kkA5phgOA9Pj5eb5VRKT89mNOF8RKyeNv13UNr/EwXPolnVouiMAgHa46z0J74xtGCLGBbxghpKai/uhYAj9/qhj4Ir5MxzUrpPxlNUx8uQiLPMlddl7MuniCxfvJjPYMXPNFId5fQEy5Nzp0SnuS5dp4dr0/0+A3L7M4wd5zvmfd6THer7ug6xY38H6tcVYzjo3oGW1JZsALpy1EZ5kai3yPNuHJ58fckyK9tAzIkNmAjs3nPC0lkQqeMZdWg+xY7fLGXux32N74hhFCbOAbRgixgW8YIaSmOj4iDoWGoi6VPqUVqSsu48DjV7R2q7qXhzvK5UMDwev4BsXKqUse0OaZMOr1klV3/SKw7tht16rt5R/tKpd7J9h7rm9czwW8DT03AAAPnklEQVTUC515QYNOfy2ZyPF8y8Cofu4TF6AXR+qmWHk5L7gf/YPsebh0oQ6GsabldLk8lNVzDadEQNDmuDaX1Qm3u7oI349uby5Dpikv5PT7dnxj8PzWTFHVwCeiwwBGUDR755xzW4moDcADADoBHAbwIefcQNAxDMOYO5yPqP8rzrnNzrmtpe3PAtjpnFsDYGdp2zCMNwAXI+rfCuD6Uvk+FHPq3T3VDvXxHDo7i15iR3u1p1dnIy8U2ZQ8puqkqC/NMOu+qAND1P0Sm6zi368uldCFEl1zKW9E9O+nVCvqluvMvydu5ey544u1yDq5iEW+Dfdy/PaZjrXe+m19r7rev6FcrheLRvxMt3lhTj0+oiMPyrZjGRbnfdGeBnjb1evj1zWxyVGmIpsq7l17SmcWHs6w2N7azN+XVEyb6OTCpJWpPlWXbWa1sTs9T9VJ8V7SP6HVogXzWQU5M6zVnZwwR3bdd2W5vOb2ZzFTVPvGdwB+SETPENH20meLnHM9AFD6vzBwb8Mw5hTVvvHf7Jw7QUQLATxBRHurPUHph2I7AMQXVpfH3DCMmaWqN75z7kTp/ykAD6OYHvskEXUAQOn/qYB9dzjntjrntsZaq1u4YRjGzHLONz4RNQCIOOdGSuWbAfwJgEcB3A7gi6X/j5zrWIlotrwSbDTjuZCKOOw/GdE58aQ5RepKLqq7PyzUbq2JaZ08cwnX1u18BhdEPZuoRtZq002TWF54+NZ2VZe9gt2P/XTPMpDD6GrWmZMvX1gXL5TG7/K5Bz7E/W1Oad16dEIEwKjXATakXq9WzHmmLAq2zAUyNOrlpas21r1RphpRfxGAh4nobPvvOuceJ6KnATxIRHcAOArggzPXTcMwppNzDnzn3CEAV1T4vB/AjTPRKcMwZpaaeu6lczG8OrAYAFBfp72V9pxZUi7HvbpRITZmfsGee6Pv1Mdv3xMcVkOmjJKLzDIfuCZwn4aHgoMiuBiL6f2XaZF96FIW75d94Weq7thDl5fLWW9FW2SI1YfGvSKNdWAvZoaWF/jcPW/l+51t01+X+a2sBvhmtKY4r4o7nufrTHvx5mNLWUxv8uLlJUV8vry3ElMiU5YvSmjPPRlI5KUzbBY+NqDVs5FJ7tfyJm2KW5xg06rv1dczxsFJek+zirT6t3Q+BWnEjPy6Tlkm6dsUfJ3TifnqG0YIsYFvGCHEBr5hhJDa5s4rRDCULupI9V788KGXWJeMTmg9Z2IF634pYf4Zu1SbkJqPsK4dvWydquu+mXdMdvNl0xSpxk5+d7PajtXz3MOiFtYlY/+k9cXF92q9XrLi83zCvR/X7qsth/h3eDZXE8pzr/kkl/d//Wrdrpn7m8nrr9KIMNdGo3zNixYNqXZSP897wTal2++xrkWB/W3u4nMPvV+vupOus+lJnkPJTOh7f0KYHPs9HX/y1Jpy2XnRf6Jj/J1b/QfVuYk33R+8UrLp/qoOcdHYG98wQogNfMMIITUV9QsFwthYUdRPR7WoL601bqM2yTSKQIjZLbyqyk9EfOq9fDm9b/GCOopjpJeziiBXgPksW6DDC0hvwzohhk4l2vsUnn+lXF778ap3mxOkjuivy6L1/JwWJHTw1JF6vlfdCA6wKcV73/uvWoY3sSqYiGpTsHxOGZH+etVHgtOX+2pi/uUXL6hfcxl74xtGCLGBbxghpKaifrI+i8uXnQDw+sANyc0sNvpeWnI2VqZZingzrHK7oVN7kgV5geU97zkZJOF4v+6jpO841627SqeWcs9c2Kqa6EZenNRzPXv/LfyqViVk+qRazv63HtQmkJdfY2/LqWbr/QAekqh4Zk312nPPF9uN6cPe+IYRQmzgG0YIsYFvGCGkpjp+KjpZjpm/sblH1Y0X2JMqFdGBEJ8+s6Jc7h0ODt8VE96AUqcHtJ45MMqeWWPDerWVk4EiCsErpZY+we3OR6ePbN5YLu+/SxskF/8/3h5az9cy+FXtMRdNC2+3Rh1yJCLSPa/7Bpsjj98UnI+gWnMkFfzcz8H3R66+7Gjg1W1+vPlquepNh8rl0axvyGWOjuj7IdNwu5ea/eYVmengpnMBe+MbRgixgW8YIaSmon4dFdBeN3rOdn25RrUdF2adrR0cc38go4N3dvWxCWzSi2c3LES+TJrNg346JifipM/fqdWAeX9T3SKMqWKj7/24uDZtcUTPW7kvlGUxmjyR2nmh+iSFVOWwHcNrtWls7e8+FXwQQddXOFCJa9DHjjWwSjaS1uJ3a0MalbisrVdtF8DXVh/RfZRxGGUq78GJJIIYHk8E1uXWjgfWTQdSjTvwGb0IaMGj3K+pFunUCnvjG0YIsYFvGCHEBr5hhJDars5zVDbbtdfpFXgNEXbXXFA3rOqyLazrvSLy6J2Z0Dq+dNmdzGlFeOMi1i0vE6bEB/ZdqdrlxX79V2j9v+EJNivGp3AnbRpm/fa1+zfpPmbZzFiY0Ldfno1yrPs6bx5C1kXS+jploAhpllr/9fWqnXSijWzSdYoW7m/U60c+y+eOxbT+L91v5Qq5sbzWfXPCtTdX0M9TunX3nWYz7trf1rkQeu+8jvvhdf98Vk6GCXvjG0YIsYFvGCGkpqK+pDWqTStjwnPv2bFOVfeLk3r7LP7KuuuWvlYuL0/oIBoHxzmuvvQMXNiizYttCe7X0AJtGmoQqZUTIq3yoQHtFZee8AXOylAm+He3IFJG++a8df+Hr63rNp1unMTKQxlQIr8nOM/psXfqY6QvZ1WFhAJSyOl+kFArJsa1CH8oG+wpKHFS1M9otSUq7kHznmBvvbkizg+tZ8/AfFZ7n04V23E2qOqNT0StRPQQEe0loleJ6FoiaiOiJ4ioq/TfT1dnGMYcpVpR/y8APO6cW49iOq1XAXwWwE7n3BoAO0vbhmG8AagmW24zgLcC+A8A4JybBDBJRLcCuL7U7D4ATwK4e6pjxSM5rI6fBKBFewA4Osled0NZ7ZklRfqBIfbg2tp5RLWT+y2Oa8vAW1q6yuWscH27pEmrBNe0sLrgWxf2jC/n8tDScnmqWHGj41pEVTP5cS3/RYelqBu8AEZm0s0n9TGkWrDvoyyEFRJ6oc+G/8WBM8bWarEU41VqgAmeyY/GdD/icbZ6yOAp+bx+12SFh6KfSTefnsJFcQ4iPfJan1ut6mYzXHolqnnjXwrgNIC/JqLniOgbpXTZi5xzPQBQ+r9wBvtpGMY0Us3ArwNwJYCvOee2oOhhXrVYT0TbiWg3Ee0ePmOhlAxjLlDNwO8G0O2cO5s69iEUfwhOElEHAJT+n6q0s3Nuh3Nuq3Nua3PbrBkRDMMQnHMkOud6iegYEa1zzu0DcCOAV0p/twP4Yun/I+c6VgQFJEqmtAMZnRJpKMf6ub9KazzD5rH8CJf39CxR7f7Thp+Uyz2TOlDmi+PLyuWWOjZXtce1OU/q9THS3mjDoo8yHXPOMysuSPKyu+MR3Y8BsWrQnQ42UUnIM6OdeAsfg/Lam64g5w1EtyITuo9S/49oJ8pAfA/CxPzKK/AAIC3mNtrnBZ8gXc/PcyyizafafGgvjemk2rv5ewC+Q0T1AA4B+G0Uv1YPEtEdAI4C+ODMdNEwjOmmqoHvnHsewNYKVTdOb3cMw6gFNZWf6imPzrqi+awhpU1Iz6Y7y+WsF2lCZjalSRb/Cp5H218f3FYuv7/zBVV3dSPHbLsucbJcHvPjyAlO5FOBdUnhube+5aSq6x7nuHKtSS0Oy8Um5OUFKCR4OzYoVALPsie9wPzeR4Q3oItyrZ/lVaoBU9WBuC46qp8LiTo/8EZqXmUTZ9RzYZMBPPKTWh2R92d4PR9vccUjzy3mmvnOx3z1DSOE2MA3jBBiA98wQkhNdfzhQhI/GL0MALAucULVvTzKprl/O7pS1UmzjhMuqrms7v5gL+vku1tWqDoZ+COV7CuXF8a0CWm0MFEuny5oc95t7T8tl7975lruR0HrvjLnW09Wr9STK87yvstuI++XF+a3ghfkUkbRkHH0fVy90N3jlYNw+n3yqYtxnzLQ9yrdw4FDx5PazbouyfvlhsUcjWeaTHYEB191aX6+0TG+H72fvk61W/oDfp4j6/VasdT3dsF4PfbGN4wQYgPfMEIIORdszpr2kxGdBnAEQDuAvnM0n2nmQh8A64eP9UNzvv1Y4ZxbcK5GNR345ZMS7XbOVXIIClUfrB/Wj9nqh4n6hhFCbOAbRgiZrYG/Y5bOK5kLfQCsHz7WD82M9GNWdHzDMGYXE/UNI4TUdOAT0S1EtI+IDhBRzaLyEtG3iOgUEb0kPqt5eHAiWk5EPyqFKH+ZiD41G30hogQRPUVEL5T68celz1cS0a5SPx4oxV+YcYgoWorn+Nhs9YOIDhPRi0T0PBHtLn02G9+RmoSyr9nAJ6IogP8N4J0ANgL4DSLaOPVe08bfALjF+2w2woPnANzlnNsAYBuAT5TuQa37kgFwg3PuCgCbAdxCRNsAfAnAl0v9GABwxwz34yyfQjFk+1lmqx+/4pzbLMxns/EdqU0oe+dcTf4AXAvgB2L7HgD31PD8nQBeEtv7AHSUyh0A9tWqL6IPjwC4aTb7AiAF4FkA16DoKFJX6XnN4PmXlb7MNwB4DMW44rPRj8MA2r3PavpcADQDeA2lubeZ7EctRf2lAI6J7e7SZ7PFrIYHJ6JOAFsA7JqNvpTE6+dRDJL6BICDAAadc2dX19Tq+dwL4DPgpUfzZ6kfDsAPiegZItpe+qzWz6VmoexrOfArZYgIpUmBiBoB/AOAO51zw+dqPxM45/LOuc0ovnGvBrChUrOZ7AMRvQfAKeeczHs9W9+TNzvnrkRRFf0EEb21Buf0uahQ9udDLQd+N4DlYnsZgBMBbWtBVeHBpxsiiqE46L/jnPvebPYFAJxzgyhmQdoGoJWIzq6FrcXzeTOA9xHRYQD3oyju3zsL/YBz7kTp/ykAD6P4Y1jr53JRoezPh1oO/KcBrCnN2NYD+HUAj9bw/D6PohgWHKgyPPjFQkQE4JsAXnXO/fls9YWIFhBRa6mcBPB2FCeRfgTgA7Xqh3PuHufcMudcJ4rfh39xzn2k1v0gogYiajpbBnAzgJdQ4+finOsFcIyIzqY5PhvKfvr7MdOTJt4kxbsA7EdRn/xvNTzv3wHoAZBF8Vf1DhR1yZ0Aukr/22rQj7egKLbuAfB86e9dte4LgE0Aniv14yUAnyt9fimApwAcAPD3AOI1fEbXA3hsNvpROt8Lpb+Xz343Z+k7shnA7tKz+UcA82aiH+a5ZxghxDz3DCOE2MA3jBBiA98wQogNfMMIITbwDSOE2MA3jBBiA98wQogNfMMIIf8f2DW2hGAA7/sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN-GP\n",
    "    reference sources:\n",
    "* https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "* https://myurasov.github.io/2017/09/24/wasserstein-gan-keras.html\n",
    "* https://github.com/bobchennan/Wasserstein-GAN-Keras/blob/master/mnist_wacgan.py\n",
    "* https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Loss functions for WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples, gradient_penalty_weight):\n",
    "    \"\"\"Calculates the gradient penalty loss for a batch of \"averaged\" samples.\n",
    "    In Improved WGANs, the 1-Lipschitz constraint is enforced by adding a term to the loss function\n",
    "    that penalizes the network if the gradient norm moves away from 1. However, it is impossible to evaluate\n",
    "    this function at all points in the input space. The compromise used in the paper is to choose random points\n",
    "    on the lines between real and generated samples, and check the gradients at these points. Note that it is the\n",
    "    gradient w.r.t. the input averaged samples, not the weights of the discriminator, that we're penalizing!\n",
    "    In order to evaluate the gradients, we must first run samples through the generator and evaluate the loss.\n",
    "    Then we get the gradients of the discriminator w.r.t. the input averaged samples.\n",
    "    The l2 norm and penalty can then be calculated for this gradient.\n",
    "    Note that this loss function requires the original averaged samples as input, but Keras only supports passing\n",
    "    y_true and y_pred to loss functions. To get around this, we make a partial() of the function with the\n",
    "    averaged_samples argument, and use that for model training.\"\"\"\n",
    "    # first get the gradients:\n",
    "    #   assuming: - that y_pred has dimensions (batch_size, 1)\n",
    "    #             - averaged_samples has dimensions (batch_size, nbr_features)\n",
    "    # gradients afterwards has dimension (batch_size, nbr_features), basically\n",
    "    # a list of nbr_features-dimensional gradient vectors\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_G_Unet(input_shape=(64, 64, 1), dropout=0.0, batchnorm=False):\n",
    "    init = Input(shape=input_shape)\n",
    "    ConvDown1 = Conv2D(filters=32, kernel_size=(2, 2), strides=(1, 1), padding=\"same\")(init)\n",
    "    if batchnorm:\n",
    "        ConvDown1 = BatchNormalization()(ConvDown1)\n",
    "    Lr1 = LeakyReLU(alpha=0.1)(ConvDown1)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr1 = Dropout(dropout)(Lr1)\n",
    "    # 64\n",
    "    ConvDown2 = Conv2D(filters=32, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(Lr1)\n",
    "    if batchnorm:\n",
    "        ConvDown2 = BatchNormalization()(ConvDown2)\n",
    "    Lr2 = LeakyReLU(alpha=0.1)(ConvDown2)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr2 = Dropout(dropout)(Lr2)\n",
    "    # 32\n",
    "    ConvDown3 = Conv2D(filters=32, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(Lr2)\n",
    "    if batchnorm:\n",
    "        ConvDown3 = BatchNormalization()(ConvDown3)\n",
    "    Lr3 = LeakyReLU(alpha=0.1)(ConvDown3)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr3 = Dropout(dropout)(Lr3)\n",
    "    # 16\n",
    "    ConvDown4 = Conv2D(filters=32, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(Lr3)\n",
    "    if batchnorm:\n",
    "        ConvDown4 = BatchNormalization()(ConvDown4)\n",
    "    Lr4 = LeakyReLU(alpha=0.1)(ConvDown4)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr4 = Dropout(dropout)(Lr4)\n",
    "    # 8\n",
    "    ConvDown5 = Conv2D(filters=64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(Lr4)\n",
    "    if batchnorm:\n",
    "        ConvDown5 = BatchNormalization()(ConvDown5)\n",
    "    Lr5 = LeakyReLU(alpha=0.1)(ConvDown5)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr5 = Dropout(dropout)(Lr5)\n",
    "    # 4\n",
    "\n",
    "    # 8\n",
    "    UpSamp1 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr5)\n",
    "    merge1 = concatenate([ConvDown4, UpSamp1], axis=-1)\n",
    "    Conv1 = Conv2D(filters=32, kernel_size=(4, 4), strides=(1, 1), padding=\"same\")(merge1)\n",
    "    if batchnorm:\n",
    "        Conv1 = BatchNormalization()(Conv1)\n",
    "    Lr6 = LeakyReLU(alpha=0.1)(Conv1)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr6 = keras.layers.Dropout(dropout)(Lr6)\n",
    "    # 16\n",
    "    UpSamp2 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr6)\n",
    "    merge2 = concatenate([ConvDown3, UpSamp2], axis=-1)\n",
    "    Conv2 = Conv2D(filters=32, kernel_size=(4, 4), strides=(1, 1), padding=\"same\")(merge2)\n",
    "    if batchnorm:\n",
    "        Conv2 = BatchNormalization()(Conv2)\n",
    "    Lr7 = LeakyReLU(alpha=0.1)(Conv2)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr7 = Dropout(dropout)(Lr7)\n",
    "    # 32\n",
    "    UpSamp3 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr7)\n",
    "    merge3 = concatenate([ConvDown2, UpSamp3], axis=-1)\n",
    "    Conv3 = Conv2D(filters=32, kernel_size=(4, 4), strides=(1, 1), padding=\"same\")(merge3)\n",
    "    if batchnorm:\n",
    "        Conv3 = BatchNormalization()(Conv3)\n",
    "    Lr8 = LeakyReLU(alpha=0.1)(Conv3)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr8 = Dropout(dropout)(Lr8)\n",
    "    # 64\n",
    "    UpSamp4 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr8)\n",
    "    merge4 = concatenate([ConvDown1, UpSamp4], axis=-1)\n",
    "    Conv4 = Conv2D(filters=32, kernel_size=(4, 4), strides=(1, 1), padding=\"same\")(merge4)\n",
    "    if batchnorm:\n",
    "        Conv4 = BatchNormalization()(Conv4)\n",
    "    Lr9 = LeakyReLU(alpha=0.1)(Conv4)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        Lr9 = Dropout(dropout)(Lr9)\n",
    "\n",
    "    Conv5 = Conv2D(filters=1, kernel_size=(4, 4), strides=(1, 1),\n",
    "                                padding=\"same\", activation='tanh')(Lr9)\n",
    "\n",
    "    return Model(inputs=init, outputs=Conv5, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 32)   160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   4128        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 32)   4128        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 32)     4128        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 32)     128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 32)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 4, 4, 64)     8256        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 4, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 4, 4, 64)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 64)     0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 96)     0           batch_normalization_4[0][0]      \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 32)     49184       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 32)     128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 8, 8, 32)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 32)   0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 32)   32800       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 32)   0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 32)   32800       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 32)   0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 32)   32800       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 64, 64, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 1)    513         leaky_re_lu_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 170,177\n",
      "Trainable params: 169,537\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G = build_G_Unet(batchnorm=True)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Discriminator Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Spatial_D(input_shape=(64, 64, 1), condition_shape=(64, 64, 1), dropout=0.3, batchnorm=False):\n",
    "    # condition is the frame t (the original frame) or the sequence of past frames\n",
    "    condition = Input(shape=condition_shape)\n",
    "    # other is the generated prediction of frame t+1 or the ground truth frame t+1\n",
    "    other = Input(shape=input_shape)\n",
    "    # Concatenate image and conditioning image by channels to produce input\n",
    "    combined_imgs = Concatenate(axis=-1)([condition, other])\n",
    "\n",
    "    conv1 = Conv2D(filters=16, kernel_size=4, strides=2, padding='same')(combined_imgs)\n",
    "    if batchnorm:\n",
    "        conv1   = BatchNormalization()(conv1)\n",
    "    relu1 = LeakyReLU(alpha=0.2)(conv1)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        relu1 = Dropout(dropout)(relu1)\n",
    "\n",
    "    conv2 = Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(relu1)\n",
    "    if batchnorm:\n",
    "        conv2   = BatchNormalization()(conv2)\n",
    "    relu2 = LeakyReLU(alpha=0.2)(conv2)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        relu2 = Dropout(dropout)(relu2)\n",
    "\n",
    "    conv3 = Conv2D(filters=64, kernel_size=4, strides=2, padding='same')(relu2)\n",
    "    if batchnorm:\n",
    "        conv3   = BatchNormalization()(conv3)\n",
    "    relu3 = LeakyReLU(alpha=0.2)(conv3)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        relu3 = Dropout(dropout)(relu3)\n",
    "\n",
    "    conv4 = Conv2D(filters=128, kernel_size=4, strides=2, padding='same')(relu3)\n",
    "    if batchnorm:\n",
    "        conv4   = BatchNormalization()(conv4)\n",
    "    relu4 = LeakyReLU(alpha=0.2)(conv4)\n",
    "    if (dropout > 0) and (dropout <= 1):\n",
    "        relu4 = Dropout(dropout)(relu4)\n",
    "\n",
    "    # Out: 1-dim probability\n",
    "    flatten = Flatten()(relu4)\n",
    "    fcl1 = Dense(1)(flatten)\n",
    "    # sig1 = Activation('sigmoid', name=\"s_disc_output\")(fcl1)\n",
    "    # For WGAN, there is no activation function\n",
    "    lin1 = Activation('linear', name=\"s_disc_output\")(fcl1)\n",
    "\n",
    "    return Model(inputs=[condition, other], outputs=lin1, name='SD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 2)    0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 16)   528         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 16)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 16)   0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   8224        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 32)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 32)   0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 64)     32832       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 8, 8, 64)     0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 64)     0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 128)    131200      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 4, 4, 128)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 4, 128)    0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "s_disc_output (Activation)      (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 174,833\n",
      "Trainable params: 174,833\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SD = build_Spatial_D()\n",
    "SD.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIENT_PENALTY_WEIGHT = 10  # As per the paper\n",
    "\n",
    "# random seed\n",
    "RND = 777\n",
    "np.random.seed(RND)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "ITERATIONS = 20000\n",
    "D_ITERS = 10\n",
    "\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_condition_ (InputLayer)   (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "G (Model)                       (None, 64, 64, 1)    170177      input_condition_[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "SD (Model)                      (None, 1)            175793      input_condition_[0][0]           \n",
      "                                                                 G[1][0]                          \n",
      "==================================================================================================\n",
      "Total params: 345,970\n",
      "Trainable params: 344,850\n",
      "Non-trainable params: 1,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D = build_Spatial_D(batchnorm=True)\n",
    "\n",
    "D.compile(\n",
    "    optimizer = RMSprop(lr=0.00005),\n",
    "    loss = wasserstein_loss)\n",
    "\n",
    "condition = Input(shape=(64, 64, 1), name='input_condition_')\n",
    "other = Input(shape=(64, 64, 1),name='input_other_')\n",
    "\n",
    "G = build_G_Unet(batchnorm=True)\n",
    "\n",
    "# create combined D(G) model\n",
    "output_is_fake = D(inputs = [condition, G(condition)])\n",
    "DG = Model(condition, outputs=output_is_fake)\n",
    "\n",
    "DG.summary()\n",
    "\n",
    "DG.compile(\n",
    "    optimizer = RMSprop(lr=0.00005),\n",
    "    loss = wasserstein_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "progress_bar = Progbar(target=ITERATIONS)\n",
    "\n",
    "DG_losses = []\n",
    "D_true_losses = []\n",
    "D_fake_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12514/20000 [=================>............] - ETA: 12:52:56 - D_real_is_fake: -0.1661 - D_fake_is_fake: 0.1677 - D(G)_is_fake: -0.1660"
     ]
    }
   ],
   "source": [
    "for it in range(ITERATIONS):\n",
    "\n",
    "    if len(D_true_losses) > 0:\n",
    "        progress_bar.update(\n",
    "            it,\n",
    "            values=[ # avg of 5 most recent\n",
    "                    ('D_real_is_fake', np.mean(D_true_losses[-5:], axis=0)),\n",
    "                    ('D_fake_is_fake', np.mean(D_fake_losses[-5:], axis=0)),\n",
    "                    ('D(G)_is_fake', np.mean(DG_losses[-5:],axis=0))\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        progress_bar.update(it)\n",
    "        \n",
    "    # 1: train D on real+generated images\n",
    "\n",
    "    if (it % 1000) < 25 or it % 500 == 0: # 25 times in 1000, every 500th\n",
    "        d_iters = 100\n",
    "    else:\n",
    "        d_iters = D_ITERS\n",
    "\n",
    "    for d_it in range(d_iters):\n",
    "\n",
    "        # unfreeze D\n",
    "        D.trainable = True\n",
    "        for l in D.layers: l.trainable = True\n",
    "\n",
    "        # clip D weights\n",
    "\n",
    "        for l in D.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "        # 1.1: maximize D output on reals === minimize -1*(D(real))\n",
    "\n",
    "        # draw random samples from real images\n",
    "        index = np.random.choice(len(X_train), BATCH_SIZE, replace=False)\n",
    "        base_images = X_train[index]\n",
    "        real_images = T_train[index]\n",
    "\n",
    "        D_loss = D.train_on_batch([base_images, real_images], -np.ones(BATCH_SIZE))\n",
    "        #print(D_loss)\n",
    "        D_true_losses.append(D_loss)\n",
    "\n",
    "        # 1.2: minimize D output on fakes \n",
    "\n",
    "        generated_images = G.predict(base_images)\n",
    "\n",
    "        D_loss = D.train_on_batch([base_images, generated_images], np.ones(BATCH_SIZE))\n",
    "        #print(D_loss)\n",
    "        D_fake_losses.append(D_loss)\n",
    "\n",
    "    # 2: train D(G) (D is frozen)\n",
    "    # minimize D output while supplying it with fakes, \n",
    "    # telling it that they are reals (-1)\n",
    "\n",
    "    # freeze D\n",
    "    D.trainable = False\n",
    "    for l in D.layers: l.trainable = False\n",
    "        \n",
    "    index = np.random.choice(len(X_train), BATCH_SIZE, replace=False)\n",
    "    base_images = X_train[index]\n",
    "\n",
    "    DG_loss = DG.train_on_batch(base_images,-np.ones(BATCH_SIZE))\n",
    "    DG_losses.append(DG_loss)\n",
    "\n",
    "#    if it % 10 == 0:\n",
    "#        update_tb_summary(it, write_sample_images=(it % 250 == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.save_weights('/Users/jlee/Desktop/JONG/TUM/18W/Advanced_Deep_Learning_for_Computer_Vision/project/results/wgan_results/iter_20000_RMSprop_0.00005/G_model.h5')\n",
    "D.save_weights('/Users/jlee/Desktop/JONG/TUM/18W/Advanced_Deep_Learning_for_Computer_Vision/project/results/wgan_results/iter_20000_RMSprop_0.00005/D_model.h5')\n",
    "DG.save_weights('/Users/jlee/Desktop/JONG/TUM/18W/Advanced_Deep_Learning_for_Computer_Vision/project/results/wgan_results/iter_20000_RMSprop_0.00005/DG_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_imgs = G.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(T_test[1,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(G_imgs[1,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16,4))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "g_labels = [\"Generator loss\"]\n",
    "#loop over gen loss components\n",
    "#for curve in range(np.shape(gan.log[\"g_loss\"])[-1]):\n",
    "ax.plot(DG_losses, c=\"g\", label=\"G_loss\")\n",
    "\n",
    "ax.plot(D_true_losses, alpha=0.3, c=\"b\")\n",
    "ax.plot(src.smooth(D_true_losses) ,label=\"D_true_loss\", c=\"b\")\n",
    "ax.plot(D_fake_losses, alpha=0.6, c=\"orange\")\n",
    "ax.plot(src.smooth(D_fake_losses),label=\"D_fake_loss\", c=\"orange\")\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "#plt.savefig(f\"best_GAN_training_1_{gan.g_dropout}_{gan.d_dropout}.png\") #g dropout, d dropout, g batchnorm, noisy labels, loss weights, augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"src.py\", \"/Users/jlee/Desktop/JONG/TUM/18W/Advanced_Deep_Learning_for_Computer_Vision/project/ADL4CV_project/src.py\")\n",
    "src = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(src)\n",
    "#import importlib as imp\n",
    "#imp.reload(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(T_test, G_imgs, metric=\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.result_plotter(range(5), (X_test[:,:,:,0], T_test[:,:,:,0], G_imgs[:,:,:,0], error_images[:,:,:,0]), save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
