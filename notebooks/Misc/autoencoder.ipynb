{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOENCODERS FOR GENERATOR\n",
    "##### convolutional autoencoder, variational autoencoder, u-net, residual u-net, recurrent u-net, r2u-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import colors\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import clear_output\n",
    "#data folder\n",
    "sys.path.insert(0, '/Users/jlee/Desktop/JONG/TUM/18W/\\\n",
    "Advanced_Deep_Learning_for_Computer_Vision/project/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forces CPU usage\n",
    "environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #\"\" or \"-1\" for CPU, \"0\" for GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = src.get_data(sys.path[0]+\"/RW-201008\", total_length=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = src.generate_datasets(inputs, n=1000, size=64, length=2, normalize=True, split=(6,2,2))\n",
    "images = np.load(sys.path[0]+\"/dataset.npy\").item()\n",
    "# images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low_res_train = images[\"low_res_train\"]\n",
    "#low_res_xval = images[\"low_res_xval\"]\n",
    "#low_res_test = images[\"low_res_test\"]\n",
    "#overfit = np.reshape(images['images'],np.shape(images['images'])+(1,))\n",
    "train = np.reshape(images[\"train\"],np.shape(images[\"train\"])+(1,))\n",
    "xval = np.reshape(images[\"xval\"],np.shape(images[\"xval\"])+(1,))\n",
    "test = np.reshape(images[\"test\"],np.shape(images[\"test\"])+(1,))\n",
    "print(f\"Training data: {train.shape}\\nValidation data: {xval.shape}\\nTest data: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.visualise_data(train[:,:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:,0,:,:,:].shape, xval[:,0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_train = np.reshape(train[5,0,:,:,:],((1,)+train.shape[2:]))\n",
    "overfit_truth = np.reshape(train[5,1,:,:,:],((1,)+train.shape[2:]))\n",
    "overfit_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_5min = np.load(sys.path[0]+\"/5_minute.npy\").item()\n",
    "train_5min = np.reshape(images_5min[\"train\"],np.shape(images_5min[\"train\"])+(1,))\n",
    "val_5min = np.reshape(images_5min[\"xval\"],np.shape(images_5min[\"xval\"])+(1,))\n",
    "test_5min = np.reshape(images_5min[\"test\"],np.shape(images_5min[\"test\"])+(1,))\n",
    "print(f\"Training data: {train.shape}\\nValidation data: {xval.shape}\\nTest data: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "src.visualise_data(train_5min[:,:,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC CONVOLUTIONAL AUTOENCODER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### USE MAXPOOLING AND UPSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(64, 64, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(overfit_train, overfit_truth,\n",
    "                epochs=2000,\n",
    "                batch_size=1,\n",
    "                shuffle=True)\n",
    "                #validation_data=(xval[:,0,:,:,:], xval[:,1,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoencoder.history\n",
    "hist.history.keys()\n",
    "plt.plot(hist.history['loss'])\n",
    "# plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig('training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_prediction = autoencoder.predict(overfit_train, batch_size=1)\n",
    "overfit_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(overfit_truth, overfit_prediction)\n",
    "error_images, error_vals, error_means = src.error_distribution(overfit_truth, overfit_prediction, metric=\"relative_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plotter(args, (overfit_train[:,:,:,0], overfit_truth[:,:,:,0], overfit_prediction[:,:,:,0], error_images[:,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=custom_loss, metrics=[src.relative_error_tensor])\n",
    "callback = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\\\n",
    "            keras.callbacks.ModelCheckpoint(filepath='cae_5min_50.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "autoencoder.fit(train_5min[:,0,:,:,:], train_5min[:,1,:,:,:],\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(val_5min[:,0,:,:,:], val_5min[:,1,:,:,:]),\n",
    "                callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.save(\"cae_50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.load_weights(\"cae_50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoencoder.history\n",
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'],)\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig('training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test[:,0,:,:,:], batch_size=100)\n",
    "truth       = test[:,1,:,:,:]\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(truth, predictions)\n",
    "args[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(truth, predictions, metric=\"relative_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:,0,:,:,0].shape, truth[:,:,:,0].shape, predictions[:,:,:,0].shape, error_images[:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_plotter(indices, datasets, task='prediction'):\n",
    "\n",
    "    if task == 'prediction':\n",
    "        title = ['Frame t', 'Frame t+1', 'Prediction t+1', 'Pixelwise difference']\n",
    "    elif task == 'upsampling':\n",
    "        title = ['Original', 'Downsampled', 'Upsampled', 'Pixelwise difference']\n",
    "    else:\n",
    "        sys.exit(\"Task must be 'prediction' or 'upsampling'.\")\n",
    "    for i in indices:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, num=None, figsize=(16, 16), dpi=80, facecolor='w', edgecolor='k')\n",
    "        for j, ax in enumerate(axes.flat):\n",
    "            im = ax.imshow(datasets[j][int(i)], vmin=0,\n",
    "                           vmax=max([np.max(dset[int(i)]) for dset in datasets[:2]]) if int(j) < 3 else None)\n",
    "                           #, norm=colors.PowerNorm(gamma=0.5) if int(j) == 3 else None)\n",
    "            ax.set_title(f\"{title[j]}\", fontsize=10)\n",
    "            colorbar(im)\n",
    "            ax.axis('off')\n",
    "        plt.savefig(f\"Sample_{i}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "def colorbar(mappable):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    return fig.colorbar(mappable, cax=cax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plotter(args[:10], (test[:,0,:,:,0], truth[:,:,:,0], predictions[:,:,:,0], error_images[:,:,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5MIN RESOLUTION, ADD GRAD DIFF LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoencoder.history\n",
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'],)\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig('training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test_5min[:,0,:,:,:], batch_size=100)\n",
    "truth       = test_5min[:,1,:,:,:]\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(truth, predictions)\n",
    "error_images, error_vals, error_means = src.error_distribution(truth, predictions, metric=\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plotter(args[:5], (test_5min[:,0,:,:,0], truth[:,:,:,0], predictions[:,:,:,0], error_images[:,:,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAME NETWORK WITH LSTM BUT NO LSTM LAYER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, BatchNormalization, Conv2DTranspose\n",
    "\n",
    "input_img = Input(shape=(64, 64, 1))\n",
    "\n",
    "x = Conv2D(8, (5, 5), strides=2, activation='relu', padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(16, (5, 5), strides=2, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (5, 5), strides=2, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (5, 5), strides=2, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded =  Conv2D(128, (5, 5), strides=4, activation='tanh', padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(64, (5, 5), strides=4, activation='relu', padding='same')(encoded)\n",
    "x = Conv2DTranspose(32, (5, 5), strides=2, activation='relu', padding='same')(x)\n",
    "x = Conv2DTranspose(16, (5, 5), strides=2, activation='relu', padding='same')(x)\n",
    "x = Conv2DTranspose(8, (5, 5), strides=2, activation='relu', padding='same')(x)\n",
    "decoded = Conv2DTranspose(1, (5, 5), strides=2, activation='relu', padding='same')(x)\n",
    "\n",
    "ae_no_lstm = Model(input_img, decoded)\n",
    "ae_no_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_diff(yTrue, yPred):\n",
    "    alpha = 1\n",
    "    if len(yTrue.shape) == 5 :\n",
    "        true = K.pow(K.flatten(K.abs(K.abs(yTrue[:,:,1:,:,:] - yTrue[:,:,:-1,:,:]) -\n",
    "                                     K.abs(yPred[:,:,1:,:,:] - yPred[:,:,:-1,:,:]))),alpha)\n",
    "        pred = K.pow(K.flatten(K.abs(K.abs(yTrue[:,:,:,1:,:] - yTrue[:,:,:,:-1,:]) -\n",
    "                                     K.abs(yPred[:,:,:,1:,:] - yPred[:,:,:,:-1,:]))),alpha)\n",
    "    elif len(yTrue.shape) == 4 :\n",
    "        true = K.pow(K.flatten(K.abs(K.abs(yTrue[:,1:,:,:] - yTrue[:,:-1,:,:]) -\n",
    "                                     K.abs(yPred[:,1:,:,:] - yPred[:,:-1,:,:]))),alpha)\n",
    "        pred = K.pow(K.flatten(K.abs(K.abs(yTrue[:,:,1:,:] - yTrue[:,:,:-1,:]) -\n",
    "                                     K.abs(yPred[:,:,1:,:] - yPred[:,:,:-1,:]))),alpha)\n",
    "    num = K.sum(true + pred)\n",
    "    return num / tf.to_float((K.shape(true)[0] + K.shape(pred)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
    "#            keras.callbacks.ModelCheckpoint(filepath='ae_best.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return keras.losses.mean_squared_error(y_true, y_pred) + gradient_diff(y_true, y_pred)\n",
    "\n",
    "# autoencoder.load_weights(\"ae_best.h5\")\n",
    "ae_no_lstm.compile(optimizer='adam', loss='mean_squared_error', metrics=[src.relative_error_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "ae_no_lstm.fit(train[:,0,:,:,:], train[:,1,:,:,:],\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(xval[:,0,:,:,:], xval[:,1,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = ae_no_lstm.history\n",
    "plt.plot(hist.history['loss'],)\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.savefig('training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ae_no_lstm.predict(test[:,0,:,:,:], batch_size=100)\n",
    "truth       = test[:,1,:,:,:]\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = src.arg_getter(truth, predictions)\n",
    "args[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images, error_vals, error_means = src.error_distribution(truth, predictions, metric=\"relative_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plotter(args[:10], (test[:,0,:,:,0], truth[:,:,:,0], predictions[:,:,:,0], error_images[:,:,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VARIATIONAL AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Flatten\n",
    "\n",
    "batch_size = 128\n",
    "latent_dim = 32\n",
    "epsilon_std = 0.0001\n",
    "\n",
    "input_img = Input(batch_shape=(batch_size, 64, 64, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "flat_x = Flatten()(encoded)\n",
    "z_mean = Dense(latent_dim)(flat_x)\n",
    "z_log_sigma = Dense(latent_dim)(flat_x)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "z = Dense(4*4*8)(z)\n",
    "tf.reshape(z, [128, 4, 4, 8])\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(z)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "vae = Model(input_img, decoded)\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
